[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Einführung in R",
    "section": "",
    "text": "Vorwort\nDieses mit quarto erstellte Dokument ist das Skript zu der am 19. und 20. Februar 2024 im KFN MethodLab abgehaltenen Einführung in die Aufbereitung, Auswertung und Darstellung von Daten mit Hilfe der freien Sprache R.\nDie Einführung ist für zwei Tage geplant, mit dem Ablauf in (tab-fstDay?) am ersten Tag. Die Abschnitte sind hier, hier und hier zu finden.",
    "crumbs": [
      "Vorwort"
    ]
  },
  {
    "objectID": "prep.html",
    "href": "prep.html",
    "title": "KFN MethodLab",
    "section": "",
    "text": "Vorbereitung des Workshops",
    "crumbs": [
      "Vorwort",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>KFN MethodLab</span>"
    ]
  },
  {
    "objectID": "prep.html#vorbereitung-des-workshops",
    "href": "prep.html#vorbereitung-des-workshops",
    "title": "KFN MethodLab",
    "section": "",
    "text": "Installation von R und RStudio\nUm die Übungen im Skript ausführen zu können, braucht es einen Rechner mit aktuellen Versionen von R und RStudio. Die Installationsdateien für R für Windows findet man hier und für Mac hier, die aktuellen Installationsdateien für RStudio finden sich hier.\nWir brauchen mindestens RStudio 2023.03 “Cherry Blossom” und eine entsprechende R-Version.\nZum Updaten können einfach die aktuellen Installer heruntergeladen und ausgeführt werden, hier gibt es dazu auch eine Anleitung.\n\n\nVorbereitung Tag 1 und 2\nZusätzlich brauchen wir für das rendern von Reports noch quarto, die Installationsdateien findet man hier.\nAußerdem werden im Skript die folgenden Pakete genutzt:\n\ntidyverse\ntidymodels\napaTables\npapaja\nhuxtable\nquarto\n\nUm alle Pakete zu installieren, die im Skript genutzt werden, bitte die folgende Zeile ausführen:\n\ninstall.packages(c('tidyverse', 'tidymodels', 'papaja', \n                   'apaTables', 'huxtable', 'quarto'))\n\nDazu den Code-Schnipsel kopieren, RStudio öffnen, die Zeile in die Konsole (bei neuer Installation unten links) einfügen und Enter drücken.\n\n\nVorbereitung Tag 3\nFür Tag 3 wird das Paket confreq benötigt.\nZum Installieren führen Sie bitte die folgende Zeile aus:\n\ninstall.packages('confreq')\n\n\n\nVorbereitung Tag 4\nFür Tag 4 werden semTools und lavaan benötigt. Sollten Sie schon für Tag 1 und 2 alle Pakete installiert haben, sind diese beiden Pakete auch schon mit-installiert.\nSonst führen Sie die folgende Zeile aus:\n\ninstall.packages('semTools')\n\nlavaan wird dann direkt mit-installiert.",
    "crumbs": [
      "Vorwort",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>KFN MethodLab</span>"
    ]
  },
  {
    "objectID": "rste_schritte.html",
    "href": "rste_schritte.html",
    "title": "Rste Schritte",
    "section": "",
    "text": "Warum R?\nDas R-Manual (R Core Team, 2023) hatte auf OpenAlex zum Zeitpunt der Erstelung dieses Skripts 10464 Zitationen gelistet.\nDie drei Paper aus diesen Zitaten mit den wiederum meisten Zitaten sind alles Paper, die R-Pakete vorstellen. Namentlich sind das lme4 (Bates et al., 2014), fitdistrplus (Delignette-Muller & Dutang, 2015) und mediation (Tingley et al., 2014). Diese drei Paper wurden in Summe weitere 51330 mal zitiert.\nÜber die Zeit zeigt sich ein eindeutiger Trend:\nUnd dabei sind alle möglichen empirischen Disziplinen unter den Outlets vertreten, in denen R am häufigsten zitiert wurde:",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rste Schritte</span>"
    ]
  },
  {
    "objectID": "rste_schritte.html#warum-r",
    "href": "rste_schritte.html#warum-r",
    "title": "Rste Schritte",
    "section": "",
    "text": "R ist beliebt!\n\n\n\n\n\n\n\n\nWoran liegt das?\nDas zentrale Argument:\nIm Gegensatz zu anderen gängigen Statistik-Tools ist R Open Source.\nDamit kommt einher, dass R kostenlos und vor allem von der Community erweiterbar ist. Dazu kommt das CRAN (Comprehensive R Archive Network), über das mit einem sehr rigorosen1 Review-Verfahren Pakete unproblematisch zur Verfügung gestellt werden.\n1 Wie auch am häufigen Nölen aus der Community abzulesen ist.\n\nCRAN\nDas CRAN habt Ihr bereits benutzt - mit install.packages() greift Ihr auf dieses Paket-Archiv zu und ladet Pakete runter.\nPosit stellt hier mit einer shiny-Demo sehr anschaulich dar, wie beliebt cran-Pakete und damit R sind.\n\n\nWas spricht gegen R?\n\nMausnavigierte IDEs wirken erstmal intuitiver2\nMan braucht vor allem am Anfang (ein bisschen) Frustrationstoleranz bis genug Übung besteht\nViele Beiträge von vielen Community-Mitglieder:innen heißt natürlich auch viele Ideen wie Probleme richtig gelöst werden. Die Syntax ist zwischen Paketen also oft uneinheitlich.\n\n2 Jamovi versucht hier die Lücke zu schließen.\n\nAber:\n\nMan findet sehr schnell Hilfe.3\nVor allem in den letzten fünf Jahren haben sich Projekte herausgebildet, die versuchen viele der größten Frustrationen an R abzustumpfen, z.B. Jamovi und das tidyverse.\n\n3 Auf stackoverflow gibt es zum Beispiel eine sehr aktive Gruppe an R-Usern",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rste Schritte</span>"
    ]
  },
  {
    "objectID": "rste_schritte.html#zuweisungen-und-das-environment",
    "href": "rste_schritte.html#zuweisungen-und-das-environment",
    "title": "Rste Schritte",
    "section": "1. Zuweisungen und das Environment",
    "text": "1. Zuweisungen und das Environment\nUnter Zuweisung ist erstmal nichts anderes zu verstehen, als einem Zwischenergebnis einen Namen zu geben, um es wiederverwenden zu können.\nAuch wenn es andere Möglichkeiten gibt, ist die Folgende die am besten lesbare:\n\na_number &lt;- 42\n\nDie Zahl 42 ist jetzt für weitere Verwendung im Environment abgelegt:\n\n\n\nScreenshot vom Environment\n\n\nUnd wie die Zahl alleine weiterzuverwenden:\n\n42^2\n\n[1] 1764\n\na_number^2 ## äquivalent\n\n[1] 1764\n\n\nJede dieser in grau unterlegten Zeilen nennt man auch eine Anweisung. R wird in der letzten Zeile angewiesen, den ‘Inhalt’ von a_number zu quadrieren. Dabei wird der dahinter durch das #-Symbol eingeleitete Kommentar ignoriert.\nDabei ist das Environment in jeder Session neu, wenn ich RStudio schließe und neu aufmache, wird also eine neue, leere Umgebung geöffnet4.\n4 Und direkt wieder befüllt, wenn man das unter Global Options -&gt; General -&gt; Workspace die Optionen nicht angepasst hat.5 Dazu zählen in R auch die FunktionenUnd nicht nur von uns erstellte Objekte sind im Environment vorgehalten, alle anderen aufrufbaren Objekte 5 sind in Environments zu finden. Um z.B. Pakete nutzen zu können, müssen diese erst in die Umgebung geladen werden - dazu aber später mehr.",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rste Schritte</span>"
    ]
  },
  {
    "objectID": "rste_schritte.html#funktionen-und-argumente",
    "href": "rste_schritte.html#funktionen-und-argumente",
    "title": "Rste Schritte",
    "section": "2. Funktionen und Argumente",
    "text": "2. Funktionen und Argumente\nDer Großteil des in R erstellten Codes besteht aus Funktionen.\nJede Funktion ist eine Sammlung an Anweisungen, die nacheinander augeführt werden sollen.\ncitation() ist ein sehr einfaches Beispiel für eine solche Funktion.\n\nWas macht citation()?\n\n\n\ncitation() gibt in der Konsole aus, wie man R am Besten zitiert.\n\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\n\nobligatorische und optionale Argumente\nDie meisten Funktionen kommen aber nicht ohne Argumente aus.\nArgumente können in obligatorische und optionale unterteilt werden. \nWie die Namen schon sagen, sind obligatorische Argumente solche, ohne die die Funktion nicht ausgeführt werden kann.\nObligatorische Argumente sind meistens die Werte, auf deren Basis gerade die Operationen ausgeführt werden sollen.\n\nWenn man keins oder ein falsches obligatorisches Argument übergibt, zeigt R einen Fehler an!\n\noptionale Argumente nennt man die, für die die Autoren der Funktion einen Standard vorgesehen haben. Das sind dann meist Stellschrauben, an denen das gewünschte Ergebnis genauer festgelegt werden kann. Werden diese Argumente nicht explizit gesetzt, wird einfach der Standard verwendet.\n\nEin Beispiel für eine Funktion, die obligatorische und optionale Argumente annimmt ist round(). \nAuf der Hilfeseite von round() finden wir folgendes6:\n6 Die Hilfeseite lässt sich entweder über die grafische Oberfläche oder mit help('round') aufrufen.\n\n\n\n\n\n\n\n\n\nWas ist hier das obligatorische Argument und wie erkennt man es?\n\n\n\nx ist hier das obligatorische Argument (kein Standard durch ein =) angegeben\nWenn man round ohne ausprobiert, gibt es einen Fehler:\n\nround()\n\nError in eval(expr, envir, enclos): 0 arguments passed to 'round' which requires 1 or 2 arguments\n\n\nWen man eine Zahl übergibt, wird auf ganze Zahlen gerundet:\n\nround(3.1415)\n\n[1] 3\n\n\n\n\nAntwort aufdecken\n\n\nDas optionale Argument digits, ermöglicht dann, die gewünschte Anzahl der Nachkommastellen anzugeben:\n\nround(3.1415, digits = 2)\n\n[1] 3.14\n\n\nSowohl 3.1415 als auch digits = 2 setzen Werte für Argumente! \nDa die Funktion aber die zu rundende Zahl x an erster Stelle erwartet, ergibt der Aufruf das gewünschte Ergebnis.\n\n\nPosition von Argumente\nR braucht also nicht unbedingt die Argumentnamen, wenn keine da sind wird die Reihenfolge interpretiert.\n\nround(3.1415, 2) ## funktioniert, digits wird an zweiter Stelle erwartet\n\n[1] 3.14\n\n\n\nWas versucht R, wenn ich die folgende Anweisung ausführe?\n\n\nround(2, 3.1415)\n\n\n\nR rundet die Zahl 2 auf 3.1415 (also 3) Nachkommastellen.\n\nround(2, 3.1415) ## funktioniert, aber vielleicht nicht wie erwartet\n\n\nWenn man Argumente ohne Namen in falscher Reihenfolge übergibt, gibt es keine Fehlermeldung aber Blödsinn!\n\n\n\nAntwort aufdecken\n\n\n\n\nOperatoren\nEinzelne Zahlen benutzt man aber ja quasi nie. Deswegen hier eine sehr praktische Funktion:\n\n1:3\n\n[1] 1 2 3\n\n\nHuch! Das sieht ja gar nicht nach einer Funktion aus! \n\nNeben den klassischen Funktionen, die durch ein Codewort und Klammern erkenntlich sind, gibt es in R noch eine Reihe Operatoren, die auf den ersten Blick keine Funktionen sind.\nHier wird aber eigentlich `:`(1,3) ausgeführt, das Funktionsschema gilt also auch hier. `:`(1,3) ist nur schrecklich schlecht lesbar und viel zu viel zu tippen.",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rste Schritte</span>"
    ]
  },
  {
    "objectID": "rste_schritte.html#indizieren",
    "href": "rste_schritte.html#indizieren",
    "title": "Rste Schritte",
    "section": "3. Indizieren",
    "text": "3. Indizieren\nDa wir jetzt erste Vektoren mit mehr als einem Element erstellen können, gehen wir zu nächsten Part, der Indizierung über.\nIn R lassen sich Elemente eines Objektes auf viele verschiedene Arten aufrufen, am Ende laufen diese aber auf den [], den [[]] und den $-Operator hinaus.\nFür Vektoren reicht erstmal der []-Operator.\n\nDas einfachste Beispiel ist der Versuch, den 3. Wert aus einer Zahlenreihe ausgeben zu lassen.\nDafür erstellen wir zuerst die Zahlenreihe von 10 bis 15 und speichern diese im Environment\n\nWie mache ich das?\n\n\n\n\neine_reihe_von_zahlen &lt;- 10:15\n\n\n\nAntwort aufdecken\n\n\nJetzt kann ich den []-Operator benutzen, um den 3. Wert anzeigen zu lassen:\n\neine_reihe_von_zahlen[3]\n\n[1] 12\n\n\nUnd fertig. So einfach.\nDer []-Operator kann aber noch viel mehr. Ich kann zum Beispiel eine Sequenz übergeben, um eine Reihe von Zahlen ausgeben zu lassen:\n\neine_reihe_von_zahlen[1:3]\n\n[1] 10 11 12\n\n\n\nDer erste Wert ist die 10! der Index für die erste Stelle ist also die 1!\n\nEine weitere Möglichkeit ist die ausschließende Indizierung. Mit einem - gibt man an, dass einen alle außer der angegebenen Stelle interessieren.\n\neine_reihe_von_zahlen[-3]\n\n[1] 10 11 13 14 15\n\n\n\nlogische Indizierung\nDer []-Operator kann außerdem benutzt werden, um über logische Operatoren Werte zu indizieren.\nDie einfachsten sind hier:\n\n1 == 2 ## ist 1 gleich 2\n1 != 3 ## ist 1 ungleich 3\n1 &lt; 4  ## ist 1 kleiner als 4\n2 &gt;= 1 ## ist 2 größer gleich 1\n\n[1] FALSE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n\n\nDiese Operatoren kann ich auch auf Vektoren anwenden:\n\neine_reihe_von_zahlen &gt; 11\n\n[1] FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n\n\nUnd kann das Ergebnis auch mit dem []-Operator kombinieren:\n\neine_reihe_von_zahlen[eine_reihe_von_zahlen &gt; 11]\n\n[1] 12 13 14 15",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rste Schritte</span>"
    ]
  },
  {
    "objectID": "rste_schritte.html#datenformate-in-r",
    "href": "rste_schritte.html#datenformate-in-r",
    "title": "Rste Schritte",
    "section": "4. Datenformate in R",
    "text": "4. Datenformate in R\nBei der letzten Operation haben wir zwei Datenformate kennengelernt:\n\nlogical, eine binär-logische Angabe und\nnumeric, alle ganze und (darstellbare) rationale Zahlen\n\nJetzt kennen wir schon 2 der 3 wichtigsten einfachen oder atomic Datenformate in R\nNeben Zahlen muss R aber natürlich auch Text verarbeiten können. Dies geschieht über das character-Datenformat.\n\nWie könnte ich versuchen, ein character-Objekt mit dem Inhalt “Ich bin ein String” anzulegen?\n\n\n\n\nein_toller_character &lt;- \"Ich bin ein String\"\n\n\n\nAntwort aufdecken\n\n\nDiese einfachen Datenformate haben eine Hierarchie, die man so darzustellen versuchen könnte:\n\n logical &lt; numeric &lt; character \n\n \nAm deutlichsten wird das beim Benutzen einer der wichtigsten Funktionen in R: c() 7 - die Vektor-Funktion. Mit ihr können wir Werte zu Vektoren zusammenfügen und zu bestehenden Vektoren hinzufügen.\n7 ‘c’ ist hier übrigens kurz für concatinate\nlogical_vector &lt;- c(TRUE, TRUE, FALSE)\nlogical_vector\n\n[1]  TRUE  TRUE FALSE\n\nc(logical_vector,1)\n\n[1] 1 1 0 1\n\n\nDie logischen Werte wurden in Zahlen umgewandelt.\n\nWas passiert wohl, wenn wir eine 1 und einen character hinzufügen?\n\n\n\n\nc(logical_vector,1,'ein character')\n\n[1] \"TRUE\"          \"TRUE\"         \n[3] \"FALSE\"         \"1\"            \n[5] \"ein character\"\n\n\nDie logischen Werte und die Zahl wurden in character umgewandelt\n\n\nAntwort aufdecken\n\n\n\nDie atomics haben mit logical &lt; numeric &lt; character eine klare Hierarchie!\n\nRückgängig machen lässt sich das durch as.logical, as.numeric und as.character. Aber Vorsicht, so können auch leicht fehlende Werte, durch NA gekennzeichnet erzeugt werden:\n\nein_umzuwandelnder_vektor &lt;- c('a',1,15,TRUE)\nas.numeric(ein_umzuwandelnder_vektor)\n\n[1] NA  1 15 NA\n\n\n\n\nas.numeric(ein_umzuwandelnder_vektor)\n\n[1] NA  1 15 NA\n\n\n\nWarum fehlt auch der letzte Wert?\n\n\n\nWeil das TRUE inzwischen ein character ist.\n\nein_umzuwandelnder_vektor\n\n[1] \"a\"    \"1\"    \"15\"   \"TRUE\"\n\n\n\n\nAntwort aufdecken\n\n\nNatürlich gibt es auch komplexere, mehrdimensionale Datenformate in R, um die geht es im nächsten Teil.\n\n\n\n\nBates, D., Mächler, M., Bolker, B., & Walker, S. (2014). Fitting linear mixed-effects models using lme4. arXiv Preprint arXiv:1406.5823.\n\n\nDelignette-Muller, M. L., & Dutang, C. (2015). Fitdistrplus: An r package for fitting distributions. Journal of Statistical Software, 64, 1–34.\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nTingley, D., Yamamoto, T., Hirose, K., Keele, L., & Imai, K. (2014). Mediation: R package for causal mediation analysis.",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rste Schritte</span>"
    ]
  },
  {
    "objectID": "wrangling00.html",
    "href": "wrangling00.html",
    "title": "Daten manipulieren",
    "section": "",
    "text": "Datensätze in R\nWie alle anderen Programme zur statistischen Auswertung hat R natürlich neben den Vektoren auch rechteckige Datenformate.\nDas typische rechteckige Datenformat in base R ist der data.frame. Im Prinzip nichts anderes, als spaltenweise zusammengeklebte Vektoren. Der Konstruktor für ein solches Objekt ist die gleichnamige Funktion, die die Spalten als benannte Argumente nimmt:\ndf &lt;- data.frame(a = 1:3,\n                 b = c(TRUE, FALSE, TRUE),\n                 c = c('a','b','c'))\ndf\n\n  a     b c\n1 1  TRUE a\n2 2 FALSE b\n3 3  TRUE c\nDas Indizieren im Datensatz geht dann am lesbarsten, durch das Angeben der gewünschten Spalte mit dem $-Operator und der Auswahl der Zeile durch den schon bekannten []-Operator.\ndf$c[2] ## 2. Wert in der 'c'-Spalte.\n\n[1] \"b\"\nWie könnte ich den 3. Wert in der b-Spalte indizieren?\nDer iris-Datensatz ist ein im Grundumfang von R mitgelieferter Datensatz, der historische botanische Daten nach Anderson (1935) enthält.\niris %&gt;% \n  head()\n\n  Sepal.Length Sepal.Width Petal.Length\n1          5.1         3.5          1.4\n2          4.9         3.0          1.4\n3          4.7         3.2          1.3\n4          4.6         3.1          1.5\n5          5.0         3.6          1.4\n6          5.4         3.9          1.7\n  Petal.Width Species\n1         0.2  setosa\n2         0.2  setosa\n3         0.2  setosa\n4         0.2  setosa\n5         0.2  setosa\n6         0.4  setosa",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten manipulieren</span>"
    ]
  },
  {
    "objectID": "wrangling00.html#datensätze-in-r",
    "href": "wrangling00.html#datensätze-in-r",
    "title": "Daten manipulieren",
    "section": "",
    "text": "df$b[3]\n\n\nAntwort aufdecken\n\n\n\n\n\nÜbersicht über Datensatz verschaffen\nDas ist natürlich ein bisschen unübersichtlich, wie kann man damit umgehen?\n\n1. Möglichkeit:\nWenn man iris explizit in das Environment nimmt, kann man die Oberfläche von RStudio nutze, um sich einen Überblick zu verschaffen 1\n1 Dabei nutzt die RStudio-IDE aber nur die str()(für structure)-Funktion.\niris &lt;- iris\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2. Möglichkeit:\nDie summary-Funktion, die genau das macht, was ihr Name suggeriert:\n\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length  \n Min.   :4.300   Min.   :2.000   Min.   :1.000  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600  \n Median :5.800   Median :3.000   Median :4.350  \n Mean   :5.843   Mean   :3.057   Mean   :3.758  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100  \n Max.   :7.900   Max.   :4.400   Max.   :6.900  \n  Petal.Width          Species  \n Min.   :0.100   setosa    :50  \n 1st Qu.:0.300   versicolor:50  \n Median :1.300   virginica :50  \n Mean   :1.199                  \n 3rd Qu.:1.800                  \n Max.   :2.500                  \n\n\n\n\n\nAufgabe: Deskriptive Kennwerte berechnen\nWir wollen für diesen Datensatz jetzt die folgenden Schritte der Auswertung vollziehen:\n\nAusschluss der Blumen, die breitere Blütenblätter als das 1.5-fache der mittleren Blütenblätter haben und Kelche, die kürzer als das Mittel der Kelchlänge sind\nDarstellung der Mittelwerte und Streuungen der Blütenblattlänge und -breite pro verbleibende Spezies als Tabelle\n\n\n\nAufgabe: Base-R Lösung\n\ndf &lt;- iris[iris$Petal.Width &lt;= 1.5 * mean(iris$Petal.Width) &\n             iris$Sepal.Length &gt;= mean(iris$Sepal.Length),]\nmeans &lt;- aggregate(cbind(df$Petal.Length,df$Petal.Width),\n          by = list(Species = df$Species),\n          FUN = mean)\nsds &lt;- aggregate(cbind(df$Petal.Length,df$Petal.Width),\n          by = list(Species = df$Species),\n          FUN = sd)\ntab &lt;- data.frame(means, sds[,2:3])\nnames(tab)[2:5] = c('m_Length', 'm_Width', 'sd_Length', 'sd_Width')\ntab\n\n     Species m_Length m_Width sd_Length\n1 versicolor    4.560   1.424 0.2783882\n2  virginica    5.375   1.500 0.3862210\n    sd_Width\n1 0.14798649\n2 0.08164966\n\n\n\n\nAuftritt tidyverse\nDie selbe Aufgabe wie gerade, jetzt mit dem tidyverse:\n\nlibrary(tidyverse)\niris %&gt;% \n  filter(Petal.Width &lt;= 1.5 * mean(Petal.Width) &\n           Sepal.Length &gt;= mean(Sepal.Length)) %&gt;% \n  group_by(Species) %&gt;% \n  summarise(m_Length = mean(Petal.Length),\n            sd_Length = sd(Petal.Length),\n            m_Width = mean(Petal.Width), \n            sd_Width = sd(Petal.Width))\n\n# A tibble: 2 × 5\n  Species    m_Length sd_Length m_Width sd_Width\n  &lt;fct&gt;         &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 versicolor     4.56     0.278    1.42   0.148 \n2 virginica      5.38     0.386    1.5    0.0816\n\n\n\n\ntidy aggregation\nDas tidyverse ist eine Sammlung von Paketen, deren Hauptziel es ist, Datenaufbereitung in R intuitiver und leichter lesbar zu machen.\nEin zentrales Element dabei ist der %&gt;%-Operator, die sogenannte Pipeline2. Beim Skript-Lesen und -Schreiben kann man sich diese am Besten als ‘dann’ vorstellen\n2 base-R hat mit Version 4.1 auch eine native pipe eingeführt (|&gt;), da wir aber eh das tidyverse nutzen bleiben wir bei der magrittr-pipeMit ihrer Hilfe werden Aufbereitungsschritte in einer stringenten Reihe an Operationen formuliert, die sich am Besten als Satz verstehen lassen.\nDa die Funktionen im tidyverse alle mit einfachen Verben benannt sind, lässt sich die Operation von eben auch so lesen.\n\n\n1library(tidyverse)\n2iris %&gt;%\n3  filter(Petal.Width &lt;= 1.5 * mean(Petal.Width) &\n           Sepal.Length &gt;= mean(Sepal.Length)) %&gt;%\n4  group_by(Species) %&gt;%\n5  summarise(m_Length = mean(Petal.Length),\n            sd_Length = sd(Petal.Length),\n            m_Width = mean(Petal.Width),\n            sd_Width = sd(Petal.Width))\n\n\n1\n\nZuerst muss das tidyverse geladen werden\n\n2\n\nNimm iris, dann …\n\n3\n\nfilter Zeilenweise nach den gesetzten Regeln, dann…\n\n4\n\ngruppiere nach der Spezies, dann…\n\n5\n\nberechne die angegebenen Kenngrößen über die Gruppen.\n\n\n\n\nZweite Beispielaufgabe:\nWir möchten für den iris-Datensatz:\n\nEine Spalte hinzufügen, die die z-transformierte Blattlänge enthält\nEine Spalte hinzufügen, die als character das Ergebnis eines Mediansplits der gerade erstellten Variable enthält\nEinen Datensatz erstellen, der nur die Spezies, die z-Transformierte und die Mediansplit-Variable enthält\nDie Häufigkeiten der Kombinationen von Mediansplit-Gruppe und Spezies auszählen\n\n\n1df &lt;- iris %&gt;%\n2  mutate(\n3        z_length = (Petal.Length-mean(Petal.Length))/sd(Petal.Length),\n4        med_split = case_when(\n5                           z_length &gt;= median(z_length) ~ 'upper',\n6                           T ~ 'lower')) %&gt;%\n7  select(Species, z_length, med_split)\n\n\n1\n\nErstelle ein Objekt df. Nimm dazu iris, dann …\n\n2\n\nverändere den Datensatz indem Du …\n\n3\n\ndie z-Werte pro Blatt-Länge berechnest und als z_length dem Datensatz hinzufügst, …\n\n4\n\nmit der Funktion case_when eine Spalte anlegst, die …\n\n5\n\nz_length-Werten kleiner/gleich dem Median ‘upper’ zuweist …\n\n6\n\nund allen anderen Werten ‘lower’. Dann…\n\n7\n\nwähle die Spalten Species, z_length und med_split aus.\n\n\n\n\nHat das geklappt?\n\nWie könnte ich das überprüfen?\n\n\n\n\nsummary(df)\n\n       Species      z_length      \n setosa    :50   Min.   :-1.5623  \n versicolor:50   1st Qu.:-1.2225  \n virginica :50   Median : 0.3354  \n                 Mean   : 0.0000  \n                 3rd Qu.: 0.7602  \n                 Max.   : 1.7799  \n  med_split        \n Length:150        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\n\n\nAntwort aufdecken\n\n\nJetzt noch Häufigkeiten auszählen:\n\n1df %&gt;%\n2  group_by(Species, med_split) %&gt;%\n3  summarise(n = n())\n\n\n1\n\nNimm df, dann …\n\n2\n\ngruppiere nach Species und med_split, dann…\n\n3\n\nZähle die absoluten Häufigkeiten aus.\n\n\n\n\n`summarise()` has grouped output by 'Species'.\nYou can override using the `.groups` argument.\n\n\n# A tibble: 4 × 3\n# Groups:   Species [3]\n  Species    med_split     n\n  &lt;fct&gt;      &lt;chr&gt;     &lt;int&gt;\n1 setosa     lower        50\n2 versicolor lower        25\n3 versicolor upper        25\n4 virginica  upper        50\n\n\n\n\nAufgabe\nMachen Sie sich mit dem swiss-Datensatz vertraut. Lesen Sie dazu auch die Hilfeseite zu dem Datensatz, diese können Sie mit ?swiss aufrufen. Erstellen Sie mit Hilfe einer pipeline einen Datensatz, der…\n\nnur Provinzen enthält, deren Einwohner zu mehr als 10% und weniger als 35% Bestnoten bei der Armee-Untersuchung erhalten haben\nnur den Anteil der männlichen Population in der Landwirtschaft, die Kindersterblichkeit, das Bildungsniveau und den Anteil der katholischen Familien enthält\neine numerische Variable enthält, die für die so ausgewählten Fälle einen Mediansplit der Kindersterblichkeit codiert.\neine Variable enthält, die angibt, ob der Anteil der männlichen Population an der Landwirtschaft über oder unter dem Mittelwert (mean) liegt\n\nLassen Sie sich die absoluten Häufigkeiten der Kombination der beiden gerade erstellten Variablen ausgeben.\nZusatz: Erstellen Sie anschließend eine kurze pipeline, die den gerade erstellten Datensatz mit dem Absteigenden Bildungsniveau als ersten Sortierschlüssel und dem aufsteigenden Anteil katholischer Familien als zweitem Schlüssel sortiert. Nutzen Sie dafür die Hilfeseite der arrange-Funktion.\n\n\n\nlibrary(tidyverse)\ndf &lt;- swiss %&gt;%\n  filter(Education &gt; 10,\n         Education &lt; 35) %&gt;%\n  select(Agriculture,\n         Infant.Mortality,\n         Education,\n         Catholic) %&gt;%\n  mutate(\n    mediansplit_mortality = case_when(\n      Infant.Mortality &gt;= median(Infant.Mortality) ~ 1,\n      T ~ -1),\n    meansplit_agriculture = case_when(\n      Agriculture &gt; mean(Agriculture) ~ 'high',\n      Agriculture &lt; mean(Agriculture) ~ 'low',\n      T ~ 'mean'\n    )\n  )\n\ndf %&gt;% \n  count(mediansplit_mortality,meansplit_agriculture)\n\n  mediansplit_mortality meansplit_agriculture n\n1                    -1                  high 4\n2                    -1                   low 4\n3                     1                  high 4\n4                     1                   low 4\n\ndf2 &lt;- df %&gt;% \n  arrange(-Education,\n          Catholic)\n\n\n\nAntwort aufdecken\n\n\n\n\n\n\nAnderson, E. (1935). The irises of the Gaspe Peninsula. Bull. Am. Iris Soc., 59, 2–5.",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten manipulieren</span>"
    ]
  },
  {
    "objectID": "wrangling01.html",
    "href": "wrangling01.html",
    "title": "Daten einlesen",
    "section": "",
    "text": "Einlesen von Daten\nDas Rechnen mit den mit R mitgelieferten Datensätzen ist natürlich nur bedingt realitätsnah.\nIm durchschnittlichen Anwendungsfall müssen externe Datensätze eingelesen werden.\nDabei sind im tidyverse dafür je nach Quelle folgende Pakete vorgesehen:",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "wrangling01.html#einlesen-von-daten",
    "href": "wrangling01.html#einlesen-von-daten",
    "title": "Daten einlesen",
    "section": "",
    "text": "Textbasierte Daten(.txt, .csv, .tsv,...) \\(\\rightarrow\\) readr\nExcel-Mappen(.xlsx, .xls) \\(\\rightarrow\\) readxl\nDaten aus anderen Statistikpaketen(.sav, .dta,...) \\(\\rightarrow\\) haven\n\n\nEinlesen von Textdaten\nAlle diese drei Pakete sind auch in der RStudio-GUI implementiert: \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem\nDas Einlesen und Aufbereiten wird am folgenden Beispiel exerziert:  Uns interessiert der Zusammenhang von Drogenmissbrauch, Lebenszufriedenheit und Straftaten in Großbritannien. Dafür haben wir die folgenden drei Datensätz zur Verfügung:\n\n'crime.csv' - Eine Textdatei mit nach Polizeibehörde aufgeschlüsselten Straftaten\n'drugs.xlsx' - Eine Excel-Arbeitsmappe mit nach Region aufgeschlüsselten Zahlen zu Krankenhauseinweisungen mit drogenbedingten Diagnosen\n'satisfaction.sav' - Ein in SPSS erstellter Datensatz mit nach Region aufgeschlüsselten Ergebnissen einer Bevölkerungsbefragung zur Lebenszufriedenheit\n\n\n\ntextbasierte Daten\nDie GUI ist hier ein guter Start. Wir wollen die Datei 'crime.csv' einlesen. Diese enthält echte Daten über von britischen Polizeibehörden aufgezeichnete Straftaten von der Website der britischen Regierung. Wenn ich dem Pfad im GUI folge, ergibt sich das folgende Bild:\n\n\n\n\n\n\n\n\n\n\nWas ist das Problem?\n\n\n\nDas Trennzeichen(Delimiter) ist falsch gesetzt. In den Daten sind die Zellen offensichtlich durch Semikolons getrennt.\n\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\nDer für das Einlesen nötige Code wird dann von RStudio in die Konsole kopiert und ausgeführt. Um nicht jedes Mal beim Ausführen desselben Skriptes wieder per Hand den Datensatz einlesen zu müssen, kopiert man den Code dann an den Anfang des Skriptes.\n\n\n\n\n\n\n\n\n\nWas passiert hier?\n\n1crime &lt;- read_delim(\"data/crime.csv\",\n2                    \";\",\n3                    escape_double = FALSE,\n4                    trim_ws = TRUE)\n5View(crime)\n\n\n1\n\nLege in crime das Textfile mit Trennzeichen unter dem angegebenen Pfad ab. Dabei…\n\n2\n\n…erwarte Semikolons als Trennzeichen,\n\n3\n\n…erwarte keine doppelten Anführungszeichen\n\n4\n\nund schneide Leerzeichen von den Einträgen ab.\n\n5\n\nDann öffne den Datensatz zum Angucken.\n\n\n\n\nMit dem Output teilt R mit, dass es Kommazahlen als Standard-Zelleninhalt versucht und bei nicht-Funktionieren auf character zurückfällt. Das ist trotz der Farbe keine Fehlermeldung.\nNoch zwei wichtige Tricks in dem Einlesetool sind die locale-Schaltfläche und das NA-Menü\n\n\n\n\n\n\n\n\n\n\n\nExcel-Arbeitsmappen\nFür die Excel-Arbeitsmappen ist die GUI auch der einfachste Weg.\n\nWie würde man vorgehen um die Datei drugs.xlsx einzulesen?\n\n\n\n\nImport Dataset \\(\\rightarrow\\) From Excel\nPfad zum file raussuchen\n\n\n\n\n\n\n\n\n\n\n\nRichtiges Sheet aussuchen\nunnötige Zeilen überspringen\netwaige von leeren Zellen abweichende NA-Codierung anpassen\n\n\n\nAntwort aufdecken\n\n\n\nAuch bei Excel-Mappen an das Kopieren des Codes denken!\n\n\nlibrary(readxl)\ndrugs &lt;- read_excel(\"data/drugs.xlsx\",\n                    sheet = \"Table 2\", \n                    na = \"*\", \n                    skip = 10)\n\nNew names:\n• `` -&gt; `...1`\n• `` -&gt; `...2`\n• `` -&gt; `...3`\n• `` -&gt; `...4`\n\n\nDiese Daten sind übrigens auch Originaldaten von der Website des britischen National Health Services\n\n\nDateien aus anderer Software\nBeispielhaft für SPSS, für Stata etc analog. Die GUI ist wieder ein guter Anfang und hier ziemlich selbsterklärend.\n\nWie würde man vorgehen um die Datei satisfaction.sav einzulesen?\n\n\n\n\nlibrary(haven)\nsatisfaction &lt;- read_sav(\"data/satisfaction.sav\")\n\nDie Daten kommen diesmal vom britischen Office for National Statistics, wurden aber stark abgewandelt.\n\n\nAntwort aufdecken\n\n\n\n\nDateien aus SPSS einlesen\nWenn man sich die Daten in der RStudio-Oberfläche anguckt, sieht man, dass die für SPSS typischen Variablendefinitionen konserviert wurden:\n\n\n\n\n\n\n\n\n\nhaven bietet mit der as_factor-Funktion eine Möglichkeit an, eine dieser Codierung enthaltenden Variablen in einen Faktor umzuwandeln.\nFaktoren sind eine Variante um in R kategoriale Variablen anzulegen.\nSo könnten wir uns zum Beispiel entscheiden, einen neuen, zweiten Datensatz zu erstellen, der die Variablen mit den Verbal-labels aus SPSS enthält. Da wir auf alle Spalten dafür dieselbe Funktion anwenden wollen, können wir dafür mutate mit der across-Funktion kombinieren.\nDabei benutzen wir die im tidyverse zur Stapelverarbeitung von Spalten genutzte tidy-select-Syntax und weil das noch nicht genug neues auf einmal ist noch die tidyverse-Syntax zur Definition von Platzhalter-Funktionen:\n\n1verbal_satisfaction &lt;- satisfaction %&gt;%\n2  mutate(\n3    across(\n4      everything(),\n5      ~ as_factor(.)\n    )\n  )\n\n\n1\n\nErstelle verbal_satisfaction indem Du verbal_satisfaction nimmst und dann…\n\n2\n\neine Veränderung durchführst indem Du…\n\n3\n\nfür mehrere Spalten 1…\n\n1 Bei across wird kein Spaltenname angegeben!4\n\nund zwar alle…\n\n5\n\ndie jeweilige Spalte an Stelle des Punkts einsetzt.\n\n\n\n\nDas Ergebnis sieht in der Oberfläche dann so aus:\n\n\n\n\n\n\n\n\n\nFür Tipps zur weitergehenden Bearbeitung von SPSS und Stata-Daten noch hier die sehr gute haven-Website mit Dokumentation und Anleitungen zu den nötigen Schritten.\n\n\nAufgabe\n\nLesen Sie die drei Datensätze temp.csv, charts.xlsx und covid_cases.sav ein und verschaffen Sie sich einen Überblick.",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "wrangling01.html#datenaufbereitung",
    "href": "wrangling01.html#datenaufbereitung",
    "title": "Daten einlesen",
    "section": "Datenaufbereitung",
    "text": "Datenaufbereitung\nDatenaufbereitung kann natürlich denkbar komplex sein, deswegen beschränken wir uns auf sehr einfache Methoden mit dem Fokus auf die Umsetzung im tidyverse. Es geht gleich explizit nicht um die Methoden! Wir gucken uns drei einfache Beispiele an:\n\nAusreißer-Behandlung\nUmgang mit fehlenden Werten\nRecodieren von Werten\n\n\nAusreißer-Behandlung\nAls ersten Schritt zur Bereinigung der drei Datensätze sollen Ausreißer erkannt und durch fehlende Werte ausgeschlossen werden.\nDafür muss man sich natürlich zuerst überlegen, was das Kriterium dafür sein soll. Wir benutzen hier das Kriterium nach Tukey (1977), also wollen wir gerade die Werte ausschlißen, die mehr als 1.5 Interquartilabstände über oder unter dem 25% bzw dem 75%-Quantil liegen.\nUm uns Tipparbeit zu sparen, schreiben wir dafür unsere erste Funktion:\n\n1remove_outlier &lt;- function(x){\n2  ifelse(\n3      between(x,\n              quantile(x,.25) - 1.5 * IQR(x),\n              quantile(x,.75) + 1.5 * IQR(x)),\n4          x,\n5          NA)\n6  }\n\n\n1\n\nErstelle ein Object mit dem Namen remove_outlier, in dem eine Funktion mit dem obligatorischen Argument x definiert ist, deren body durch { eingeleitet wird.\n\n2\n\nSetze anhand des logischen Vektors an der ersten Stelle Werte ein.\n\n3\n\nDie Logik soll sein ob sich die Werte von x zwischen den Tukey-Fences liegt\n\n4\n\nWenn ja, behalte den Werte von x…\n\n5\n\nsonst ersetze mit NA.\n\n6\n\nEnde der Definition.\n\n\n\n\n\nWie sähe die Frage mit case_when aus?\n\n\n\n\nremove_outlier &lt;- function(x){\n  case_when(\n    x &lt; quantile(x,.25) - 1.5 * IQR(x) ~ NA,\n    x &gt; quantile(x,.75) + 1.5 * IQR(x) ~ NA,\n    T ~ x\n  )\n  }\n\n\n\nAntwort aufdecken\n\n\nKombiniert mit einem mutate, einem across und einem weiteren tidy-select-helper können wir damit alle Ausreißer gegen fehlende Werte austauschen.\n\n1crime &lt;- crime %&gt;%\n2  mutate(\n3    across(\n4      where(is.numeric),\n5      ~remove_outlier(.)\n    )\n  )\n\n\n1\n\nÜberschreibe crime indem Du crime nimmst und dann…\n\n2\n\neine Veränderung durchführst indem Du…\n\n3\n\nfür mehrere Spalten…\n\n4\n\nund zwar alle numerischen…\n\n5\n\nunsere Ausreißer-Berinigung anwendest.\n\n\n\n\n\n\nUmgang mit fehlenden Werten\nFehlende Werte werden in R generell mit NA codiert. Um damit umzugehen bietet das tidyverse ein paar Funktionen, wir beschränken uns hier auf zwei.\ndrop_na zum rigorosen Entfernen von Zeilen mit fehlenden Werten:\n\ndrugs %&gt;% \n  drop_na()\n\n# A tibble: 0 × 7\n# ℹ 7 variables: ...1 &lt;chr&gt;, ...2 &lt;chr&gt;,\n#   ...3 &lt;chr&gt;, ...4 &lt;chr&gt;, All persons9 &lt;dbl&gt;,\n#   Male &lt;dbl&gt;, Female &lt;dbl&gt;\n\n\n…in unserem Fall vielleicht ein bisschen zu rigoros\nDie zweite Möglichkeit ist replace_na, eine Funktion die, wie der Name schon sagt, NAs durch festgelegte Werte ersetzen kann. Mit unserem mutate von eben kombiniert, können wir so alle fehlenden Zahlen im Datensatz durch 0 ersetzen:\n\ndrugs %&gt;% \n  mutate(\n    across(where(is.numeric),\n           ~replace_na(., 0))\n  )\n\n# A tibble: 195 × 7\n   ...1     ...2  ...3  ...4  `All persons9`  Male\n   &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;\n 1 &lt;NA&gt;     &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;               0     0\n 2 E920000… &lt;NA&gt;  &lt;NA&gt;  Engl…           7139  5294\n 3 &lt;NA&gt;     &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;               0     0\n 4 U        &lt;NA&gt;  U     Unkn…            244   202\n 5 &lt;NA&gt;     &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;               0     0\n 6 E120000… &lt;NA&gt;  A     Nort…            276   194\n 7 E060000… &lt;NA&gt;  116   Coun…             56    40\n 8 E060000… &lt;NA&gt;  117   Darl…             26    16\n 9 E080000… &lt;NA&gt;  106   Gate…             12     0\n10 E060000… &lt;NA&gt;  111   Hart…             29     0\n# ℹ 185 more rows\n# ℹ 1 more variable: Female &lt;dbl&gt;\n\n\n\nJetzt können wir noch die fehlenden character umgewandeln:\n\ndrugs &lt;- drugs %&gt;% \n  mutate(\n    across(where(is.numeric),\n           ~replace_na(., 0)),\n    across(where(is.character),\n           ~replace_na(., ''))\n  )\ndrugs\n\n# A tibble: 195 × 7\n   ...1     ...2  ...3  ...4  `All persons9`  Male\n   &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;\n 1 \"\"       \"\"    \"\"    \"\"                 0     0\n 2 \"E92000… \"\"    \"\"    \"Eng…           7139  5294\n 3 \"\"       \"\"    \"\"    \"\"                 0     0\n 4 \"U\"      \"\"    \"U\"   \"Unk…            244   202\n 5 \"\"       \"\"    \"\"    \"\"                 0     0\n 6 \"E12000… \"\"    \"A\"   \"Nor…            276   194\n 7 \"E06000… \"\"    \"116\" \"Cou…             56    40\n 8 \"E06000… \"\"    \"117\" \"Dar…             26    16\n 9 \"E08000… \"\"    \"106\" \"Gat…             12     0\n10 \"E06000… \"\"    \"111\" \"Har…             29     0\n# ℹ 185 more rows\n# ℹ 1 more variable: Female &lt;dbl&gt;\n\n\n\n\nRecodieren von Werten\nAuch bei dem Recodieren von Werten können wir eine mutate-pipeline benutzen.\nFür Kategoriale Daten bietet das tidyverse die case_match-Funktion, die so ähnlich wie die case_when-Funktion funktioniert, die wir ja auch schon kennen. Für numerische Werte funktioniert natürlich weiter case_when oder auch einfache arithmetische Operationen.\n\nWie könnte ich die Anxiety-Skala im satisfaction-Datensatz umpolen?\n\n\n\n\nsatisfaction &lt;- satisfaction %&gt;% \n  mutate(Average_Anxious_Yesterday = -1* (Average_Anxious_Yesterday-10))\n\n\n\nAntwort aufdecken\n\n\n\n\nAufgabe\n\nTransformieren Sie nun die Datensätze in der folgenden Art und Weise:\n\nFassen Sie den Covid-Datensatz so zusammen, dass pro Kalenderwoche eine Summe der jeweils neuen Fälle übrigbleibt. Ersetzen Sie vorher die fehlenden Werte entweder durch Nullen, oder wenn Sie sich eine kleine Herausforderung wünschen, durch die Mittelwerte der jeweiligen Kalenderwoche. Als kleiner Tipp: schauen Sie sich dafür die Hilfeseiten von group_split und map_dfr an.\nFassen Sie den Temperatur-Datensatz bitte auch pro Kalenderwoche zusammen, diesmal aber mit der mittleren Temperatur als Ergebnis\nIm Charts-Datensatz haben sich ein paar unrealistische Platzierungen eingeschlichen. Entfernen Sie diese bitte. Wir wollen für unsere folgenden Analysen pro Lied einen Score benutzen, der zwischen 1 und 0 liegt. Je größer dieser Score ist, desto höher soll der Song platziert gewesen sein und umgekehrt. Rechnen Sie die Position bitte in diesen Score um.\n\n\n\n\n\nTukey, J. W. (1977). Exploratory data analysis (Vol. 2). Reading, Mass.",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "graphics.html",
    "href": "graphics.html",
    "title": "Grammar of Graphics und ggplot2",
    "section": "",
    "text": "Grammar of Graphics\nHadley Wickhams Paket ggplot2 versucht, die Erstellung von Grafiken in einer einheitlichen Grammatik, der “grammar of graphics”, auszudrücken. Das Ziel hier ist es, nicht mehr in “Scatterplot” und “Boxplot” als einzelne Kategorien zu denken und diese einzeln erstellen lernen zu müssen, sondern alle Abbildungen mit derselben Logik erstellen zu können.\nIn Seinem Paper (Wickham, 2010) werden die folgenden Komponenten als grundlegende Bausteine einer Grafik eingeführt:",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#grammar-of-graphics",
    "href": "graphics.html#grammar-of-graphics",
    "title": "Grammar of Graphics und ggplot2",
    "section": "",
    "text": "a default dataset and set of mappings from variables to aesthetics,\none or more layers, with each layer having one geometric object, one statistical trans- formation, one position adjustment, and optionally, one dataset and set of aesthetic mappings,\none scale for each aesthetic mapping used,\na coordinate system,\nthe facet specification. (Wickham, 2010, p. 8)\n\n\n\nKomponenten eines Plots\nWir müssen für einen Plot also überlegen:\n\nwelche Daten wir auf welche Aesthetics mappen\nwelche geometrischen Objekte wir in welcher Reihenfolge auf die Grafik layer wollen und ob diese optionale andere Daten benötigen\nwelche Skala wir für die Mappings nutzen wollen\nwelches Koordinatensystem wir nutzen wollen\nin welchen Facetten wir die Daten darstellen wollen",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#komponenten-in-ggplot2",
    "href": "graphics.html#komponenten-in-ggplot2",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Komponenten in ggplot2",
    "text": "Komponenten in ggplot2\n\nBeispieldaten\n\n\n\n\n\nPinguine im Eis\n\n\n\nIm palmerpenguins-Paket werden Pinguin-Beobachtungen der Palmer-Station in der Antarktis zur Verfügung gestellt:\n\npalmerpenguins::penguins %&gt;% \n  head()\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\n\n1. Daten und Aesthetics - ggplot() + aes()\nWir wollen den Zusammenhang zwischen Körpergewicht und Schnabellänge über die Spezies betrachten. Dafür legen wir die “Leinwand” des Plots mit den zentralen mappings an:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species))\n\n\n\n\n\n\n\n\nDabei können natürlich je nach geom(s), die aufgeschaltet werden, unterschiedliche mappings relevant sein. Welche jeweils nötig sind, lässt sich auf der Hilfeseite des entsprechenden geoms nachlesen.\nBeispiele für mögliche Werte für die meisten mappings lassen sich in der ggplot2-Vignette zum Thema (vignette(\"ggplot2-specs\")) finden.\n\n\n2. Geometrische Objekte - geom_*\nDiesem Plot fügen wir Punkte als geometrische Objekte hinzu, die uns zu einem Scatterplot führen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\n3. Skalen - scale_*\nDie Symbole und Farben haben genau wie x- und y- Koordinaten als ästhetische Mappings eigene Skalen. Wenn uns also die Farben nicht passen, können wir einfach eine andere Skala setzen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point() +\n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\n\n\n4. Koordinatensystem coord_*\nDas Koordinatensystem passt von der Auflösung erstmal, aber wir wollen eine direkte Zuordnung von 10 mm Schnabellänge zu 1000 g Körpermasse. Dazu fügen wir eine coord_*-Spezifikation an:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point() +\n  scale_color_viridis_d()+\n  coord_fixed(ratio = 10/1000)\n\n\n\n\n\n\n\n\n\n\n5. Facetten - facet_*\nAls letzte Komponente überlegen wir uns, dass die verschiedenen Beobachtungspunkte als Einteilung interessant sein könnten und wir diese getrennt betrachten wollen. Mit der facet-Familie können wir den Graphen nach Indel facettieren:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point() +\n  scale_color_viridis_d()+\n  coord_fixed(ratio = 10/1000) +\n  facet_wrap(~island)",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#sec-geoms",
    "href": "graphics.html#sec-geoms",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Einfache Grafiken",
    "text": "Einfache Grafiken\nNeben den dem Point-geom gibt es in ggplot2 natürlich auch so gut wie alle anderen geoms, die für gängige Plots nötig sind. 1\n1 Daneben gibt es einen riesigen Stamm an Paketen, die weniger gängige Plot-Typen als geoms implementieren, z.B. ggwordcloud für wordclouds, ggalluvial für Alluvial und Sankey-Diagramme, ggnet für Netzwerk-Plots und das bei meinen Studis sehr beliebte ggpubr für ‘publication ready plots’. Auf cran sind im Moment 213 Pakete gelistet, die mit “gg” anfangen und ggplot2 imoprtieren oder von ggplot2 abhängig sind.Die folgende Auswahl ist nach dem System des sehr zu empfehlenden Cheat-Sheets von posit zu ggplot2 sortiert und nur ein Bruchteil der in R angelegten geoms.\n\nEine VariableZwei VariablenDrei Variablen\n\n\n\nkontinuierlichdiskret\n\n\nFür die Darstellung einer numerischen Variable bieten Histogramme und ähnliche Darstellungen der Verteilungen einer Variable an.\nIn Abbildung 6.1 sind vier Beispiele, wie sich mit ggplot2 eine numerische Variable darstellen ließe. Alle diese Plots haben den folgenden ggplot-Call als Grundlage:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = flipper_length_mm))\n\n\n\n\n\n\n\n\n\n\n\n\n(a) + geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n(b) + geom_dotplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) + geom_area(stat= ‘bin’)\n\n\n\n\n\n\n\n\n\n\n\n(d) + geom_freqpoly()\n\n\n\n\n\n\n\nAbb 6.1: Eine Auswahl der in ggplot2 angelegten geoms, die die Verteilung einer Variable abbilden.\n\n\n\nAlle vier Beispiele berechnen dabei die bins in die die Beobachtungen einsortiert werden als Standard so, dass 30 Gruppen entstehen.\n\nWelches der auf der geom_histogram()-Hilfeseite genannten Argumente hilft mir am ehesten, die Bin-Breite auf 5mm flipper-Length zu setzen?\n\n\n\n\nbinwidth\nThe width of the bins. Can be specified as a numeric value or as a function that calculates width from unscaled x. Here, “unscaled x” refers to the original x values in the data, before application of any scale transformation. When specifying a function along with a grouping structure, the function will be called once per group. The default is to use the number of bins in bins, covering the range of the data. You should always override this value, exploring multiple widths to find the best to illustrate the stories in your data.\n\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = flipper_length_mm)) +\n  geom_histogram(binwidth=5)\n\n\n\n\n\n\n\n\nIm Hilfetext wird auch die Möglichkeit eines Funktionsaufrufs genannt. Wenn wir zum Beispiel 5% des Abstands zwischen Maximum und Minimum des Wertebereichs als Binwidth setzen wollen, können wir den folgenden Call mit Lambda-Funktion benutzen. Lambda-Funktionen sind anonyme Funktionen, für die in R 4.1.0 die Kurzschreibweise \\(x) &lt;body&gt; statt function(x) &lt;body&gt; eingeführt wurde.\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = flipper_length_mm)) +\n  geom_histogram(binwidth=\\(x) .05 * (max(x, na.rm=T) - min(x, na.rm=T)))\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\n\n\nFür eine diskrete Variable kann mit einem Barchart die Verteilung illustriert werden:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = island)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeide kontinuierlichEine diskret, eine kontinuierlich\n\n\nIn Abbildung 6.2 wird die Basis des geom_point-Blocks aus dem Anfang des ggplot-Abschnitts für alle vier Plots genutzt. Die Basis ist also in jedem Fall der folgende Code-Schnipsel:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g))\n\n\n\n\n\n\n\n\n\n\n\n\n(a) + geom_point()\n\n\n\n\n\n\n\n\n\n\n\n(b) + geom_quantile()\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) + geom_smooth(method = ‘lm’)\n\n\n\n\n\n\n\n\n\n\n\n(d) + geom_rug(sides = ‘bl’)\n\n\n\n\n\n\n\nAbb 6.2: Eine Auswahl der in ggplot2 angelegten geoms, die die Verteilung einer Variable abbilden.\n\n\n\n\n\nTypische Darstellungen, die diskrete und kontinuierliche Variablen kombinieren, sind Darstellungen von Verteilungsvergleichen. Zum Beispiel könnte der Vergleich der Verteilungen der Schnabel-Länge zwischen den Spezies mit folgendem Call angelegt werden:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = species, \n             y = bill_length_mm,\n             color = species))\n\nIn Abbildung 6.3 sind drei Möglichkeiten abgetragen, wie sich diese Basis für eine Darstellung nutzen ließe.\n\n\n\n\n\n\n\n\n\n\n\n(a) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n(b) + geom_dotplot(binaxis = ‘y’, stackdir = ‘center’)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) + geom_violin(scale = ‘area’)\n\n\n\n\n\n\n\nAbb 6.3: Eine Auswahl der in ggplot2 angelegten geoms, die die Verteilung einer Variable abbilden.\n\n\n\nNatürlich lassen sich diese beide Variablen auch mit dem Psychologen-Favourite der Mittelwert-Barcharts darstellen.\nDazu gibt es zwei Möglichkeiten. Entweder wir bauen eine Pipeline, die gruppierte Mittelwerte berechnet und darstellt wie im folgenden Beispiel:\n\npalmerpenguins::penguins %&gt;%\n  group_by(species) %&gt;% \n  summarise(bill_length_mm = mean(bill_length_mm, na.rm = T)) %&gt;% \n  ggplot(aes(x = species, \n             y = bill_length_mm,\n             fill = species)) +\n  geom_col()\n\n\n\n\n\n\n\n\nAlternativ können wir das ggplot-Feature nutzen, Berechnungen im data-Argument eines geoms anzugeben:\n\npalmerpenguins::penguins %&gt;%\n  ggplot(aes(x = species, \n             y = bill_length_mm,\n             fill = species)) +\n  geom_col(data = ~ group_by(.x, species) %&gt;% \n             summarise(bill_length_mm = mean(bill_length_mm, na.rm=T)))\n\n\n\n\n\n\n\n\n\n\n\n\n\nNatürlich sind viele der schon genannten geoms auch nutzbar, um drei Variablen darzustellen. Mit unserem Beispiel vom Anfang hatten wir z.B. ja schon drei Variablen (species, bill_length_mm und body_mass_g) auf jeweils eine “Ästhetische Dimension” gemapped.\nFür zum Beispiel Korrelationsdarstellungen könnte ergänzend aber noch geom_tile ganz interessant sein. Dazu berechnen wir einmal die Korrelation zwischen allen numerischen Variablen in unserem Datensatz:\n\npalmerpenguins::penguins %&gt;% \n  select(where(is.numeric)) %&gt;% \n  cor(., use = 'p')\n\n                  bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\nbill_length_mm        1.00000000   -0.23505287         0.6561813  0.59510982\nbill_depth_mm        -0.23505287    1.00000000        -0.5838512 -0.47191562\nflipper_length_mm     0.65618134   -0.58385122         1.0000000  0.87120177\nbody_mass_g           0.59510982   -0.47191562         0.8712018  1.00000000\nyear                  0.05454458   -0.06035364         0.1696751  0.04220939\n                         year\nbill_length_mm     0.05454458\nbill_depth_mm     -0.06035364\nflipper_length_mm  0.16967511\nbody_mass_g        0.04220939\nyear               1.00000000\n\n\nMit ein bisschen R-Magie machen wir daraus einen ggplot-kompatiblen Datensatz mit den drei Variablen x-Dimension, y-Dimension und Korrelation:\n\n\nCode\nr &lt;- palmerpenguins::penguins %&gt;%\n  select(where(is.numeric)) %&gt;%\n  cor(., use = 'p')\n\nr &lt;- tibble(x = rep(row.names(r), nrow(r)),\n       y = rep(colnames(r), each=nrow(r)),\n       r = c(r))\n\nr\n\n\n# A tibble: 25 × 3\n   x                 y                    r\n   &lt;chr&gt;             &lt;chr&gt;            &lt;dbl&gt;\n 1 bill_length_mm    bill_length_mm  1     \n 2 bill_depth_mm     bill_length_mm -0.235 \n 3 flipper_length_mm bill_length_mm  0.656 \n 4 body_mass_g       bill_length_mm  0.595 \n 5 year              bill_length_mm  0.0545\n 6 bill_length_mm    bill_depth_mm  -0.235 \n 7 bill_depth_mm     bill_depth_mm   1     \n 8 flipper_length_mm bill_depth_mm  -0.584 \n 9 body_mass_g       bill_depth_mm  -0.472 \n10 year              bill_depth_mm  -0.0604\n# ℹ 15 more rows\n\n\nDiese drei Dimensionen können wir mit geom_tile darstellen:\n\nr %&gt;% \n  ggplot(aes(x, y, fill = r)) +\n  geom_tile() \n\n\n\n\n\n\n\n\nAlternativ gibt es selbstverständlich auch ein Paket, das ggplot2-basierte Korrelationsmatrizen darstellt:\n\nr &lt;- palmerpenguins::penguins %&gt;%\n  select(where(is.numeric)) %&gt;%\n  cor(., use = 'p')\n\n\nggcorrplot::ggcorrplot(r)\n\n\n\n\n\n\n\n\n\n\n\n\nAufgabe",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#kombination-mehrerer-geoms",
    "href": "graphics.html#kombination-mehrerer-geoms",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Kombination mehrerer geoms",
    "text": "Kombination mehrerer geoms\nPlots müssen nicht nur aus einem geom bestehen.\nEin möglicher Fall ist der Wunsch nach der Darstellung von Summary-Statistics in Grafiken mit Rohdaten.\nIm Pinguin-Scatter-Plot vom Anfang könnten wir uns zum Beispiel wünschen, die Mittelwerte pro Gruppe darzustellen. Dazu müssen wir zuerst diesen neuen Datensatz berechnen. :\n\npenguin_means &lt;- palmerpenguins::penguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(across(c(bill_length_mm, \n                     body_mass_g), \n                   ~mean(., na.rm=T)))\n\n…und auf den Plot in einem neuen Layer hinzufügen2:\n2 alternativ würde natürlich wieder eine (Lambda-)Funktion im data-Argument funktionieren.\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point() +\n  geom_point(data=penguin_means)+\n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\nFür den Layer können wir dann auch wieder spezifische geometrische Eigenschaften einfügen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point() +\n  geom_point(data=penguin_means, shape = 3)+\n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\nOder direkt ein neues Mapping einführen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original')) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'))+\n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\nUnd auch beide Varianten kombinieren:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3)+\n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\nDie Kombination von mehreren geoms kann außerdem interessant sein, wenn wir verschiedene kombinieren wollen, um mehrere Aspekte abzubilden. So könnte man mehrere der in Einfache Grafiken besprochenen geoms zur Darstellung gleicher Daten auf einem Plot zusammenfügen.\nIn Abbildung 6.4 sind Beispiele dargestellt, die mit dem eingeklappten Chunk erstellt wurden, um mit Hilfe mehrerer geoms mehr Informationen abzubilden.\n\nCode\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = flipper_length_mm, \n             y = bill_length_mm,\n             color = species)) +\n  geom_point(alpha = .5) +\n  geom_smooth(method = 'lm') +\n  geom_quantile(lty = 3)\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = species, \n             y = bill_length_mm,\n             color = species)) +\n  geom_violin(scale = 'area',\n              aes(fill = species),\n              alpha = .25) +\n  geom_boxplot(width = 0.25,\n               position = position_nudge(x = -0.125)) +\n  geom_dotplot(aes(fill = species),\n               binaxis = 'y', \n               stackdir = 'up',\n               dotsize = 0.1)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Zwei kontinuierliche Variablen (+1 diskrete)\n\n\n\n\n\n\n\n\n\n\n\n(b) Je eine diskrete und eine kontinuierliche Variable\n\n\n\n\n\n\n\nAbb 6.4: Abbildungen mit Kombinationen mehrerer geoms",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#mehrere-scales",
    "href": "graphics.html#mehrere-scales",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Mehrere scales",
    "text": "Mehrere scales\nGenauso wie die Verwendung mehrerer geoms, können natürlich auch mehrere Skalen gesetzt werden. So können wir im Scatter-Plot mit den Mittwelwerten zum Beispiel noch die Symbole für die unterschiedlichen dargestellten Daten anpassen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#aufgabe-1",
    "href": "graphics.html#aufgabe-1",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Aufgabe",
    "text": "Aufgabe",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#styling",
    "href": "graphics.html#styling",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Styling",
    "text": "Styling\nggplot2 hat neben den in der Grammar of Graphics beschriebenen Komponenten außerdem noch Gruppen von Funktionen die die Usability verbessern oder die Einstellung zur optischen Erscheinung neben den scales ermöglichen.\nDie wohl wichtigste dieser Funktionen ist die labs-Funktion, mit der sich die Beschriftungen des Graphen anpassen lassen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))+\n  coord_fixed(ratio = 10/1000) +\n  facet_wrap(~island) +\n  labs(x = 'Schnabellänge (mm)',\n       y = 'Körpergewicht (g)',\n       color = 'Pinguin-Spezies',\n       shape = 'Aggregations-Niveau')\n\n\n\n\n\n\n\n\nFür eine top-Level-Anpassung der optischen Erscheinung gibt es außerdem die Familie der theme_ Funktionen. In Abbildung 7.1 ist der Pinguin-Plot von eben mit allen in ggplot2 definierten themes kombiniert.\n\n\n\n\n\n\n\n\n\n\n\n(a) theme_grey\n\n\n\n\n\n\n\n\n\n\n\n(b) theme_bw\n\n\n\n\n\n\n\n\n\n\n\n(c) theme_linedraw\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d) theme_light\n\n\n\n\n\n\n\n\n\n\n\n(e) theme_dark\n\n\n\n\n\n\n\n\n\n\n\n(f) theme_minimal\n\n\n\n\n\n\n\n\n\n\n\n\n\n(g) theme_classic\n\n\n\n\n\n\n\n\n\n\n\n(h) theme_void\n\n\n\n\n\n\n\n\n\n\n\n(i) theme_test\n\n\n\n\n\n\n\nAbb 7.1: Alle in ggplot2 angelegten Themes\n\n\n\nMir gefallen aus dieser Aufstellung “light” und “minimal” am Besten, die anderen sind aber je nach Anlass auch gute Startpunkte.\nUnserem Plot können wir das theme wie alle bisherigen layer hinzufügen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))+\n  labs(x = 'Schnabellänge (mm)',\n       y = 'Körpergewicht (g)',\n       color = 'Pinguin-Spezies',\n       shape = 'Aggregations-Niveau') +\n  theme_light()\n\n\n\n\n\n\n\n\nIn diesem Zusammenhang können wir auch gleich Base-Font und Schriftgröße setzen. theme_light setzt die kleinste Schriftgröße auf .8 mal die base_size3, wenn wir minimal 8pt große Schrift haben wollen, wie es zum Beispiel von der APA gefordert wird. Außerdem lässt sich eine APA-konforme Schriftart auswählen.\n3 Diese Info findet man nicht auf der Hilfeseite, wenn man aber in RStudio eine Funktion markiert und F2 drückt, kann man den Quellcode einsehen. theme_light ist dabei auch ein gutes Beispiel als Ausgangpunkt für ein eigenes theme\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))+\n  labs(x = 'Schnabellänge (mm)',\n       y = 'Körpergewicht (g)',\n       color = 'Pinguin-Spezies',\n       shape = 'Aggregations-Niveau') +\n  theme_light(base_family = 'Helvetica',\n              base_size = 10)\n\n\n\n\n\n\n\n\nFür genauere Kontrolle der optischen Eigenschaften kann die theme-Funktion benutzt werden. Wir kratzen nur mal an der Oberfläche der Möglichkeiten und verschieben die Legende an den unteren Rand des Graphen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))+\n  labs(x = 'Schnabellänge (mm)',\n       y = 'Körpergewicht (g)',\n       color = 'Pinguin-Spezies',\n       shape = 'Aggregations-Niveau') +\n  theme_light(base_family = 'Helvetica',\n              base_size = 10) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\nUm die zu breite Beschriftung zu reparieren nutzen wir die guides-Funktion 4\n4 ggplot2 hat eine ganze Familie an guide_-Funktionen, die unterschiedliche Legenden-Arten und Legenden-Anpassungen bieten - aus Zeitgründen sei hier aber nur auf deren Existenz verwiesen.\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))+\n  labs(x = 'Schnabellänge (mm)',\n       y = 'Körpergewicht (g)',\n       color = 'Pinguin-Spezies',\n       shape = 'Aggregations-Niveau') +\n  theme_light(base_family = 'Helvetica',\n              base_size = 10) +\n  theme(legend.position = 'bottom') +\n  guides(color = guide_legend(nrow = 3),\n         shape = guide_legend(nrow = 2))\n\n\n\n\n\n\n\n\n\nExport\nZum Abschluss wollen wir die Grafiken natürlich exportieren.\nDie Textgröße ist in pt gesetzt, deswegen sollten wir nach dem Export die Größe im besten Fall nicht mehr viel ändern.\nEine Din A4-Seite ist 8.2 x 11.6 Zoll groß. Wenn wir eine Grafik auf 80% der Seitenbreite haben wollen, brauchen wir also eine 6.56 Zoll breite Grafik.\nZum Speichern setzen wir unsere Grafik und die Maße in ggsave ein:\n\np &lt;- palmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))+\n  labs(x = 'Schnabellänge (mm)',\n       y = 'Körpergewicht (g)',\n       color = 'Pinguin-Spezies',\n       shape = 'Aggregations-Niveau') +\n  theme_light(base_family = 'Helvetica',\n              base_size = 10) +\n  theme(legend.position = 'bottom') +\n  guides(color = guide_legend(nrow = 3),\n         shape = guide_legend(nrow = 2))\n\nggsave(plot = p,\n       filename = 'imgs/penguin_scatter.png',\n       width = 6.56,units = 'in')\n\nSaving 6.56 x 5 in image\n\n\nDer Export sieht so aus:\n\n\n\nExportierte Grafik\n\n\nDer Plot ist für meinen Geschmack etwas zu sehr vertikal geraten, das können wir im Export mit “hight” anpassen:\n\nggsave(plot = p,\n       filename = 'imgs/shorter_penguin_scatter.png',\n       width = 6.56, height = 6, units = 'in')\n\n\n\nConvenient Standards\nDie beiden theme-Funktionen müssten wir so an jede Grafik anfügen. Solche Wiederholungen sind schlechter Stil und stören beim Lesen des Skripts, deswegen bietet ggplot2 convenience-Funktionen um allgemeine Einstellungen zu setzen. Mit dem folgenden Snippet am Anfang des Skripts werden die Standards für alle Grafiken genutzt:\n\nmy_theme &lt;-  theme_light(base_family = 'Helvetica',\n              base_size = 10) +\n  theme(legend.position = 'bottom')\n\ntheme_set(my_theme)\n\nSo kann ich jetzt beispielsweise einfach ein eingefärbtes Histogramm für die Flossen-Länge mit den gesetzten Standards erstellen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = flipper_length_mm,\n             fill = sex)) +\n  geom_histogram(binwidth = 5)",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#summary-layer",
    "href": "graphics.html#summary-layer",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Summary-Layer",
    "text": "Summary-Layer\nUm einer Grafik deskriptive Statistiken hinzuzufügen, gibt es mehrere Möglichkeiten. Eine haben wir bereits genutzt, indem wir ein geom erstellt haben, dass einen anderen Wert für das data-Argument5 übergeben bekommt:\n5 Oder halt wieder eine Lambda-Funktion als data-Argument\npenguin_means &lt;- palmerpenguins::penguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(across(c(bill_length_mm, \n                     body_mass_g), \n                   ~mean(., na.rm=T)))\n\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = species, \n             y = body_mass_g,\n             color = species))+ \n  geom_boxplot(alpha = .5) +\n  geom_point(data=penguin_means,\n             size = 3)+\n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\nAuf diese Art und Weise können wir natürlich beliebig viele Statistiken hinzufügen, so zum Beispiel Mittelwerte +/- SEMs und Text, der Anzahl der in die Mittelwerte einfließenden Werte beziffert:\n\npenguin_means &lt;- palmerpenguins::penguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(across(c(bill_length_mm, \n                     body_mass_g), \n                   .fns = list(mean = ~mean(., na.rm=T),\n                               n = ~sum(!is.na(.)),\n                               sem = ~sd(., na.rm = T)/sqrt(sum(!is.na(.))))))\n\npenguin_means %&gt;% \n1  ggplot(aes(color = species,\n                 x = species,\n                 y = body_mass_g_mean)) +\n2  geom_boxplot(data = palmerpenguins::penguins,\n               aes(y = body_mass_g)) +\n  geom_point(size = 3) +\n3  geom_errorbar(aes(ymin = body_mass_g_mean - body_mass_g_sem,\n                     ymax = body_mass_g_mean + body_mass_g_sem),\n                width = 0.5, lty = 2) +\n4  geom_text(aes(label = paste('N =', bill_length_mm_n)),\n5            position = position_nudge(x = 0.175, y = 30),\n            color = 'black') +\n  scale_color_viridis_d()\n\n\n1\n\nDa nur noch der erste geom_point-Layer die Koordinaten aus dem original-Datensatz zieht ist das wirklich einheitliche Mapping auf den gerade erstellten Datensatz bezogen.\n\n2\n\nAlle Layer nach diesem nutzen den erstellten Datensatz - so rum muss nur dem ersten Layer ein extra-Datenargument übergeben werden.\n\n3\n\ngeom_linerange und geom_errorbar brauchen Start- und Endpunkte der Fehlerbalken. Um die Koordinaten zu berechnen, können wir direkt im Mapping eine Funktion, hier den +-Operator aufrufen.\n\n4\n\nMit paste fügen wir den String zusammen.\n\n5\n\nMit position_nudge können wir die labels verschieben. Die genauen Werte kann man durch ausprobieren finden. Oder man nutzt das Paket ggrepel, das genau dieses Problem löst.\n\n\n\n\n\n\n\n\n\n\n\nAb einem bestimmten Punkt werden diese Operationen aber natürlich etwas unübersichtlich. Für diesen Fall bietet ggplot2 die stat_-Layer und die Lambda-Funktionen im data-Argument.\nDerselbe Graph lässt sich damit auch wie folgt erstellen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(color = species,\n                 x = species,\n                 y = body_mass_g)) + \n  geom_boxplot() +\n  stat_summary() +\n  geom_text(data = ~ group_by(., species) %&gt;%  \n              summarise(n = sum(!is.na(body_mass_g)),\n                        body_mass_g = mean(body_mass_g, na.rm = T)),\n            aes(label = paste('N =', n)),\n            position = position_nudge(x = 0.175, y = 30),\n            color = 'black') +\n  scale_color_viridis_d()\n\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n\n\nDieser Graph ist auch ein gutes Beispiel, um Faktoren zur Gruppierung von kategorialen aesthetics zu besprechen.\nNeben den bisher besprochenen atomaren Variablentypen logical, numeric und character gibt es in R noch das etwas speziellere Format der factors.\nfactoren sind kategoriale Variablen, deren levels eine Ordnung zugewiesen werden kann. ggplot2 sortiert kategoriale Variablen erstmal nach Alphabet, Faktor-levels werden aber berücksichtigt.\nWir können uns zum Beispiel wünschen, dass die Spezies in der Reihenfolge Gentoo, Chinstrap, Adelie aufgelistet werden, also genau umgekehrt.\nDazu können wir die species-Variable in einer Pipeline in einen Faktor umwandeln und die levels entsprechend unserer Vorstellung sortieren:\n\npalmerpenguins::penguins %&gt;%\n  mutate(species = factor(species, levels = c('Gentoo', 'Chinstrap', 'Adelie'))) %&gt;% \n  ggplot(aes(color = species,\n                 x = species,\n                 y = body_mass_g)) + \n  geom_boxplot() +\n  stat_summary() +\n  geom_text(data = ~ group_by(., species) %&gt;%  \n              summarise(n = sum(!is.na(body_mass_g)),\n                        body_mass_g = mean(body_mass_g, na.rm = T)),\n            aes(label = paste('N =', n)),\n            position = position_nudge(x = 0.175, y = 30),\n            color = 'black') +\n  scale_color_viridis_d()\n\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n\n\nWie (so gut wie) immer bietet das tidyverse aber auch hier natürlich eine bequemere und felxiblere Lösung.\nMit dem forcats-Paket lassen sich Faktoren mit einer Reihe von Ordnungsfunktionen anordnen:\n\n\n\n\n\n\n\n\n\n\n\n(a) forcats::fct_infreq(species) - nach Anzahl\n\n\n\n\n\n\n\n\n\n\n\n(b) forcats::fct_reorder(species, body_mass_g) - nach Median einer anderen Variable\n\n\n\n\n\n\n\n\n\n\n\n(c) forcats::fct_rev(species) - umgedreht\n\n\n\n\n\n\n\nAbb 7.2: Drei Möglichkeiten, Faktoren mit forcats umzusortieren.\n\n\n\n\nAufgabe",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#hilfreiche-links",
    "href": "graphics.html#hilfreiche-links",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Hilfreiche Links",
    "text": "Hilfreiche Links\n\nfür einen Überblick über alle möglichen Kompenenten empfiehlt sich das von posit herausgegebene cheatsheet\ndas Kapitel zu Datenvisualisierungen in Grolemund & Wickham (2016) ist sehr gut und geht weiter ins Detail als hier möglich ist\nIm Paket ggpubr wird ggplot2 genutzt um eine Reihe von “publication ready plots” zu erstelllen\nUnter diesem Link ist eine shiny-App zur interaktiven Erstellung von ggplot-Graphen zu finden\nUnter diesem Link findet sich eine Sammlung von Farben, Formen, usw., die mit ggplot nutzbar sind.",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#aufgabe-3",
    "href": "graphics.html#aufgabe-3",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Aufgabe",
    "text": "Aufgabe\n\nLese den im Repo zu diesem Skript zur Verfügung gestellten Datensatz example.csv ein. Dazu kann einfach der folgende Chunk genutzt werden:\n\n\nread_csv('https://raw.githubusercontent.com/MBrede/r_thesis_tools/main/data/example.csv')\n\n\nStelle die Reaktionszeiten und Accuracies in einem Scatterplot dar.\nFärbe den Graphen nach Gruppen ein\nFüge Mittelwerte und Standardabweichungen pro Gruppe hinzu. Füge die Standardabweichungen dabei mit geom_linerange in zwei layern hinzu (einem für die x- und einem für die y-Richtung)\nPasse die Grafik so an, dass sie APA-konform ist\nMache die Grafik so unästhetisch, wie es die APA-Richtlinien zulassen. Hier sind Fonts, Farben und Formen zu finden.\n\n\n\n\n\nGrolemund, G., & Wickham, H. (2016). R for Data Science. https://r4ds.had.co.nz/\n\n\nWickham, H. (2010). A layered grammar of graphics. Journal of Computational and Graphical Statistics, 19(1), 3–28.",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "wrangling02.html",
    "href": "wrangling02.html",
    "title": "Zusammenführen von Datensätzen",
    "section": "",
    "text": "Aufgabe\nFügen Sie den Covid und den Temperatur-Datensatz anhand der Kalenderwoche zusammen. Dabei sollen alle Zeilen, die im Temperatur-Datensatz vorliegen auch im neuen Datensatz vorliegen. Ersetzen Sie anschließend alle möglicherweise vorliegenden fehlenden Werte durch Nullen.\nBenennen Sie abschließend die Kalender-Wochen-Spalte in calendar_week und die Fall-Spalte im new_covid_cases um.\nSpeichern Sie sich den so erstellten Datensatz für später als ‘temp_covid.csv’ ab und den vorbereiteten Charts-Datensatz unter ‘chart_overview.csv’ ab.",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Zusammenführen von Datensätzen</span>"
    ]
  },
  {
    "objectID": "wrangling02.html#pivotieren-von-datensätzen",
    "href": "wrangling02.html#pivotieren-von-datensätzen",
    "title": "Zusammenführen von Datensätzen",
    "section": "Pivotieren von Datensätzen",
    "text": "Pivotieren von Datensätzen\nFür SPSS-Nutzer:innen sehen viele Datensätze, die wir bisher gesehen haben, wahrscheinlich etwas seltsam aus. Das liegt vielleicht zum Teil daran, dass das tidyverse grundsätzlich das long-Format dem wide-Format vorzieht.\nDas folgende Beispiel der Ergebnisse der Bundestagswahlen nach 2002 1 illustriert vielleicht den Unterschied. Im wide-Format ist das zentrale Ziel dass pro Fall eine Zeile vorliegt, im long-Format wird pro Variable eine Spalte angelegt.\n1 gekürzt von https://www.bundestag.de/parlament/wahlen/ergebnisse_seit1949-244692\n\nlong-Format\n\n\n# A tibble: 35 × 3\n    Jahr Partei                Zweitstimmen\n   &lt;int&gt; &lt;chr&gt;                        &lt;dbl&gt;\n 1  2021 CDU/CSU                       24.1\n 2  2021 SPD                           25.7\n 3  2021 FDP                           11.5\n 4  2021 Bündnis 90/Die Grünen         14.8\n 5  2021 Die Linke. PDS                 4.9\n 6  2021 AfD                           10.3\n 7  2021 Sonstige                       8.7\n 8  2017 CDU/CSU                       32.9\n 9  2017 SPD                           20.5\n10  2017 FDP                           10.7\n# ℹ 25 more rows\n\n\n\nwide-Format\n\n\n# A tibble: 5 × 8\n   Jahr `CDU/CSU`   SPD   FDP\n  &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  2021      24.1  25.7  11.5\n2  2017      32.9  20.5  10.7\n3  2013      41.5  25.7   4.8\n4  2009      33.8  23    14.6\n5  2005      35.2  34.2   9.8\n# ℹ 4 more variables:\n#   `Bündnis 90/Die Grünen` &lt;dbl&gt;,\n#   `Die Linke. PDS` &lt;dbl&gt;, AfD &lt;dbl&gt;,\n#   Sonstige &lt;dbl&gt;\n\n\n\n\nBeide Formate haben Vorteile, im tidyverse ist das Hauptargument (neben Geschmaack) für das long-Format, dass sich so vektorisierte Funktionen direkt auf eine Variable anwenden lassen.\nUm zwischen den Formaten zu konvertieren gibt es im tidyverse die pivot_wider und pivot_longer Funktionen.\nDer Original-Datensatz zu den Bundestagswahlen sieht wie folgt aus:\n\nbundestagswahl\n\n# A tibble: 20 × 8\n    Jahr `CDU/CSU`   SPD   FDP\n   &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  2021      24.1  25.7  11.5\n 2  2017      32.9  20.5  10.7\n 3  2013      41.5  25.7   4.8\n 4  2009      33.8  23    14.6\n 5  2005      35.2  34.2   9.8\n 6  2002      38.5  38.5   7.4\n 7  1998      35.2  40.9   6.2\n 8  1994      41.5  36.4   6.9\n 9  1990      43.8  33.5  11  \n10  1987      44.3  37     9.1\n11  1983      48.8  38.2   7  \n12  1980      44.5  42.9  10.6\n13  1976      48.6  42.6   7.9\n14  1972      44.9  45.8   8.4\n15  1969      46.1  42.7   5.8\n16  1965      47.6  39.3   9.5\n17  1961      45.3  36.2  12.8\n18  1957      50.2  31.8   7.7\n19  1953      45.2  28.8   9.5\n20  1949      31    29.2  11.9\n# ℹ 4 more variables:\n#   `Bündnis 90/Die Grünen` &lt;dbl&gt;,\n#   `Die Linke. PDS` &lt;dbl&gt;, AfD &lt;dbl&gt;,\n#   Sonstige &lt;dbl&gt;\n\n\nWir würden gern eine ggplot-Grafik erstellen, in der die Verläufe der Stimmen über die Zeit dargestellt sind. Da wir alle Zweitstimmen-Prozente auf einem aesthetic darstellen wollen, brauchen wir den Datensatz aber natürlich im long-Format\nDas pivotieren geht mit pivot_longer auch sehr einfach:\n\nbtw_long &lt;- bundestagswahl %&gt;% \n  pivot_longer(-Jahr,\n               names_to = 'Partei',\n               values_to = 'Zweitstimmen')\nbtw_long\n\n# A tibble: 140 × 3\n    Jahr Partei                Zweitstimmen\n   &lt;int&gt; &lt;chr&gt;                        &lt;dbl&gt;\n 1  2021 CDU/CSU                       24.1\n 2  2021 SPD                           25.7\n 3  2021 FDP                           11.5\n 4  2021 Bündnis 90/Die Grünen         14.8\n 5  2021 Die Linke. PDS                 4.9\n 6  2021 AfD                           10.3\n 7  2021 Sonstige                       8.7\n 8  2017 CDU/CSU                       32.9\n 9  2017 SPD                           20.5\n10  2017 FDP                           10.7\n# ℹ 130 more rows\n\n\n\nWie erstelle ich damit jetzt einen line-chart?\n\n\n\n\nbtw_long %&gt;% \n  ggplot(aes(x = Jahr, y = Zweitstimmen, color = Partei)) +\n  geom_line(linewidth = 0.7) +\n  scale_color_manual(values = c(AfD = '#0489DB',\n                                'Bündnis 90/Die Grünen' = '#1AA037',\n                                CDU = '#000000',\n                                'Die Linke. PDS' = '#BD3075',\n                                FDP = '#FFEF00',\n                                Sonstige = 'darkgrey',\n                                SPD = '#E3000F'\n                                ))\n\nScale for colour is already present.\nAdding another scale for colour, which will\nreplace the existing scale.\n\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\nZu dieser Grafik wollen wir noch Mittlere Werte über die Zeit +/- Streuungen als Linien hinzufügen.\n\nWie ginge das denn mit summarise und across? Und wie könnte ich die Linien hinzufügen?\n\n\n\n\nbtw_summary &lt;- btw_long %&gt;% \n  group_by(Partei) %&gt;% \n  summarise('M' = mean(Zweitstimmen, na.rm=T),\n            'SD' = sd(Zweitstimmen, na.rm=T),\n            lower = M - SD,\n            upper = M + SD)\n\nDen Datensatz können wir jetzt benutzen:\n\nbtw_long %&gt;% \n  ggplot(aes(x = Jahr, y = Zweitstimmen, color = Partei)) +\n  geom_line(linewidth = 0.7) +\n  geom_hline(data = btw_summary,\n             aes(yintercept = M, color = Partei))+\n  geom_hline(data = btw_summary,\n             aes(yintercept = lower, color = Partei),\n             lty = 2)+\n  geom_hline(data = btw_summary,\n             aes(yintercept = upper, color = Partei),\n             lty = 2)+\n  scale_color_manual(values = c(AfD = '#0489DB',\n                                'Bündnis 90/Die Grünen' = '#1AA037',\n                                'CDU/CSU' = '#000000',\n                                'Die Linke. PDS' = '#BD3075',\n                                FDP = '#FFEF00',\n                                Sonstige = 'darkgrey',\n                                SPD = '#E3000F'\n                                )) \n\nScale for colour is already present.\nAdding another scale for colour, which will\nreplace the existing scale.\n\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\nUnter der Grafik wollen wir zum Schluss noch die Mittelwerte pro Partei hintereinander als Spalten darstellen. Das heißt, wir müssen die Tabelle ins wide-Format überführen. Auch dieser Schritt ist relativ einfach:\n\nbtw_summary %&gt;% \n  select(Partei, M) %&gt;% \n  pivot_wider(values_from = M,\n              names_from = Partei,\n              names_prefix = 'M ')\n\n# A tibble: 1 × 7\n  `M AfD` `M Bündnis 90/Die Grünen` `M CDU/CSU`\n    &lt;dbl&gt;                     &lt;dbl&gt;       &lt;dbl&gt;\n1     9.2                       8.3        41.2\n# ℹ 4 more variables: `M Die Linke. PDS` &lt;dbl&gt;,\n#   `M FDP` &lt;dbl&gt;, `M SPD` &lt;dbl&gt;,\n#   `M Sonstige` &lt;dbl&gt;\n\n\nDie pivot_wider-Funktion ist aber wesentlich mächtiger, was wir zum Beispiel sehen können wenn wir die Streuungen mit hinzufügen:\n\nbtw_summary %&gt;% \n  select(Partei, M, SD) %&gt;% \n  pivot_wider(values_from = c(M, SD),\n              names_from = Partei,\n              names_glue = '{.value} {Partei}')\n\n# A tibble: 1 × 14\n  `M AfD` `M Bündnis 90/Die Grünen` `M CDU/CSU`\n    &lt;dbl&gt;                     &lt;dbl&gt;       &lt;dbl&gt;\n1     9.2                       8.3        41.2\n# ℹ 11 more variables: `M Die Linke. PDS` &lt;dbl&gt;,\n#   `M FDP` &lt;dbl&gt;, `M SPD` &lt;dbl&gt;,\n#   `M Sonstige` &lt;dbl&gt;, `SD AfD` &lt;dbl&gt;,\n#   `SD Bündnis 90/Die Grünen` &lt;dbl&gt;,\n#   `SD CDU/CSU` &lt;dbl&gt;,\n#   `SD Die Linke. PDS` &lt;dbl&gt;, `SD FDP` &lt;dbl&gt;,\n#   `SD SPD` &lt;dbl&gt;, `SD Sonstige` &lt;dbl&gt;\n\n\nDie letzte Tabelle ließe sich natürlich auch direkt aus dem Ursprünglichen Datensatz erstellen…\n\nWie ginge das direkt mit summarise und across?\n\n\n\n\nbundestagswahl %&gt;% \n  summarise(across(-Jahr, \n                   .fns = list(mean = ~mean(., na.rm=T),\n                               sd = ~sd(., na.rm=T))))\n\n# A tibble: 1 × 14\n  `CDU/CSU_mean` `CDU/CSU_sd` SPD_mean SPD_sd\n           &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1           41.2         7.00     34.6   7.22\n# ℹ 10 more variables: FDP_mean &lt;dbl&gt;,\n#   FDP_sd &lt;dbl&gt;,\n#   `Bündnis 90/Die Grünen_mean` &lt;dbl&gt;,\n#   `Bündnis 90/Die Grünen_sd` &lt;dbl&gt;,\n#   `Die Linke. PDS_mean` &lt;dbl&gt;,\n#   `Die Linke. PDS_sd` &lt;dbl&gt;, AfD_mean &lt;dbl&gt;,\n#   AfD_sd &lt;dbl&gt;, Sonstige_mean &lt;dbl&gt;, …\n\n\n\n\nAntwort aufdecken\n\n\n\nAufgabe\n\nDatensatz hin pivotieren, Grafik machen, her-pivotieren",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Zusammenführen von Datensätzen</span>"
    ]
  },
  {
    "objectID": "tidymodels.html",
    "href": "tidymodels.html",
    "title": "tidymodels",
    "section": "",
    "text": "Engines und Modelle",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>tidymodels</span>"
    ]
  },
  {
    "objectID": "tidymodels.html#datenaufbereitng-mit-recipes",
    "href": "tidymodels.html#datenaufbereitng-mit-recipes",
    "title": "tidymodels",
    "section": "Datenaufbereitng mit recipes",
    "text": "Datenaufbereitng mit recipes",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>tidymodels</span>"
    ]
  },
  {
    "objectID": "tidymodels.html#inferenzstatistik-pipelines-mit-infer",
    "href": "tidymodels.html#inferenzstatistik-pipelines-mit-infer",
    "title": "tidymodels",
    "section": "Inferenzstatistik-Pipelines mit infer",
    "text": "Inferenzstatistik-Pipelines mit infer",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>tidymodels</span>"
    ]
  },
  {
    "objectID": "quarto.html",
    "href": "quarto.html",
    "title": "Methodenteil in quarto",
    "section": "",
    "text": "Code-chunks\nDer große Vorteil quartos ist es, dass wir Code-chunks im Dokument anlegen können, deren Output direkt in das gerenderte Ergebnis eingebunden wird.\nDazu kann mit der “Insert new code chunk”-Schaltfläche (1 in Abbildung 8.3) oben rechts oder Strg + Alt + I ein neuer Chunk eingefügt werden, der an die Cursor-Stelle im Dokument eingefügt wird (2).\nIn der ersten Zeile des neuen Chunks steht die Sprache. In den Chunk kann dann wie in ein R-Skript Code eingefügt werden.\nDamit haben wir die Basics die wir brauchen.",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Methodenteil in `quarto`{#sec-quarto}</span>"
    ]
  },
  {
    "objectID": "quarto.html#code-chunks",
    "href": "quarto.html#code-chunks",
    "title": "Methodenteil in quarto",
    "section": "",
    "text": "Abb 8.3: Neuen Chunk erstellen.\n\n\n\n\n\n\n\n\n\n\n\n\nAbb 8.4: Code Chunks mit bisherigen Analysen.\n\n\n\n\nIn Abbildung 8.4 ist das neue file mit dem Code für die letzte Tabelle aus Erstellung von APA-konformen Tabellen und der Beispielgrafik aus ?sec-ggplot eingefügt.\nDer erste Chunk (1) ist dabei nur dafür da um Pakete und die Daten zu laden. Im zweiten Chunk (2) wird die Tabelle, im dritten Chunk (3) die Grafik erstellt. Der Text hinter dem r in der ersten Zeile der Chunks ist nur ein Titel und hat erstmal keine weitere Bedeutung.\nWie in (4) und (5) zu sehen ist, kann zwischen den Chunks einfach Text eingefügt werden.\nDie Chunks können dabei wie ein ganz normales R-Skript genutzt werden und der Code an der Zeile des Cursors kann mit Strg + Enter ausgeführt werden. Der Output erscheint dabei unter dem Chunk, kann mit Hilfe der Einstellungen aber auch in die Konsole verschoben werden.",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Methodenteil in `quarto`{#sec-quarto}</span>"
    ]
  },
  {
    "objectID": "quarto.html#yaml-header",
    "href": "quarto.html#yaml-header",
    "title": "Methodenteil in quarto",
    "section": "YAML-Header",
    "text": "YAML-Header\nUm das Ergebnis des Renderns anzupassen können wir den YAML-Header setzen.\nFür dieses Skript konzentrieren wir uns auf Output im docx-Format, Quarto bietet aber wesentlich mehr Optionen. Die Doku für alle unterstützten Header-Optionen für docx findet sich hier.\nFür uns sind erstmal die folgenden Parameter wichtig:\nformat: docx # setzt das Format des Outputs\nfig-width: 6.56 # setzt 6.56 Zoll als Standard-Breite für alle Plot-Outputs\nfig-dpi: 300 # setzt alle plots auf 300 dpi\nNach Klick auf “Render” kann ich neben dem erstellten qmd-file das in Abbildung 8.5 abgebildete Dokument finden.\n\n\n\n\n\n\nAbb 8.5: Erstes Render-Ergebnis.\n\n\n\nDer Output der Chunks wurde also erfolgreich in das Dokument übergeben, ich brauche aber die ganzen messages nicht.\nUm diese zu unterdrücken kann ich den YAML-Header einfach um den folgenden Teil ergänzen:\nexecute:\n  warning: false\n  message: false\nWas zu folgendem Output führt:\n Schon viel besser, für einen Methodenteil stört aber noch der Code zwischen den Outputs. Um das rausschreiben der Chunks zu unterdrücken ergänzen wir nur noch echo: false um bei folgendem vollständigen Header zu enden:\ntitle: \"Methoden\"\neditor: visual\nformat: docx\nfig-width: 6.56\nfig-dpi: 300\nexecute:\n  warning: false\n  message: false\n  echo: false\nUnd schon ist das Ergebnis nicht mehr allzu schlecht:\n\n\n\n\n\n\nAbb 8.6: Ergebnis ohne Chunks",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Methodenteil in `quarto`{#sec-quarto}</span>"
    ]
  },
  {
    "objectID": "quarto.html#code-chunk-optionen",
    "href": "quarto.html#code-chunk-optionen",
    "title": "Methodenteil in quarto",
    "section": "Code-Chunk-Optionen",
    "text": "Code-Chunk-Optionen\nDie letzten drei Parameter waren Beispiele für chunk-Optionen, die das Verhalten von Chunks anpassen. Das kann entweder global im YAML-Header unter execute oder lokal pro Chunk gesetzt werden.\nAuf der quarto-Seite gibt es einen Überblick über alle Optionen, wir konzentrieren uns aber erstmal auf einen kleinen Teil zur Beschriftung von Grafiken und Tabellen.\nUm eine Grafik zu beschriften und im Text referenzierbar zu machen,müssen wir zwei Optionen für den Chunk setzten: label und fig-cap. In Abbildung 8.7 ist ein Beispiel wie das aussehen könnte. Die Chunk-Optionen werden dabei immer durch ein so genanntes “pipe-comment” eingeleitet.\n\n\n\n\n\n\nAbb 8.7: Chunk-Optionen für Grafiken\n\n\n\nIm text können wir die Grafik dann mit @fig-scatter referenzieren. Das label für Grafiken muss dabei durch “fig-” eingeleitet und referenziert werden, sonst schlägt die Formatierung fehl.\nÄhnliche Parameter sind auch für Tabellen implementiert, hier ist der Prefix nur tbl. Leider funktioniert das Crossreferenzieren in den aktuellen Versionen von quarto und flextable noch nicht reibungslos, es gibt aber einen workaround.\nStatt mit @tbl-table müssen wir die Tabelle mit einem Call an das officer-Paket im Text referenzieren. Sonst ist das Format aber ähnlich, wie in Abbildung 8.8 zu sehen ist..\n\n\n\n\n\n\nAbb 8.8: Chunk-Optionen für Tabellen\n\n\n\nDer Output des so angepassten Skripts ist in Abbildung 8.9 zu sehen.\n\n\n\n\n\n\nAbb 8.9: Ergebnis mit Corss-Referenzen\n\n\n\nOffensichtlich funktioniert auch der Workaround noch nicht perfekt - das Problem ist aber bekannt.\nIn dem Beispiel haben wir aber einen weiteren Vorteil von Quarto gesehen: Inline Code-Chunks",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Methodenteil in `quarto`{#sec-quarto}</span>"
    ]
  },
  {
    "objectID": "quarto.html#sec-inline",
    "href": "quarto.html#sec-inline",
    "title": "Methodenteil in quarto",
    "section": "Inline Code-Chunks",
    "text": "Inline Code-Chunks\nIm Fließtext kann mit der folgenden Syntax auf R zugegriffen und Output generiert werden:\n`r &lt;some code&gt;`\nWozu ist das nützlich? Wir können so einfach statistische Kennwerte ohne sie kopieren zu müssen in den Text einflißen lassen! Und jedes mal wenn das Ergebnis erstellt wird, werden die Werte neu berechnet. So kann keine Aktualisierung vergessen werden.\nWir könnten unserem Beispiel-File so beispielsweise eine Stichprobenbeschreibung hinzufügen, wie in Abbildung 8.10 zu sehen ist.\n\n\n\n\n\n\nAbb 8.10: Inline Chunk\n\n\n\nDie Ergebnisse im docx können in Abbildung 8.11 gesehen werden.\n\n\n\n\n\n\nAbb 8.11: Gerendertes Ergebnis der Inline-Chunks\n\n\n\nDas hier gezeigte Beispiel ist auch im Repo des Skripts zugänglich.",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Methodenteil in `quarto`{#sec-quarto}</span>"
    ]
  },
  {
    "objectID": "quarto.html#aufgabe",
    "href": "quarto.html#aufgabe",
    "title": "Methodenteil in quarto",
    "section": "Aufgabe",
    "text": "Aufgabe\n\nÜbertrage Deine Ergebnisse aus den anderen Aufgaben in ein quarto-Dokument\nBeschrifte alle Grafiken und Tabellen.\nRender das Dokument als docx.",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Methodenteil in `quarto`{#sec-quarto}</span>"
    ]
  },
  {
    "objectID": "quarto.html#zusammenarbeit",
    "href": "quarto.html#zusammenarbeit",
    "title": "Methodenteil in quarto",
    "section": "Zusammenarbeit",
    "text": "Zusammenarbeit\nDer größte Nachteil an Quarto ist der etwas umständlichere Workflow beim Kommentieren und Zusammenarbeiten als das in Word möglich ist.\nDie Dokumente können zwar immer in word gerendert und dann ausgetauscht werden, etwaige Anmerkungen können aber nicht direkt in Quarto eingepflegt werden.\nUnter diesem Link findet Ihr aber eine Anleitung, wie man die Zusammenarbeit über git ermöglichen kann.",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Methodenteil in `quarto`{#sec-quarto}</span>"
    ]
  },
  {
    "objectID": "tables.html",
    "href": "tables.html",
    "title": "Erstellung von APA-konformen Tabellen",
    "section": "",
    "text": "Export mit apaTables\nWie am Anfang gesagt wollen wir möglichst vermeiden, Tabellen und Daten a) händisch zu übertragen und b) zu formatieren.\nIm besten Fall exportieren wir also alles was an Zahlen und Tabellen für den Text anfällt direkt in files, die wir einfach einbinden können.\nFür die ANOVAs, Regressionen, t-Tests und Korrelationsanalysen gibt es im apaTables-Paket fertige Wrapper, die einen direkten Export der Tabellen ins RTF-Format umsetzen.\nUnter den folgenden Links findet Ihr die Dokumentation der einzelnen Funktionen aufgelistet:\nAußerdem sind im Tutorial Beispiele für alle implementierten Verfahren und Tabellen zu finden.\nWir können zum Beispiel mit ezAnova eine Varianzanalyse für unsere Pinguine durchführen, bei der wir Pinguin-Geschlecht und Spezies als UVs und die Flossenlänge als AV nutzen:\nlibrary(ez)\n\npalmerpenguins::penguins %&gt;% \n  mutate(id = seq_along(species)) %&gt;% \n  filter(!is.na(flipper_length_mm)) %&gt;% \n  ezANOVA(wid = id,\n          between = .(species, sex),\n          dv = flipper_length_mm,\n          detailed = T,\n          type = 2)\n\nWarning: Converting \"id\" to factor for ANOVA.\n\n\nWarning: You have removed one or more levels from variable \"sex\". Refactoring\nfor ANOVA.\n\n\nWarning: Data is unbalanced (unequal N per group). Make sure you specified a\nwell-considered value for the type argument to ezANOVA().\n\n\nCoefficient covariances computed by hccm()\n\n\n$ANOVA\n       Effect DFn DFd        SSn      SSd          F             p p&lt;.05\n1     species   2 327 50185.0266 10458.11 784.582911 1.569568e-125     *\n2         sex   1 327  3905.6038 10458.11 122.118894  2.461150e-24     *\n3 species:sex   2 327   329.0425 10458.11   5.144186  6.314424e-03     *\n         ges\n1 0.82754673\n2 0.27190772\n3 0.03050319\n\n$`Levene's Test for Homogeneity of Variance`\n  DFn DFd      SSn    SSd        F          p p&lt;.05\n1   5 327 141.5881 3845.9 2.407723 0.03652301     *\nMit apa.ezANOVA.table können gewünschte Tabellen dann exportiert werden. Laut der Doku ist dabei noch wichtig, mit options eine Anzahl an Dezimalstellen vor Umwandlung in 10-er-Potenz-Notation zu setzen, die mindestens 10 ist.\nlibrary(apaTables)\noptions(digits = 10)\n\npalmerpenguins::penguins %&gt;%\n  mutate(id = seq_along(species)) %&gt;%\n  filter(!is.na(flipper_length_mm)) %&gt;%\n  ezANOVA(\n    wid = id,\n    between = .(species, sex),\n    dv = flipper_length_mm,\n    detailed = T,\n    type = 2\n  ) %&gt;%\n  apa.ezANOVA.table(drink_attitude_results,\n                    table.number = 1,\n                    filename = \"Table1_APA.doc\")\n\nWarning: Converting \"id\" to factor for ANOVA.\n\n\nWarning: You have removed one or more levels from variable \"sex\". Refactoring\nfor ANOVA.\n\n\nWarning: Data is unbalanced (unequal N per group). Make sure you specified a\nwell-considered value for the type argument to ezANOVA().\n\n\nCoefficient covariances computed by hccm()\n\n\n\n\nTable 1 \n\nANOVA results\n \n\n     Predictor df_num df_den   SS_num   SS_den      F    p ges\n       species      2    327 50185.03 10458.11 784.58 .000 .83\n           sex      1    327  3905.60 10458.11 122.12 .000 .27\n species x sex      2    327   329.04 10458.11   5.14 .006 .03\n\nNote. df_num indicates degrees of freedom numerator. df_den indicates degrees of freedom denominator. \nSS_num indicates sum of squares numerator. SS_den indicates sum of squares denominator. \nges indicates generalized eta-squared.\nDas table_number-Argument setzt dabei nur die Zahl in der Tabellen-Überschrift.\nDas Ergebnis ist in Abbildung 9.1 zu sehen.\nDas ist natürlich schon schön und praktisch wenn wir uns englische Tabellen für die implementierten Analysen ausgeben lassen wollen. Aber wie können wir eigene Tabellen nach APA-Richtlinien-konform exportieren?",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Erstellung von APA-konformen Tabellen</span>"
    ]
  },
  {
    "objectID": "tables.html#export-mit-apatables",
    "href": "tables.html#export-mit-apatables",
    "title": "Erstellung von APA-konformen Tabellen",
    "section": "",
    "text": "Korrelationsanalyse\nANOVA mit ezANOVA\nRegressionsanalyse\nZusammenfassungstabelle für deskriptive Maße, 1 Faktor\nZusammenfassungstabelle für deskriptive Maße, 2 Faktoren\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbb 9.1: Output von apa.ezANOVA.table",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Erstellung von APA-konformen Tabellen</span>"
    ]
  },
  {
    "objectID": "tables.html#tabellen-mit-flextable",
    "href": "tables.html#tabellen-mit-flextable",
    "title": "Erstellung von APA-konformen Tabellen",
    "section": "Tabellen mit flextable",
    "text": "Tabellen mit flextable\nWas sind die Anforderungen an Tabellen laut APA? Konsultieren wir nochmal Julias1 Folien (Abbildung 9.2).\n1 Nochmal Danke, Julia!\n\n\n\n\n\nAbb 9.2: Checklist für Tabellen aus Julias Folien\n\n\n\nUnsere Tabellen müssen also die folgenden Anforderungen erfüllen:\n\nJede Spalte muss eine Überschrift haben\ndie Überschriften müssen zentriert sein\n\nAußerdem kommen noch die folgenden Anforderungen an die Formatierung statistischer Ergebnisse2 hinzu:\n2 laut https://apastyle.apa.org/style-grammar-guidelines/tables-figures/tables und https://www.scribbr.com/apa-style/numbers-and-statistics/\nNamen statistischer Kennwerte sollen kursiv sein\nZahlen sollen auf den Wert gerundet werden, bei dem Präzision erhalten wird\nWerte die nicht größer als 1 werden können sollen keine Null vor dem Komma haben\n\nFangen wir mit der Formatierung der Nummern an. Als Beispiel haben wir die folgende Tabelle, in der die mittlere Schnabellänge und Standardabweichung pro Pinguin-Spezies und Beobachtungsort abgetragen sind:\n\nsummary_table &lt;- palmerpenguins::penguins %&gt;%\n  group_by(species, island) %&gt;%\n  summarise(across(matches(\"bill_length_mm\"),\n                   .fns = list(\n                     M = \\(x) mean(x, na.rm = T),\n                     SD = \\(x) sd(x, na.rm = T)\n                   ),\n                   .names = \"{.col}_{.fn}\")) %&gt;% # Damit Funktion hinten steht\n  pivot_wider(names_from = 'island',\n              values_from = 3:4,\n              names_glue = \"{island}_{.value}\") # Damit Insel vorne steht\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\nsummary_table\n\n# A tibble: 3 × 7\n# Groups:   species [3]\n  species   Biscoe_bill_length_m…¹ Dream_bill_length_mm_M Torgersen_bill_lengt…²\n  &lt;fct&gt;                      &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n1 Adelie                      39.0                   38.5                   39.0\n2 Chinstrap                   NA                     48.8                   NA  \n3 Gentoo                      47.5                   NA                     NA  \n# ℹ abbreviated names: ¹​Biscoe_bill_length_mm_M, ²​Torgersen_bill_length_mm_M\n# ℹ 3 more variables: Biscoe_bill_length_mm_SD &lt;dbl&gt;,\n#   Dream_bill_length_mm_SD &lt;dbl&gt;, Torgersen_bill_length_mm_SD &lt;dbl&gt;\n\n\nZuerstmal sortieren wir die Spalten so, dass Pro Ort erst Mittelwert, dann SD steht:\n\nsummary_table %&gt;% \n  select(species, matches('Bis'), matches('Dre'), matches('Tor'))\n\n# A tibble: 3 × 7\n# Groups:   species [3]\n  species   Biscoe_bill_length_m…¹ Biscoe_bill_length_m…² Dream_bill_length_mm_M\n  &lt;fct&gt;                      &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n1 Adelie                      39.0                   2.48                   38.5\n2 Chinstrap                   NA                    NA                      48.8\n3 Gentoo                      47.5                   3.08                   NA  \n# ℹ abbreviated names: ¹​Biscoe_bill_length_mm_M, ²​Biscoe_bill_length_mm_SD\n# ℹ 3 more variables: Dream_bill_length_mm_SD &lt;dbl&gt;,\n#   Torgersen_bill_length_mm_M &lt;dbl&gt;, Torgersen_bill_length_mm_SD &lt;dbl&gt;\n\n\nDann legen wir die Dezimalstellen auf eine Nachkommastelle fest:\n\nsummary_table %&gt;% \n  select(species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1)))\n\n# A tibble: 3 × 7\n# Groups:   species [3]\n  species   Biscoe_bill_length_m…¹ Biscoe_bill_length_m…² Dream_bill_length_mm_M\n  &lt;fct&gt;                      &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n1 Adelie                      39                      2.5                   38.5\n2 Chinstrap                   NA                     NA                     48.8\n3 Gentoo                      47.5                    3.1                   NA  \n# ℹ abbreviated names: ¹​Biscoe_bill_length_mm_M, ²​Biscoe_bill_length_mm_SD\n# ℹ 3 more variables: Dream_bill_length_mm_SD &lt;dbl&gt;,\n#   Torgersen_bill_length_mm_M &lt;dbl&gt;, Torgersen_bill_length_mm_SD &lt;dbl&gt;\n\n\nUnd schon können wir an die eigentliche Formatierung in einer Tabelle gehen. Dazu nutzen wir das Paket flextable.\nWir können unsere Tabelle direkt in flextable pipen:\n\nlibrary(flextable)\n\n\nAttaching package: 'flextable'\n\n\nThe following object is masked from 'package:purrr':\n\n    compose\n\nsummary_table %&gt;% \n  select(species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  flextable()\n\nspeciesBiscoe_bill_length_mm_MBiscoe_bill_length_mm_SDDream_bill_length_mm_MDream_bill_length_mm_SDTorgersen_bill_length_mm_MTorgersen_bill_length_mm_SDAdelie39.02.538.52.5393Chinstrap48.83.3Gentoo47.53.1\n\n\nAls erstes können wir den Header trennen:\n\nsummary_table %&gt;% \n  select(species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  flextable() %&gt;% \n  separate_header()\n\nspeciesBiscoeDreamTorgersenbilllengthmmMSDMSDMSDAdelie39.02.538.52.5393Chinstrap48.83.3Gentoo47.53.1\n\n\nDie bill-length kann weg, am besten entfernen wir die schon vor der Umwandlung in eine flextable:\n\nsummary_table %&gt;% \n  select(species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  rename_with(.fn = ~str_remove(.,'bill_length_mm')) %&gt;% \n  flextable() %&gt;% \n  separate_header()\n\nspeciesBiscoeDreamTorgersenMSDMSDMSDAdelie39.02.538.52.5393Chinstrap48.83.3Gentoo47.53.1\n\n\n“Spezies” können wir auch in deutsch übertiteln:\n\nsummary_table %&gt;% \n  select(Spezies = species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  rename_with(.fn = ~str_remove(.,'_bill_length_mm')) %&gt;% \n  flextable() %&gt;% \n  separate_header()\n\nSpeziesBiscoeDreamTorgersenMSDMSDMSDAdelie39.02.538.52.5393Chinstrap48.83.3Gentoo47.53.1\n\n\nUnd die statistischen Kennwerte kursiv setzen:\n\nsummary_table %&gt;% \n  select(Spezies = species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  rename_with(.fn = ~str_remove(.,'_bill_length_mm')) %&gt;% \n  flextable() %&gt;% \n  separate_header() %&gt;% \n  style(i = 2,part = 'header',\n        pr_t = fp_text_default(italic = T))\n\nSpeziesBiscoeDreamTorgersenMSDMSDMSDAdelie39.02.538.52.5393Chinstrap48.83.3Gentoo47.53.1\n\n\nIm flextable-Paket gibt es außerdem die theme_apa-Funktion, die den Text und die Abstände nach APA formatiert:\n\nsummary_table %&gt;% \n  select(Spezies = species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  rename_with(.fn = ~str_remove(.,'_bill_length_mm')) %&gt;% \n  flextable() %&gt;% \n  separate_header() %&gt;%\n  italic(part =\"header\", i= 2) %&gt;% \n  theme_apa()\n\nSpeziesBiscoeDreamTorgersenMSDMSDMSDAdelie39.002.5038.502.5039.003.00Chinstrap48.803.30Gentoo47.503.10\n\n\nAußerdem können wir Linien unter den Inseln einfügen:\n\nsummary_table %&gt;% \n  select(Spezies = species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  rename_with(.fn = ~str_remove(.,'_bill_length_mm')) %&gt;% \n  flextable() %&gt;% \n  separate_header() %&gt;%\n  italic(part =\"header\", i= 2) %&gt;% \n  theme_apa() %&gt;% \n  hline(i = 1, j = -1,part = 'header', \n        border= list(width = 0.1, color = \"black\", style = \"solid\"))\n\nSpeziesBiscoeDreamTorgersenMSDMSDMSDAdelie39.002.5038.502.5039.003.00Chinstrap48.803.30Gentoo47.503.10\n\n\nUnd abschließend exportieren:\n\nsummary_table %&gt;% \n  select(Spezies = species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  rename_with(.fn = ~str_remove(.,'_bill_length_mm')) %&gt;% \n  flextable() %&gt;% \n  separate_header() %&gt;%\n  italic(part =\"header\", i= 2) %&gt;% \n  theme_apa() %&gt;% \n  hline(i = 1, j = -1,part = 'header', \n        border= list(width = 0.1, color = \"black\", style = \"solid\")) %&gt;% \n  save_as_docx(path = 'flextable_out.docx')\n\nDer Export ist in Abbildung 9.3 zu sehen.\n\n\n\n\n\n\nAbb 9.3: Export des flextable-calls.\n\n\n\n\n\n\n\n\nAber da muss ich ja die Beschreibung doch noch nachträglich einfügen! Und was soll ich mit 15 einzelnen docs, dann muss ich ja doch alles rüberkopieren!\n\n\n\nNatürlich gibt es da auch eine Lösung! Auftritt quarto.",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Erstellung von APA-konformen Tabellen</span>"
    ]
  },
  {
    "objectID": "tables.html#aufgabe",
    "href": "tables.html#aufgabe",
    "title": "Erstellung von APA-konformen Tabellen",
    "section": "Aufgabe",
    "text": "Aufgabe\n\nErstelle eine Tabelle mit den deskriptiven Kennwerten der Blütenblatt-Länge im iris-Datensatz mit apaTables. Guck Dir dafür die Dokumentation der apa.1way.table-Funktion an.\nBaue dieselbe Tabelle mit flextable nach.",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Erstellung von APA-konformen Tabellen</span>"
    ]
  }
]