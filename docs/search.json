[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Einführung in R",
    "section": "",
    "text": "Vorwort\nDieses mit quarto erstellte Dokument ist das Skript zu der am 19. und 20. Februar 2024 im KFN MethodLab abgehaltenen Einführung in die Aufbereitung, Auswertung und Darstellung von Daten mit Hilfe der freien Sprache R.\nDie Einführung ist für zwei Tage geplant, der Ablauf ist im Folgenden einzusehen:",
    "crumbs": [
      "Vorwort"
    ]
  },
  {
    "objectID": "prep.html",
    "href": "prep.html",
    "title": "KFN MethodLab",
    "section": "",
    "text": "Vorbereitung des Workshops",
    "crumbs": [
      "Vorwort",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>KFN MethodLab</span>"
    ]
  },
  {
    "objectID": "prep.html#vorbereitung-des-workshops",
    "href": "prep.html#vorbereitung-des-workshops",
    "title": "KFN MethodLab",
    "section": "",
    "text": "Installation von R und RStudio\nUm die Übungen im Skript ausführen zu können, braucht es einen Rechner mit aktuellen Versionen von R und RStudio. Die Installationsdateien für R für Windows findet man hier und für Mac hier, die aktuellen Installationsdateien für RStudio finden sich hier.\nWir brauchen mindestens RStudio 2023.03 “Cherry Blossom” und eine entsprechende R-Version.\nZum Updaten können einfach die aktuellen Installer heruntergeladen und ausgeführt werden, hier gibt es dazu auch eine Anleitung.\n\n\nVorbereitung Tag 1 und 2\nZusätzlich brauchen wir für das rendern von Reports noch quarto, die Installationsdateien findet man hier.\nAußerdem werden im Skript die folgenden Pakete genutzt:\n\ntidyverse\ntidymodels\napaTables\npapaja\nhuxtable\nquarto\n\nUm alle Pakete zu installieren, die im Skript genutzt werden, bitte die folgende Zeile ausführen:\n\ninstall.packages(c('tidyverse', 'tidymodels', 'papaja', \n                   'apaTables', 'huxtable', 'quarto'))\n\nDazu den Code-Schnipsel kopieren, RStudio öffnen, die Zeile in die Konsole (bei neuer Installation unten links) einfügen und Enter drücken.\n\n\nVorbereitung Tag 3\nFür Tag 3 wird das Paket confreq benötigt.\nZum Installieren führen Sie bitte die folgende Zeile aus:\n\ninstall.packages('confreq')\n\n\n\nVorbereitung Tag 4\nFür Tag 4 werden semTools und lavaan benötigt. Sollten Sie schon für Tag 1 und 2 alle Pakete installiert haben, sind diese beiden Pakete auch schon mit-installiert.\nSonst führen Sie die folgende Zeile aus:\n\ninstall.packages('semTools')\n\nlavaan wird dann direkt mit-installiert.",
    "crumbs": [
      "Vorwort",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>KFN MethodLab</span>"
    ]
  },
  {
    "objectID": "rste_schritte.html",
    "href": "rste_schritte.html",
    "title": "Rste Schritte",
    "section": "",
    "text": "Warum R?\nDas R-Manual (R Core Team, 2023) hatte auf OpenAlex zum Zeitpunt der Erstelung dieses Skripts 10464 Zitationen gelistet.\nDie drei Paper aus diesen Zitaten mit den wiederum meisten Zitaten sind alles Paper, die R-Pakete vorstellen. Namentlich sind das lme4 (Bates et al., 2014), fitdistrplus (Delignette-Muller & Dutang, 2015) und mediation (Tingley et al., 2014). Diese drei Paper wurden in Summe weitere 51330 mal zitiert.\nÜber die Zeit zeigt sich ein eindeutiger Trend:\nUnd dabei sind alle möglichen empirischen Disziplinen unter den Outlets vertreten, in denen R am häufigsten zitiert wurde:",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rste Schritte</span>"
    ]
  },
  {
    "objectID": "rste_schritte.html#warum-r",
    "href": "rste_schritte.html#warum-r",
    "title": "Rste Schritte",
    "section": "",
    "text": "R ist beliebt!\n\n\n\n\n\n\n\n\nWoran liegt das?\nDas zentrale Argument:\nIm Gegensatz zu anderen gängigen Statistik-Tools ist R Open Source.\nDamit kommt einher, dass R kostenlos und vor allem von der Community erweiterbar ist. Dazu kommt das CRAN (Comprehensive R Archive Network), über das mit einem sehr rigorosen1 Review-Verfahren Pakete unproblematisch zur Verfügung gestellt werden.\n1 Wie auch am häufigen Nölen aus der Community abzulesen ist.\n\nCRAN\nDas CRAN habt Ihr bereits benutzt - mit install.packages() greift Ihr auf dieses Paket-Archiv zu und ladet Pakete runter.\nPosit stellt hier mit einer shiny-Demo sehr anschaulich dar, wie beliebt cran-Pakete und damit R sind.\n\n\nWas spricht gegen R?\n\nMausnavigierte IDEs wirken erstmal intuitiver2\nMan braucht vor allem am Anfang (ein bisschen) Frustrationstoleranz bis genug Übung besteht\nViele Beiträge von vielen Community-Mitglieder:innen heißt natürlich auch viele Ideen wie Probleme richtig gelöst werden. Die Syntax ist zwischen Paketen also oft uneinheitlich.\n\n2 Jamovi versucht hier die Lücke zu schließen.\n\nAber:\n\nMan findet sehr schnell Hilfe.3\nVor allem in den letzten fünf Jahren haben sich Projekte herausgebildet, die versuchen viele der größten Frustrationen an R abzustumpfen, z.B. Jamovi und das tidyverse.\n\n3 Auf stackoverflow gibt es zum Beispiel eine sehr aktive Gruppe an R-Usern",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rste Schritte</span>"
    ]
  },
  {
    "objectID": "rste_schritte.html#zuweisungen-und-das-environment",
    "href": "rste_schritte.html#zuweisungen-und-das-environment",
    "title": "Rste Schritte",
    "section": "1. Zuweisungen und das Environment",
    "text": "1. Zuweisungen und das Environment\nUnter Zuweisung ist erstmal nichts anderes zu verstehen, als einem Zwischenergebnis einen Namen zu geben, um es wiederverwenden zu können.\nAuch wenn es andere Möglichkeiten gibt, ist die Folgende die am besten lesbare:\n\na_number &lt;- 42\n\nDie Zahl 42 ist jetzt für weitere Verwendung im Environment abgelegt:\n\n\n\nScreenshot vom Environment\n\n\nUnd wie die Zahl alleine weiterzuverwenden:\n\n42^2\n\n[1] 1764\n\na_number^2 ## äquivalent\n\n[1] 1764\n\n\nJede dieser in grau unterlegten Zeilen nennt man auch eine Anweisung. R wird in der letzten Zeile angewiesen, den ‘Inhalt’ von a_number zu quadrieren. Dabei wird der dahinter durch das #-Symbol eingeleitete Kommentar ignoriert.\nDabei ist das Environment in jeder Session neu, wenn ich RStudio schließe und neu aufmache, wird also eine neue, leere Umgebung geöffnet4.\n4 Und direkt wieder befüllt, wenn man das unter Global Options -&gt; General -&gt; Workspace die Optionen nicht angepasst hat.5 Dazu zählen in R auch die FunktionenUnd nicht nur von uns erstellte Objekte sind im Environment vorgehalten, alle anderen aufrufbaren Objekte 5 sind in Environments zu finden. Um z.B. Pakete nutzen zu können, müssen diese erst in die Umgebung geladen werden - dazu aber später mehr.",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rste Schritte</span>"
    ]
  },
  {
    "objectID": "rste_schritte.html#funktionen-und-argumente",
    "href": "rste_schritte.html#funktionen-und-argumente",
    "title": "Rste Schritte",
    "section": "2. Funktionen und Argumente",
    "text": "2. Funktionen und Argumente\nDer Großteil des in R erstellten Codes besteht aus Funktionen.\nJede Funktion ist eine Sammlung an Anweisungen, die nacheinander augeführt werden sollen.\ncitation() ist ein sehr einfaches Beispiel für eine solche Funktion.\n\nWas macht citation()?\n\n\n\ncitation() gibt in der Konsole aus, wie man R am Besten zitiert.\n\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\n\nobligatorische und optionale Argumente\nDie meisten Funktionen kommen aber nicht ohne Argumente aus.\nArgumente können in obligatorische und optionale unterteilt werden. Wie die Namen schon sagen, sind obligatorische Argumente solche, ohne die die Funktion nicht ausgeführt werden kann.\nObligatorische Argumente sind meistens die Werte, auf deren Basis gerade die Operationen ausgeführt werden sollen.\n\nWenn man keins oder ein falsches obligatorisches Argument übergibt, zeigt R einen Fehler an!\n\noptionale Argumente nennt man die, für die die Autoren der Funktion einen Standard vorgesehen haben. Das sind dann meist Stellschrauben, an denen das gewünschte Ergebnis genauer festgelegt werden kann. Werden diese Argumente nicht explizit gesetzt, wird einfach der Standard verwendet.\n\nEin Beispiel für eine Funktion, die obligatorische und optionale Argumente annimmt ist round().\nAuf der Hilfeseite von round() finden wir folgendes6:\n6 Die Hilfeseite lässt sich entweder über die grafische Oberfläche oder mit help('round') aufrufen.\n\n\n\n\n\n\n\n\n\nWas ist hier das obligatorische Argument und wie erkennt man es?\n\n\n\nx ist hier das obligatorische Argument (kein Standard durch ein =) angegeben\nWenn man round ohne ausprobiert, gibt es einen Fehler:\n\nround()\n\nError in eval(expr, envir, enclos): 0 arguments passed to 'round' which requires 1 or 2 arguments\n\n\nWen man eine Zahl übergibt, wird auf ganze Zahlen gerundet:\n\nround(3.1415)\n\n[1] 3\n\n\n\n\nAntwort aufdecken\n\n\nDas optionale Argument digits, ermöglicht dann, die gewünschte Anzahl der Nachkommastellen anzugeben:\n\nround(3.1415, digits = 2)\n\n[1] 3.14\n\n\nSowohl 3.1415 als auch digits = 2 setzen Werte für Argumente! \nDa die Funktion aber die zu rundende Zahl x an erster Stelle erwartet, ergibt der Aufruf das gewünschte Ergebnis.\n\n\nPosition von Argumente\nR braucht also nicht unbedingt die Argumentnamen, wenn keine da sind wird die Reihenfolge interpretiert.\n\nround(3.1415, 2) ## funktioniert, digits wird an zweiter Stelle erwartet\n\n[1] 3.14\n\n\n\nWas versucht R, wenn ich die folgende Anweisung ausführe?\n\n\nround(2, 3.1415)\n\n\n\nR rundet die Zahl 2 auf 3.1415 (also 3) Nachkommastellen.\n\nround(2, 3.1415) ## funktioniert, aber vielleicht nicht wie erwartet\n\n\nWenn man Argumente ohne Namen in falscher Reihenfolge übergibt, gibt es keine Fehlermeldung aber Blödsinn!\n\n\n\nAntwort aufdecken\n\n\n\n\nOperatoren\nEinzelne Zahlen benutzt man aber ja quasi nie. Deswegen hier eine sehr praktische Funktion:\n\n1:3\n\n[1] 1 2 3\n\n\nHuch! Das sieht ja gar nicht nach einer Funktion aus! \n\nNeben den klassischen Funktionen, die durch ein Codewort und Klammern erkenntlich sind, gibt es in R noch eine Reihe Operatoren, die auf den ersten Blick keine Funktionen sind.\nHier wird aber eigentlich `:`(1,3) ausgeführt, das Funktionsschema gilt also auch hier. `:`(1,3) ist nur schrecklich schlecht lesbar und viel zu viel zu tippen.",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rste Schritte</span>"
    ]
  },
  {
    "objectID": "rste_schritte.html#indizieren",
    "href": "rste_schritte.html#indizieren",
    "title": "Rste Schritte",
    "section": "3. Indizieren",
    "text": "3. Indizieren\nDa wir jetzt erste Vektoren mit mehr als einem Element erstellen können, gehen wir zu nächsten Part, der Indizierung über.\nIn R lassen sich Elemente eines Objektes auf viele verschiedene Arten aufrufen, am Ende laufen diese aber auf den [], den [[]] und den $-Operator hinaus.\nFür Vektoren reicht erstmal der []-Operator.\n\nDas einfachste Beispiel ist der Versuch, den 3. Wert aus einer Zahlenreihe ausgeben zu lassen.\nDafür erstellen wir zuerst die Zahlenreihe von 10 bis 15 und speichern diese im Environment\n\nWie mache ich das?\n\n\n\n\neine_reihe_von_zahlen &lt;- 10:15\n\n\n\nAntwort aufdecken\n\n\nJetzt kann ich den []-Operator benutzen, um den 3. Wert anzeigen zu lassen:\n\neine_reihe_von_zahlen[3]\n\n[1] 12\n\n\nUnd fertig. So einfach.\nDer []-Operator kann aber noch viel mehr. Ich kann zum Beispiel eine Sequenz übergeben, um eine Reihe von Zahlen ausgeben zu lassen:\n\neine_reihe_von_zahlen[1:3]\n\n[1] 10 11 12\n\n\n\nDer erste Wert ist die 10! der Index für die erste Stelle ist also die 1!\n\nEine weitere Möglichkeit ist die ausschließende Indizierung. Mit einem - gibt man an, dass einen alle außer der angegebenen Stelle interessieren.\n\neine_reihe_von_zahlen[-3]\n\n[1] 10 11 13 14 15\n\n\n\nlogische Indizierung\nDer []-Operator kann außerdem benutzt werden, um über logische Operatoren Werte zu indizieren.\nDie einfachsten sind hier:\n\n1 == 2 ## ist 1 gleich 2\n1 != 3 ## ist 1 ungleich 3\n1 &lt; 4  ## ist 1 kleiner als 4\n2 &gt;= 1 ## ist 2 größer gleich 1\n\n[1] FALSE\n[1] TRUE\n[1] TRUE\n[1] TRUE\n\n\nDiese Operatoren kann ich auch auf Vektoren anwenden:\n\neine_reihe_von_zahlen &gt; 11\n\n[1] FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n\n\nUnd kann das Ergebnis auch mit dem []-Operator kombinieren:\n\neine_reihe_von_zahlen[eine_reihe_von_zahlen &gt; 11]\n\n[1] 12 13 14 15",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rste Schritte</span>"
    ]
  },
  {
    "objectID": "rste_schritte.html#datenformate-in-r",
    "href": "rste_schritte.html#datenformate-in-r",
    "title": "Rste Schritte",
    "section": "4. Datenformate in R",
    "text": "4. Datenformate in R\nBei der letzten Operation haben wir zwei Datenformate kennengelernt:\n\nlogical, eine binär-logische Angabe und\nnumeric, alle ganze und (darstellbare) rationale Zahlen\n\nJetzt kennen wir schon 2 der 3 wichtigsten einfachen oder atomic Datenformate in R\nNeben Zahlen muss R aber natürlich auch Text verarbeiten können. Dies geschieht über das character-Datenformat.\n\nWie könnte ich versuchen, ein character-Objekt mit dem Inhalt “Ich bin ein String” anzulegen?\n\n\n\n\nein_toller_character &lt;- \"Ich bin ein String\"\n\n\n\nAntwort aufdecken\n\n\nDiese einfachen Datenformate haben eine Hierarchie, die man so darzustellen versuchen könnte:\n\n logical &lt; numeric &lt; character \n\n \nAm deutlichsten wird das beim Benutzen einer der wichtigsten Funktionen in R: c() 7 - die Vektor-Funktion. Mit ihr können wir Werte zu Vektoren zusammenfügen und zu bestehenden Vektoren hinzufügen.\n7 ‘c’ ist hier übrigens kurz für concatinate\nlogical_vector &lt;- c(TRUE, TRUE, FALSE)\nlogical_vector\n\n[1]  TRUE  TRUE FALSE\n\nc(logical_vector,1)\n\n[1] 1 1 0 1\n\n\nDie logischen Werte wurden in Zahlen umgewandelt.\n\nWas passiert wohl, wenn wir eine 1 und einen character hinzufügen?\n\n\n\n\nc(logical_vector,1,'ein character')\n\n[1] \"TRUE\"          \"TRUE\"         \n[3] \"FALSE\"         \"1\"            \n[5] \"ein character\"\n\n\nDie logischen Werte und die Zahl wurden in character umgewandelt\n\n\nAntwort aufdecken\n\n\n\nDie atomics haben mit logical &lt; numeric &lt; character eine klare Hierarchie!\n\nRückgängig machen lässt sich das durch as.logical, as.numeric und as.character. Aber Vorsicht, so können auch leicht fehlende Werte, durch NA gekennzeichnet erzeugt werden:\n\nein_umzuwandelnder_vektor &lt;- c('a',1,15,TRUE)\nas.numeric(ein_umzuwandelnder_vektor)\n\n[1] NA  1 15 NA\n\n\n\n\nas.numeric(ein_umzuwandelnder_vektor)\n\n[1] NA  1 15 NA\n\n\n\nWarum fehlt auch der letzte Wert?\n\n\n\nWeil das TRUE inzwischen ein character ist.\n\nein_umzuwandelnder_vektor\n\n[1] \"a\"    \"1\"    \"15\"   \"TRUE\"\n\n\n\n\nAntwort aufdecken\n\n\nNatürlich gibt es auch komplexere, mehrdimensionale Datenformate in R, um die geht es im nächsten Teil.\n\n\n\n\nBates, D., Mächler, M., Bolker, B., & Walker, S. (2014). Fitting linear mixed-effects models using lme4. arXiv Preprint arXiv:1406.5823.\n\n\nDelignette-Muller, M. L., & Dutang, C. (2015). Fitdistrplus: An r package for fitting distributions. Journal of Statistical Software, 64, 1–34.\n\n\nR Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nTingley, D., Yamamoto, T., Hirose, K., Keele, L., & Imai, K. (2014). Mediation: R package for causal mediation analysis.",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rste Schritte</span>"
    ]
  },
  {
    "objectID": "wrangling00.html",
    "href": "wrangling00.html",
    "title": "Daten manipulieren",
    "section": "",
    "text": "Datensätze in R\nWie alle anderen Programme zur statistischen Auswertung hat R natürlich neben den Vektoren auch rechteckige Datenformate.\nDas typische rechteckige Datenformat in base R ist der data.frame. Im Prinzip nichts anderes, als spaltenweise zusammengeklebte Vektoren. Der Konstruktor für ein solches Objekt ist die gleichnamige Funktion, die die Spalten als benannte Argumente nimmt:\ndf &lt;- data.frame(a = 1:3,\n                 b = c(TRUE, FALSE, TRUE),\n                 c = c('a','b','c'))\ndf\n\n  a     b c\n1 1  TRUE a\n2 2 FALSE b\n3 3  TRUE c\nDas Indizieren im Datensatz geht dann am lesbarsten, durch das Angeben der gewünschten Spalte mit dem $-Operator und der Auswahl der Zeile durch den schon bekannten []-Operator.\ndf$c[2] ## 2. Wert in der 'c'-Spalte.\n\n[1] \"b\"\nWie könnte ich den 3. Wert in der b-Spalte indizieren?\nDer iris-Datensatz ist ein im Grundumfang von R mitgelieferter Datensatz, der historische botanische Daten nach Anderson (1935) enthält.\niris %&gt;% \n  head()\n\n  Sepal.Length Sepal.Width Petal.Length\n1          5.1         3.5          1.4\n2          4.9         3.0          1.4\n3          4.7         3.2          1.3\n4          4.6         3.1          1.5\n5          5.0         3.6          1.4\n6          5.4         3.9          1.7\n  Petal.Width Species\n1         0.2  setosa\n2         0.2  setosa\n3         0.2  setosa\n4         0.2  setosa\n5         0.2  setosa\n6         0.4  setosa",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten manipulieren</span>"
    ]
  },
  {
    "objectID": "wrangling00.html#datensätze-in-r",
    "href": "wrangling00.html#datensätze-in-r",
    "title": "Daten manipulieren",
    "section": "",
    "text": "df$b[3]\n\n\nAntwort aufdecken\n\n\n\n\n\nÜbersicht über Datensatz verschaffen\nDas ist natürlich ein bisschen unübersichtlich, wie kann man damit umgehen?\n\n1. Möglichkeit:\nWenn man iris explizit in das Environment nimmt, kann man die Oberfläche von RStudio nutze, um sich einen Überblick zu verschaffen 1\n1 Dabei nutzt die RStudio-IDE aber nur die str()(für structure)-Funktion.\niris &lt;- iris\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2. Möglichkeit:\nDie summary-Funktion, die genau das macht, was ihr Name suggeriert:\n\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length  \n Min.   :4.300   Min.   :2.000   Min.   :1.000  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600  \n Median :5.800   Median :3.000   Median :4.350  \n Mean   :5.843   Mean   :3.057   Mean   :3.758  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100  \n Max.   :7.900   Max.   :4.400   Max.   :6.900  \n  Petal.Width          Species  \n Min.   :0.100   setosa    :50  \n 1st Qu.:0.300   versicolor:50  \n Median :1.300   virginica :50  \n Mean   :1.199                  \n 3rd Qu.:1.800                  \n Max.   :2.500                  \n\n\n\n\n\nAufgabe: Deskriptive Kennwerte berechnen\nWir wollen für diesen Datensatz jetzt die folgenden Schritte der Auswertung vollziehen:\n\nAusschluss der Blumen, die breitere Blütenblätter als das 1.5-fache der mittleren Blütenblätter haben und Kelche, die kürzer als das Mittel der Kelchlänge sind\nDarstellung der Mittelwerte und Streuungen der Blütenblattlänge und -breite pro verbleibende Spezies als Tabelle\n\n\n\nAufgabe: Base-R Lösung\n\ndf &lt;- iris[iris$Petal.Width &lt;= 1.5 * mean(iris$Petal.Width) &\n             iris$Sepal.Length &gt;= mean(iris$Sepal.Length),]\nmeans &lt;- aggregate(cbind(df$Petal.Length,df$Petal.Width),\n          by = list(Species = df$Species),\n          FUN = mean)\nsds &lt;- aggregate(cbind(df$Petal.Length,df$Petal.Width),\n          by = list(Species = df$Species),\n          FUN = sd)\ntab &lt;- data.frame(means, sds[,2:3])\nnames(tab)[2:5] = c('m_Length', 'm_Width', 'sd_Length', 'sd_Width')\ntab\n\n     Species m_Length m_Width sd_Length\n1 versicolor    4.560   1.424 0.2783882\n2  virginica    5.375   1.500 0.3862210\n    sd_Width\n1 0.14798649\n2 0.08164966\n\n\n\n\nAuftritt tidyverse\nDie selbe Aufgabe wie gerade, jetzt mit dem tidyverse:\n\nlibrary(tidyverse)\niris %&gt;% \n  filter(Petal.Width &lt;= 1.5 * mean(Petal.Width) &\n           Sepal.Length &gt;= mean(Sepal.Length)) %&gt;% \n  group_by(Species) %&gt;% \n  summarise(m_Length = mean(Petal.Length),\n            sd_Length = sd(Petal.Length),\n            m_Width = mean(Petal.Width), \n            sd_Width = sd(Petal.Width))\n\n# A tibble: 2 × 5\n  Species    m_Length sd_Length m_Width sd_Width\n  &lt;fct&gt;         &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 versicolor     4.56     0.278    1.42   0.148 \n2 virginica      5.38     0.386    1.5    0.0816\n\n\n\n\ntidy aggregation\nDas tidyverse (Wickham et al., 2019) ist eine Sammlung von Paketen, deren Hauptziel es ist, Datenaufbereitung in R intuitiver und leichter lesbar zu machen.\nEin zentrales Element dabei ist der %&gt;%-Operator, die sogenannte Pipeline2. Beim Skript-Lesen und -Schreiben kann man sich diese am Besten als ‘dann’ vorstellen\n2 base-R hat mit Version 4.1 auch eine native pipe eingeführt (|&gt;), da wir aber eh das tidyverse nutzen bleiben wir bei der magrittr-pipeMit ihrer Hilfe werden Aufbereitungsschritte in einer stringenten Reihe an Operationen formuliert, die sich am Besten als Satz verstehen lassen.\nDa die Funktionen im tidyverse alle mit einfachen Verben benannt sind, lässt sich die Operation von eben auch so lesen.\n\n1library(tidyverse)\n2iris %&gt;%\n3  filter(Petal.Width &lt;= 1.5 * mean(Petal.Width) &\n           Sepal.Length &gt;= mean(Sepal.Length)) %&gt;%\n4  group_by(Species) %&gt;%\n5  summarise(m_Length = mean(Petal.Length),\n            sd_Length = sd(Petal.Length),\n            m_Width = mean(Petal.Width),\n            sd_Width = sd(Petal.Width))\n\n\n1\n\nZuerst muss das tidyverse geladen werden\n\n2\n\nNimm iris, dann …\n\n3\n\nfilter Zeilenweise nach den gesetzten Regeln, dann…\n\n4\n\ngruppiere nach der Spezies, dann…\n\n5\n\nberechne die angegebenen Kenngrößen über die Gruppen.\n\n\n\n\nZweite Beispielaufgabe:\nWir möchten für den iris-Datensatz:\n\nEine Spalte hinzufügen, die die z-transformierte Blattlänge enthält\nEine Spalte hinzufügen, die als character das Ergebnis eines Mediansplits der gerade erstellten Variable enthält\nEinen Datensatz erstellen, der nur die Spezies, die z-Transformierte und die Mediansplit-Variable enthält\nDie Häufigkeiten der Kombinationen von Mediansplit-Gruppe und Spezies auszählen\n\n\n1df &lt;- iris %&gt;%\n2  mutate(\n3        z_length = (Petal.Length-mean(Petal.Length))/sd(Petal.Length),\n4        med_split = case_when(\n5                           z_length &gt;= median(z_length) ~ 'upper',\n6                           T ~ 'lower')) %&gt;%\n7  select(Species, z_length, med_split)\n\n\n1\n\nErstelle ein Objekt df. Nimm dazu iris, dann …\n\n2\n\nverändere den Datensatz indem Du …\n\n3\n\ndie z-Werte pro Blatt-Länge berechnest und als z_length dem Datensatz hinzufügst, …\n\n4\n\nmit der Funktion case_when eine Spalte anlegst, die …\n\n5\n\nz_length-Werten kleiner/gleich dem Median ‘upper’ zuweist …\n\n6\n\nund allen anderen Werten ‘lower’. Dann…\n\n7\n\nwähle die Spalten Species, z_length und med_split aus.\n\n\n\n\nHat das geklappt?\n\nWie könnte ich das überprüfen?\n\n\n\n\nsummary(df)\n\n       Species      z_length      \n setosa    :50   Min.   :-1.5623  \n versicolor:50   1st Qu.:-1.2225  \n virginica :50   Median : 0.3354  \n                 Mean   : 0.0000  \n                 3rd Qu.: 0.7602  \n                 Max.   : 1.7799  \n  med_split        \n Length:150        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\n\n\nAntwort aufdecken\n\n\nJetzt noch Häufigkeiten auszählen:\n\n1df %&gt;%\n2  group_by(Species, med_split) %&gt;%\n3  summarise(n = n())\n\n\n1\n\nNimm df, dann …\n\n2\n\ngruppiere nach Species und med_split, dann…\n\n3\n\nZähle die absoluten Häufigkeiten aus.\n\n\n\n\n`summarise()` has grouped output by 'Species'.\nYou can override using the `.groups` argument.\n\n\n# A tibble: 4 × 3\n# Groups:   Species [3]\n  Species    med_split     n\n  &lt;fct&gt;      &lt;chr&gt;     &lt;int&gt;\n1 setosa     lower        50\n2 versicolor lower        25\n3 versicolor upper        25\n4 virginica  upper        50\n\n\n\n\nAufgabe\nMachen Sie sich mit dem swiss-Datensatz vertraut. Lesen Sie dazu auch die Hilfeseite zu dem Datensatz, diese können Sie mit ?swiss aufrufen. Erstellen Sie mit Hilfe einer pipeline einen Datensatz, der…\n\nnur Provinzen enthält, deren Einwohner zu mehr als 10% und weniger als 35% Bestnoten bei der Armee-Untersuchung erhalten haben\nnur den Anteil der männlichen Population in der Landwirtschaft, die Kindersterblichkeit, das Bildungsniveau und den Anteil der katholischen Familien enthält\neine numerische Variable enthält, die für die so ausgewählten Fälle einen Mediansplit der Kindersterblichkeit codiert.\neine Variable enthält, die angibt, ob der Anteil der männlichen Population an der Landwirtschaft über oder unter dem Mittelwert (mean) liegt\n\nLassen Sie sich die absoluten Häufigkeiten der Kombination der beiden gerade erstellten Variablen ausgeben.\nZusatz: Erstellen Sie anschließend eine kurze pipeline, die den gerade erstellten Datensatz mit dem Absteigenden Bildungsniveau als ersten Sortierschlüssel und dem aufsteigenden Anteil katholischer Familien als zweitem Schlüssel sortiert. Nutzen Sie dafür die Hilfeseite der arrange-Funktion.\n\n\n\nlibrary(tidyverse)\ndf &lt;- swiss %&gt;%\n  filter(Education &gt; 10,\n         Education &lt; 35) %&gt;%\n  select(Agriculture,\n         Infant.Mortality,\n         Education,\n         Catholic) %&gt;%\n  mutate(\n    mediansplit_mortality = case_when(\n      Infant.Mortality &gt;= median(Infant.Mortality) ~ 1,\n      T ~ -1),\n    meansplit_agriculture = case_when(\n      Agriculture &gt; mean(Agriculture) ~ 'high',\n      Agriculture &lt; mean(Agriculture) ~ 'low',\n      T ~ 'mean'\n    )\n  )\n\ndf %&gt;% \n  count(mediansplit_mortality,meansplit_agriculture)\n\n  mediansplit_mortality meansplit_agriculture n\n1                    -1                  high 4\n2                    -1                   low 4\n3                     1                  high 4\n4                     1                   low 4\n\ndf2 &lt;- df %&gt;% \n  arrange(-Education,\n          Catholic)\n\n\n\nAntwort aufdecken",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten manipulieren</span>"
    ]
  },
  {
    "objectID": "wrangling00.html#literatur",
    "href": "wrangling00.html#literatur",
    "title": "Daten manipulieren",
    "section": "Literatur",
    "text": "Literatur\n\n\n\n\nAnderson, E. (1935). The irises of the Gaspe Peninsula. Bull. Am. Iris Soc., 59, 2–5.\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten manipulieren</span>"
    ]
  },
  {
    "objectID": "wrangling01.html",
    "href": "wrangling01.html",
    "title": "Daten einlesen",
    "section": "",
    "text": "Einlesen von Daten\nDas Rechnen mit den mit R mitgelieferten Datensätzen ist natürlich nur bedingt realitätsnah.\nIm durchschnittlichen Anwendungsfall müssen externe Datensätze eingelesen werden.\nDabei sind im tidyverse dafür je nach Quelle folgende Pakete vorgesehen:",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "wrangling01.html#einlesen-von-daten",
    "href": "wrangling01.html#einlesen-von-daten",
    "title": "Daten einlesen",
    "section": "",
    "text": "Textbasierte Daten(.txt, .csv, .tsv,...) \\(\\rightarrow\\) readr\nExcel-Mappen(.xlsx, .xls) \\(\\rightarrow\\) readxl\nDaten aus anderen Statistikpaketen(.sav, .dta,...) \\(\\rightarrow\\) haven\n\n\nEinlesen von Textdaten\nAlle diese drei Pakete sind auch in der RStudio-GUI implementiert: \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem\nDas Einlesen und Aufbereiten wird am folgenden Beispiel exerziert:  Uns interessiert der Zusammenhang von Drogenmissbrauch, Lebenszufriedenheit und Straftaten in Großbritannien. Dafür haben wir die folgenden drei Datensätz zur Verfügung:\n\n'crime.csv' - Eine Textdatei mit nach Polizeibehörde aufgeschlüsselten Straftaten\n'drugs.xlsx' - Eine Excel-Arbeitsmappe mit nach Region aufgeschlüsselten Zahlen zu Krankenhauseinweisungen mit drogenbedingten Diagnosen\n'satisfaction.sav' - Ein in SPSS erstellter Datensatz mit nach Region aufgeschlüsselten Ergebnissen einer Bevölkerungsbefragung zur Lebenszufriedenheit\n\n\n\ntextbasierte Daten\nDie GUI ist hier ein guter Start. Wir wollen die Datei 'crime.csv' einlesen. Diese enthält echte Daten über von britischen Polizeibehörden aufgezeichnete Straftaten von der Website der britischen Regierung. Wenn ich dem Pfad im GUI folge, ergibt sich das folgende Bild:\n\n\n\n\n\n\n\n\n\n\nWas ist das Problem?\n\n\n\nDas Trennzeichen(Delimiter) ist falsch gesetzt. In den Daten sind die Zellen offensichtlich durch Semikolons getrennt.\n\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\nDer für das Einlesen nötige Code wird dann von RStudio in die Konsole kopiert und ausgeführt. Um nicht jedes Mal beim Ausführen desselben Skriptes wieder per Hand den Datensatz einlesen zu müssen, kopiert man den Code dann an den Anfang des Skriptes.\n\n\n\n\n\n\n\n\n\nWas passiert hier?\n\n1crime &lt;- read_delim(\"data/crime.csv\",\n2                    \";\",\n3                    escape_double = FALSE,\n4                    trim_ws = TRUE)\n5View(crime)\n\n\n1\n\nLege in crime das Textfile mit Trennzeichen unter dem angegebenen Pfad ab. Dabei…\n\n2\n\n…erwarte Semikolons als Trennzeichen,\n\n3\n\n…erwarte keine doppelten Anführungszeichen\n\n4\n\nund schneide Leerzeichen von den Einträgen ab.\n\n5\n\nDann öffne den Datensatz zum Angucken.\n\n\n\n\nMit dem Output teilt R mit, dass es Kommazahlen als Standard-Zelleninhalt versucht und bei nicht-Funktionieren auf character zurückfällt. Das ist trotz der Farbe keine Fehlermeldung.\nNoch zwei wichtige Tricks in dem Einlesetool sind die locale-Schaltfläche und das NA-Menü\n\n\n\n\n\n\n\n\n\n\n\nExcel-Arbeitsmappen\nFür die Excel-Arbeitsmappen ist die GUI auch der einfachste Weg.\n\nWie würde man vorgehen um die Datei drugs.xlsx einzulesen?\n\n\n\n\nImport Dataset \\(\\rightarrow\\) From Excel\nPfad zum file raussuchen\n\n\n\n\n\n\n\n\n\n\n\nRichtiges Sheet aussuchen\nunnötige Zeilen überspringen\netwaige von leeren Zellen abweichende NA-Codierung anpassen\n\n\n\nAntwort aufdecken\n\n\n\nAuch bei Excel-Mappen an das Kopieren des Codes denken!\n\n\nlibrary(readxl)\ndrugs &lt;- read_excel(\"data/drugs.xlsx\",\n                    sheet = \"Table 2\", \n                    na = \"*\", \n                    skip = 10)\n\nNew names:\n• `` -&gt; `...1`\n• `` -&gt; `...2`\n• `` -&gt; `...3`\n• `` -&gt; `...4`\n\n\nDiese Daten sind übrigens auch Originaldaten von der Website des britischen National Health Services\n\n\nDateien aus anderer Software\nBeispielhaft für SPSS, für Stata etc analog. Die GUI ist wieder ein guter Anfang und hier ziemlich selbsterklärend.\n\nWie würde man vorgehen um die Datei satisfaction.sav einzulesen?\n\n\n\n\nlibrary(haven)\nsatisfaction &lt;- read_sav(\"data/satisfaction.sav\")\n\nDie Daten kommen diesmal vom britischen Office for National Statistics, wurden aber stark abgewandelt.\n\n\nAntwort aufdecken\n\n\nWenn man sich die Daten in der RStudio-Oberfläche anguckt, sieht man, dass die für SPSS typischen Variablendefinitionen konserviert wurden:\n\n\n\n\n\n\n\n\n\nhaven bietet mit der as_factor-Funktion eine Möglichkeit an, eine dieser Codierung enthaltenden Variablen in einen Faktor umzuwandeln.\nFaktoren sind eine Variante um in R kategoriale Variablen anzulegen.\nSo könnten wir uns zum Beispiel entscheiden, einen neuen, zweiten Datensatz zu erstellen, der die Variablen mit den Verbal-labels aus SPSS enthält. Da wir auf alle Spalten dafür dieselbe Funktion anwenden wollen, können wir dafür mutate mit der across-Funktion kombinieren.\nDabei benutzen wir die im tidyverse zur Stapelverarbeitung von Spalten genutzte tidy-select-Syntax und weil das noch nicht genug neues auf einmal ist noch die tidyverse-Syntax zur Definition von Platzhalter-Funktionen:\n\n1verbal_satisfaction &lt;- satisfaction %&gt;%\n2  mutate(\n3    across(\n4      everything(),\n5      ~ as_factor(.)\n    )\n  )\n\n\n1\n\nErstelle verbal_satisfaction indem Du verbal_satisfaction nimmst und dann…\n\n2\n\neine Veränderung durchführst indem Du…\n\n3\n\nfür mehrere Spalten 1…\n\n1 Bei across wird kein Spaltenname angegeben!4\n\nund zwar alle…\n\n5\n\ndie jeweilige Spalte an Stelle des Punkts einsetzt.\n\n\n\n\nDas Ergebnis sieht in der Oberfläche dann so aus:\n\n\n\n\n\n\n\n\n\nFür Tipps zur weitergehenden Bearbeitung von SPSS und Stata-Daten noch hier die sehr gute haven-Website mit Dokumentation und Anleitungen zu den nötigen Schritten.\n\n\nAufgabe\nLesen Sie die drei Datensätze temp.csv, charts.xlsx und covid_cases.sav ein und verschaffen Sie sich einen Überblick.\n\n\n\ntemp &lt;-  read_csv2('data/temp.csv')\nsummary(temp)\n\nlibrary(haven)\ncovid_cases &lt;- read_sav(\"data/covid_cases.sav\")\nsummary(covid_cases)\n\nlibrary(readxl)\ncharts &lt;- read_excel(\"data/charts.xlsx\")\nsummary(charts)\n\n\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nRows: 338 Columns: 3\n── Column specification ──────────────────────────\nDelimiter: \";\"\ndbl  (2): temp, cw\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nAntwort aufdecken",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "wrangling01.html#datenaufbereitung",
    "href": "wrangling01.html#datenaufbereitung",
    "title": "Daten einlesen",
    "section": "Datenaufbereitung",
    "text": "Datenaufbereitung\nDatenaufbereitung kann natürlich denkbar komplex sein, deswegen beschränken wir uns auf sehr einfache Methoden mit dem Fokus auf die Umsetzung im tidyverse. Es geht gleich explizit nicht um die Methoden! Wir gucken uns drei einfache Beispiele an:\n\nAusreißer-Behandlung\nUmgang mit fehlenden Werten\nRecodieren von Werten\n\n\nAusreißer-Behandlung\nAls ersten Schritt zur Bereinigung der drei Datensätze sollen Ausreißer erkannt und durch fehlende Werte ausgeschlossen werden.\nDafür muss man sich natürlich zuerst überlegen, was das Kriterium dafür sein soll. Wir benutzen hier das Kriterium nach Tukey (1977), also wollen wir gerade die Werte ausschlißen, die mehr als 1.5 Interquartilabstände über oder unter dem 25% bzw dem 75%-Quantil liegen.\nUm uns Tipparbeit zu sparen, schreiben wir dafür unsere erste Funktion:\n\n1remove_outlier &lt;- function(x){\n2  ifelse(\n3      between(x,\n              quantile(x,.25) - 1.5 * IQR(x),\n              quantile(x,.75) + 1.5 * IQR(x)),\n4          x,\n5          NA)\n6  }\n\n\n1\n\nErstelle ein Object mit dem Namen remove_outlier, in dem eine Funktion mit dem obligatorischen Argument x definiert ist, deren body durch { eingeleitet wird.\n\n2\n\nSetze anhand des logischen Vektors an der ersten Stelle Werte ein.\n\n3\n\nDie Logik soll sein ob sich die Werte von x zwischen den Tukey-Fences liegt\n\n4\n\nWenn ja, behalte den Werte von x…\n\n5\n\nsonst ersetze mit NA.\n\n6\n\nEnde der Definition.\n\n\n\n\n\nWie sähe die Frage mit case_when aus?\n\n\n\n\nremove_outlier &lt;- function(x){\n  case_when(\n    x &lt; quantile(x,.25) - 1.5 * IQR(x) ~ NA,\n    x &gt; quantile(x,.75) + 1.5 * IQR(x) ~ NA,\n    T ~ x\n  )\n  }\n\n\n\nAntwort aufdecken\n\n\nKombiniert mit einem mutate, einem across und einem weiteren tidy-select-helper können wir damit alle Ausreißer gegen fehlende Werte austauschen.\n\n1crime &lt;- crime %&gt;%\n2  mutate(\n3    across(\n4      where(is.numeric),\n5      ~remove_outlier(.)\n    )\n  )\n\n\n1\n\nÜberschreibe crime indem Du crime nimmst und dann…\n\n2\n\neine Veränderung durchführst indem Du…\n\n3\n\nfür mehrere Spalten…\n\n4\n\nund zwar alle numerischen…\n\n5\n\nunsere Ausreißer-Berinigung anwendest.\n\n\n\n\n\n\nUmgang mit fehlenden Werten\nFehlende Werte werden in R generell mit NA codiert. Um damit umzugehen bietet das tidyverse ein paar Funktionen, wir beschränken uns hier auf zwei.\ndrop_na zum rigorosen Entfernen von Zeilen mit fehlenden Werten:\n\ndrugs %&gt;% \n  drop_na()\n\n# A tibble: 0 × 7\n# ℹ 7 variables: ...1 &lt;chr&gt;, ...2 &lt;chr&gt;,\n#   ...3 &lt;chr&gt;, ...4 &lt;chr&gt;, All persons9 &lt;dbl&gt;,\n#   Male &lt;dbl&gt;, Female &lt;dbl&gt;\n\n\n…in unserem Fall vielleicht ein bisschen zu rigoros\nDie zweite Möglichkeit ist replace_na, eine Funktion die, wie der Name schon sagt, NAs durch festgelegte Werte ersetzen kann. Mit unserem mutate von eben kombiniert, können wir so alle fehlenden Zahlen im Datensatz durch 0 ersetzen:\n\ndrugs %&gt;% \n  mutate(\n    across(where(is.numeric),\n           ~replace_na(., 0))\n  )\n\n# A tibble: 195 × 7\n   ...1     ...2  ...3  ...4  `All persons9`  Male\n   &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;\n 1 &lt;NA&gt;     &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;               0     0\n 2 E920000… &lt;NA&gt;  &lt;NA&gt;  Engl…           7139  5294\n 3 &lt;NA&gt;     &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;               0     0\n 4 U        &lt;NA&gt;  U     Unkn…            244   202\n 5 &lt;NA&gt;     &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;               0     0\n 6 E120000… &lt;NA&gt;  A     Nort…            276   194\n 7 E060000… &lt;NA&gt;  116   Coun…             56    40\n 8 E060000… &lt;NA&gt;  117   Darl…             26    16\n 9 E080000… &lt;NA&gt;  106   Gate…             12     0\n10 E060000… &lt;NA&gt;  111   Hart…             29     0\n# ℹ 185 more rows\n# ℹ 1 more variable: Female &lt;dbl&gt;\n\n\n\nJetzt können wir noch die fehlenden character umgewandeln:\n\ndrugs &lt;- drugs %&gt;% \n  mutate(\n    across(where(is.numeric),\n           ~replace_na(., 0)),\n    across(where(is.character),\n           ~replace_na(., ''))\n  )\ndrugs\n\n# A tibble: 195 × 7\n   ...1     ...2  ...3  ...4  `All persons9`  Male\n   &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;\n 1 \"\"       \"\"    \"\"    \"\"                 0     0\n 2 \"E92000… \"\"    \"\"    \"Eng…           7139  5294\n 3 \"\"       \"\"    \"\"    \"\"                 0     0\n 4 \"U\"      \"\"    \"U\"   \"Unk…            244   202\n 5 \"\"       \"\"    \"\"    \"\"                 0     0\n 6 \"E12000… \"\"    \"A\"   \"Nor…            276   194\n 7 \"E06000… \"\"    \"116\" \"Cou…             56    40\n 8 \"E06000… \"\"    \"117\" \"Dar…             26    16\n 9 \"E08000… \"\"    \"106\" \"Gat…             12     0\n10 \"E06000… \"\"    \"111\" \"Har…             29     0\n# ℹ 185 more rows\n# ℹ 1 more variable: Female &lt;dbl&gt;\n\n\n\n\nRecodieren von Werten\nAuch bei dem Recodieren von Werten können wir eine mutate-pipeline benutzen.\nFür Kategoriale Daten bietet das tidyverse die case_match-Funktion, die so ähnlich wie die case_when-Funktion funktioniert, die wir ja auch schon kennen. Für numerische Werte funktioniert natürlich weiter case_when oder auch einfache arithmetische Operationen.\nIm folgenden Beispiel benutzen wir case_match auf dem iris-Datensatz, um die Spezies auf deutsch zu übersetzen:\n\niris %&gt;% \n  mutate(Spezies = case_match(Species,\n                              'virginica' ~ 'Virginische Schwertlinie',\n                              'versicolor' ~ 'Verschiedenfarbige Schwertlilie',\n                              'setosa' ~ 'Borsten-Schwertlilie'))\n\n    Sepal.Length Sepal.Width Petal.Length\n1            5.1         3.5          1.4\n2            4.9         3.0          1.4\n3            4.7         3.2          1.3\n4            4.6         3.1          1.5\n5            5.0         3.6          1.4\n6            5.4         3.9          1.7\n7            4.6         3.4          1.4\n8            5.0         3.4          1.5\n9            4.4         2.9          1.4\n10           4.9         3.1          1.5\n11           5.4         3.7          1.5\n12           4.8         3.4          1.6\n13           4.8         3.0          1.4\n14           4.3         3.0          1.1\n15           5.8         4.0          1.2\n16           5.7         4.4          1.5\n17           5.4         3.9          1.3\n18           5.1         3.5          1.4\n19           5.7         3.8          1.7\n20           5.1         3.8          1.5\n21           5.4         3.4          1.7\n22           5.1         3.7          1.5\n23           4.6         3.6          1.0\n24           5.1         3.3          1.7\n25           4.8         3.4          1.9\n26           5.0         3.0          1.6\n27           5.0         3.4          1.6\n28           5.2         3.5          1.5\n29           5.2         3.4          1.4\n30           4.7         3.2          1.6\n31           4.8         3.1          1.6\n32           5.4         3.4          1.5\n33           5.2         4.1          1.5\n34           5.5         4.2          1.4\n35           4.9         3.1          1.5\n36           5.0         3.2          1.2\n37           5.5         3.5          1.3\n38           4.9         3.6          1.4\n39           4.4         3.0          1.3\n40           5.1         3.4          1.5\n41           5.0         3.5          1.3\n42           4.5         2.3          1.3\n43           4.4         3.2          1.3\n44           5.0         3.5          1.6\n45           5.1         3.8          1.9\n46           4.8         3.0          1.4\n47           5.1         3.8          1.6\n48           4.6         3.2          1.4\n49           5.3         3.7          1.5\n50           5.0         3.3          1.4\n51           7.0         3.2          4.7\n52           6.4         3.2          4.5\n53           6.9         3.1          4.9\n54           5.5         2.3          4.0\n55           6.5         2.8          4.6\n56           5.7         2.8          4.5\n57           6.3         3.3          4.7\n58           4.9         2.4          3.3\n59           6.6         2.9          4.6\n60           5.2         2.7          3.9\n61           5.0         2.0          3.5\n62           5.9         3.0          4.2\n63           6.0         2.2          4.0\n64           6.1         2.9          4.7\n65           5.6         2.9          3.6\n66           6.7         3.1          4.4\n67           5.6         3.0          4.5\n68           5.8         2.7          4.1\n69           6.2         2.2          4.5\n70           5.6         2.5          3.9\n71           5.9         3.2          4.8\n72           6.1         2.8          4.0\n73           6.3         2.5          4.9\n74           6.1         2.8          4.7\n75           6.4         2.9          4.3\n76           6.6         3.0          4.4\n77           6.8         2.8          4.8\n78           6.7         3.0          5.0\n79           6.0         2.9          4.5\n80           5.7         2.6          3.5\n81           5.5         2.4          3.8\n82           5.5         2.4          3.7\n83           5.8         2.7          3.9\n84           6.0         2.7          5.1\n85           5.4         3.0          4.5\n86           6.0         3.4          4.5\n87           6.7         3.1          4.7\n88           6.3         2.3          4.4\n89           5.6         3.0          4.1\n90           5.5         2.5          4.0\n91           5.5         2.6          4.4\n92           6.1         3.0          4.6\n93           5.8         2.6          4.0\n94           5.0         2.3          3.3\n95           5.6         2.7          4.2\n96           5.7         3.0          4.2\n97           5.7         2.9          4.2\n98           6.2         2.9          4.3\n99           5.1         2.5          3.0\n100          5.7         2.8          4.1\n101          6.3         3.3          6.0\n102          5.8         2.7          5.1\n103          7.1         3.0          5.9\n104          6.3         2.9          5.6\n105          6.5         3.0          5.8\n106          7.6         3.0          6.6\n107          4.9         2.5          4.5\n108          7.3         2.9          6.3\n109          6.7         2.5          5.8\n110          7.2         3.6          6.1\n111          6.5         3.2          5.1\n112          6.4         2.7          5.3\n113          6.8         3.0          5.5\n114          5.7         2.5          5.0\n115          5.8         2.8          5.1\n116          6.4         3.2          5.3\n117          6.5         3.0          5.5\n118          7.7         3.8          6.7\n119          7.7         2.6          6.9\n120          6.0         2.2          5.0\n121          6.9         3.2          5.7\n122          5.6         2.8          4.9\n123          7.7         2.8          6.7\n124          6.3         2.7          4.9\n125          6.7         3.3          5.7\n126          7.2         3.2          6.0\n127          6.2         2.8          4.8\n128          6.1         3.0          4.9\n129          6.4         2.8          5.6\n130          7.2         3.0          5.8\n131          7.4         2.8          6.1\n132          7.9         3.8          6.4\n133          6.4         2.8          5.6\n134          6.3         2.8          5.1\n135          6.1         2.6          5.6\n136          7.7         3.0          6.1\n137          6.3         3.4          5.6\n138          6.4         3.1          5.5\n139          6.0         3.0          4.8\n140          6.9         3.1          5.4\n141          6.7         3.1          5.6\n142          6.9         3.1          5.1\n143          5.8         2.7          5.1\n144          6.8         3.2          5.9\n145          6.7         3.3          5.7\n146          6.7         3.0          5.2\n147          6.3         2.5          5.0\n148          6.5         3.0          5.2\n149          6.2         3.4          5.4\n150          5.9         3.0          5.1\n    Petal.Width    Species\n1           0.2     setosa\n2           0.2     setosa\n3           0.2     setosa\n4           0.2     setosa\n5           0.2     setosa\n6           0.4     setosa\n7           0.3     setosa\n8           0.2     setosa\n9           0.2     setosa\n10          0.1     setosa\n11          0.2     setosa\n12          0.2     setosa\n13          0.1     setosa\n14          0.1     setosa\n15          0.2     setosa\n16          0.4     setosa\n17          0.4     setosa\n18          0.3     setosa\n19          0.3     setosa\n20          0.3     setosa\n21          0.2     setosa\n22          0.4     setosa\n23          0.2     setosa\n24          0.5     setosa\n25          0.2     setosa\n26          0.2     setosa\n27          0.4     setosa\n28          0.2     setosa\n29          0.2     setosa\n30          0.2     setosa\n31          0.2     setosa\n32          0.4     setosa\n33          0.1     setosa\n34          0.2     setosa\n35          0.2     setosa\n36          0.2     setosa\n37          0.2     setosa\n38          0.1     setosa\n39          0.2     setosa\n40          0.2     setosa\n41          0.3     setosa\n42          0.3     setosa\n43          0.2     setosa\n44          0.6     setosa\n45          0.4     setosa\n46          0.3     setosa\n47          0.2     setosa\n48          0.2     setosa\n49          0.2     setosa\n50          0.2     setosa\n51          1.4 versicolor\n52          1.5 versicolor\n53          1.5 versicolor\n54          1.3 versicolor\n55          1.5 versicolor\n56          1.3 versicolor\n57          1.6 versicolor\n58          1.0 versicolor\n59          1.3 versicolor\n60          1.4 versicolor\n61          1.0 versicolor\n62          1.5 versicolor\n63          1.0 versicolor\n64          1.4 versicolor\n65          1.3 versicolor\n66          1.4 versicolor\n67          1.5 versicolor\n68          1.0 versicolor\n69          1.5 versicolor\n70          1.1 versicolor\n71          1.8 versicolor\n72          1.3 versicolor\n73          1.5 versicolor\n74          1.2 versicolor\n75          1.3 versicolor\n76          1.4 versicolor\n77          1.4 versicolor\n78          1.7 versicolor\n79          1.5 versicolor\n80          1.0 versicolor\n81          1.1 versicolor\n82          1.0 versicolor\n83          1.2 versicolor\n84          1.6 versicolor\n85          1.5 versicolor\n86          1.6 versicolor\n87          1.5 versicolor\n88          1.3 versicolor\n89          1.3 versicolor\n90          1.3 versicolor\n91          1.2 versicolor\n92          1.4 versicolor\n93          1.2 versicolor\n94          1.0 versicolor\n95          1.3 versicolor\n96          1.2 versicolor\n97          1.3 versicolor\n98          1.3 versicolor\n99          1.1 versicolor\n100         1.3 versicolor\n101         2.5  virginica\n102         1.9  virginica\n103         2.1  virginica\n104         1.8  virginica\n105         2.2  virginica\n106         2.1  virginica\n107         1.7  virginica\n108         1.8  virginica\n109         1.8  virginica\n110         2.5  virginica\n111         2.0  virginica\n112         1.9  virginica\n113         2.1  virginica\n114         2.0  virginica\n115         2.4  virginica\n116         2.3  virginica\n117         1.8  virginica\n118         2.2  virginica\n119         2.3  virginica\n120         1.5  virginica\n121         2.3  virginica\n122         2.0  virginica\n123         2.0  virginica\n124         1.8  virginica\n125         2.1  virginica\n126         1.8  virginica\n127         1.8  virginica\n128         1.8  virginica\n129         2.1  virginica\n130         1.6  virginica\n131         1.9  virginica\n132         2.0  virginica\n133         2.2  virginica\n134         1.5  virginica\n135         1.4  virginica\n136         2.3  virginica\n137         2.4  virginica\n138         1.8  virginica\n139         1.8  virginica\n140         2.1  virginica\n141         2.4  virginica\n142         2.3  virginica\n143         1.9  virginica\n144         2.3  virginica\n145         2.5  virginica\n146         2.3  virginica\n147         1.9  virginica\n148         2.0  virginica\n149         2.3  virginica\n150         1.8  virginica\n                            Spezies\n1              Borsten-Schwertlilie\n2              Borsten-Schwertlilie\n3              Borsten-Schwertlilie\n4              Borsten-Schwertlilie\n5              Borsten-Schwertlilie\n6              Borsten-Schwertlilie\n7              Borsten-Schwertlilie\n8              Borsten-Schwertlilie\n9              Borsten-Schwertlilie\n10             Borsten-Schwertlilie\n11             Borsten-Schwertlilie\n12             Borsten-Schwertlilie\n13             Borsten-Schwertlilie\n14             Borsten-Schwertlilie\n15             Borsten-Schwertlilie\n16             Borsten-Schwertlilie\n17             Borsten-Schwertlilie\n18             Borsten-Schwertlilie\n19             Borsten-Schwertlilie\n20             Borsten-Schwertlilie\n21             Borsten-Schwertlilie\n22             Borsten-Schwertlilie\n23             Borsten-Schwertlilie\n24             Borsten-Schwertlilie\n25             Borsten-Schwertlilie\n26             Borsten-Schwertlilie\n27             Borsten-Schwertlilie\n28             Borsten-Schwertlilie\n29             Borsten-Schwertlilie\n30             Borsten-Schwertlilie\n31             Borsten-Schwertlilie\n32             Borsten-Schwertlilie\n33             Borsten-Schwertlilie\n34             Borsten-Schwertlilie\n35             Borsten-Schwertlilie\n36             Borsten-Schwertlilie\n37             Borsten-Schwertlilie\n38             Borsten-Schwertlilie\n39             Borsten-Schwertlilie\n40             Borsten-Schwertlilie\n41             Borsten-Schwertlilie\n42             Borsten-Schwertlilie\n43             Borsten-Schwertlilie\n44             Borsten-Schwertlilie\n45             Borsten-Schwertlilie\n46             Borsten-Schwertlilie\n47             Borsten-Schwertlilie\n48             Borsten-Schwertlilie\n49             Borsten-Schwertlilie\n50             Borsten-Schwertlilie\n51  Verschiedenfarbige Schwertlilie\n52  Verschiedenfarbige Schwertlilie\n53  Verschiedenfarbige Schwertlilie\n54  Verschiedenfarbige Schwertlilie\n55  Verschiedenfarbige Schwertlilie\n56  Verschiedenfarbige Schwertlilie\n57  Verschiedenfarbige Schwertlilie\n58  Verschiedenfarbige Schwertlilie\n59  Verschiedenfarbige Schwertlilie\n60  Verschiedenfarbige Schwertlilie\n61  Verschiedenfarbige Schwertlilie\n62  Verschiedenfarbige Schwertlilie\n63  Verschiedenfarbige Schwertlilie\n64  Verschiedenfarbige Schwertlilie\n65  Verschiedenfarbige Schwertlilie\n66  Verschiedenfarbige Schwertlilie\n67  Verschiedenfarbige Schwertlilie\n68  Verschiedenfarbige Schwertlilie\n69  Verschiedenfarbige Schwertlilie\n70  Verschiedenfarbige Schwertlilie\n71  Verschiedenfarbige Schwertlilie\n72  Verschiedenfarbige Schwertlilie\n73  Verschiedenfarbige Schwertlilie\n74  Verschiedenfarbige Schwertlilie\n75  Verschiedenfarbige Schwertlilie\n76  Verschiedenfarbige Schwertlilie\n77  Verschiedenfarbige Schwertlilie\n78  Verschiedenfarbige Schwertlilie\n79  Verschiedenfarbige Schwertlilie\n80  Verschiedenfarbige Schwertlilie\n81  Verschiedenfarbige Schwertlilie\n82  Verschiedenfarbige Schwertlilie\n83  Verschiedenfarbige Schwertlilie\n84  Verschiedenfarbige Schwertlilie\n85  Verschiedenfarbige Schwertlilie\n86  Verschiedenfarbige Schwertlilie\n87  Verschiedenfarbige Schwertlilie\n88  Verschiedenfarbige Schwertlilie\n89  Verschiedenfarbige Schwertlilie\n90  Verschiedenfarbige Schwertlilie\n91  Verschiedenfarbige Schwertlilie\n92  Verschiedenfarbige Schwertlilie\n93  Verschiedenfarbige Schwertlilie\n94  Verschiedenfarbige Schwertlilie\n95  Verschiedenfarbige Schwertlilie\n96  Verschiedenfarbige Schwertlilie\n97  Verschiedenfarbige Schwertlilie\n98  Verschiedenfarbige Schwertlilie\n99  Verschiedenfarbige Schwertlilie\n100 Verschiedenfarbige Schwertlilie\n101        Virginische Schwertlinie\n102        Virginische Schwertlinie\n103        Virginische Schwertlinie\n104        Virginische Schwertlinie\n105        Virginische Schwertlinie\n106        Virginische Schwertlinie\n107        Virginische Schwertlinie\n108        Virginische Schwertlinie\n109        Virginische Schwertlinie\n110        Virginische Schwertlinie\n111        Virginische Schwertlinie\n112        Virginische Schwertlinie\n113        Virginische Schwertlinie\n114        Virginische Schwertlinie\n115        Virginische Schwertlinie\n116        Virginische Schwertlinie\n117        Virginische Schwertlinie\n118        Virginische Schwertlinie\n119        Virginische Schwertlinie\n120        Virginische Schwertlinie\n121        Virginische Schwertlinie\n122        Virginische Schwertlinie\n123        Virginische Schwertlinie\n124        Virginische Schwertlinie\n125        Virginische Schwertlinie\n126        Virginische Schwertlinie\n127        Virginische Schwertlinie\n128        Virginische Schwertlinie\n129        Virginische Schwertlinie\n130        Virginische Schwertlinie\n131        Virginische Schwertlinie\n132        Virginische Schwertlinie\n133        Virginische Schwertlinie\n134        Virginische Schwertlinie\n135        Virginische Schwertlinie\n136        Virginische Schwertlinie\n137        Virginische Schwertlinie\n138        Virginische Schwertlinie\n139        Virginische Schwertlinie\n140        Virginische Schwertlinie\n141        Virginische Schwertlinie\n142        Virginische Schwertlinie\n143        Virginische Schwertlinie\n144        Virginische Schwertlinie\n145        Virginische Schwertlinie\n146        Virginische Schwertlinie\n147        Virginische Schwertlinie\n148        Virginische Schwertlinie\n149        Virginische Schwertlinie\n150        Virginische Schwertlinie\n\n\nUm arithmetisch umzucodieren, kann in mutate eine Spalte verrechnet werden.\n\nWie könnte ich die Anxiety-Skala im satisfaction-Datensatz umpolen?\n\n\n\n\nsatisfaction &lt;- satisfaction %&gt;% \n  mutate(Average_Anxious_Yesterday = -1* (Average_Anxious_Yesterday-10))\n\n\n\nAntwort aufdecken\n\n\n\n\nAufgabe\nTransformieren Sie nun die Datensätze in der folgenden Art und Weise:\n\nFassen Sie den Covid-Datensatz so zusammen, dass pro Kalenderwoche eine Summe der jeweils neuen Fälle übrigbleibt. Ersetzen Sie vorher die fehlenden Werte entweder durch Nullen, oder, wenn Sie sich eine kleine Herausforderung wünschen, durch die Mittelwerte der jeweiligen Kalenderwoche. Als kleiner Tipp: schauen Sie sich dafür die Hilfeseiten von group_split und map_dfr an.\n\n\n\n\ncovid_summary &lt;- covid_cases %&gt;% #Ersetzen mit 0\n  mutate(new_cases = case_when(is.na(new_cases) ~ 0, T ~ new_cases)) %&gt;% \n  group_by(calendar_week) %&gt;% \n  summarise(new_cases = sum(new_cases))\n\ncovid_summary &lt;- covid_cases %&gt;% #Ersetzen mit Mittelwert\n  group_by(calendar_week) %&gt;%\n  group_split() %&gt;%\n  map_dfr( ~ mutate(., new_cases = case_when(\n    is.na(new_cases) ~ mean(new_cases, na.rm = T),\n    T ~ new_cases\n  ))) %&gt;% \n  group_by(calendar_week) %&gt;%\n  summarise(new_cases = sum(new_cases))\n\n\n\nAntwort aufdecken\n\n\n\nFassen Sie den Temperatur-Datensatz bitte auch pro Kalenderwoche zusammen, diesmal aber mit der mittleren Temperatur als Ergebnis\n\n\n\n\ntemp_summary &lt;- temp %&gt;% \n  group_by(cw) %&gt;% \n  summarise(temp = mean(temp))\n\n\n\nAntwort aufdecken\n\n\n\nIm Charts-Datensatz haben sich ein paar unrealistische Platzierungen eingeschlichen. Entfernen Sie diese bitte. Wir wollen für unsere folgenden Analysen pro Lied einen Score benutzen, der zwischen 1 und 0 liegt. Je größer dieser Score ist, desto höher soll der Song platziert gewesen sein und umgekehrt. Rechnen Sie die Position bitte pro Kalenderwoche in diesen Score um.\n\n\n\n\nremove_outlier &lt;- function(x){\n  ifelse(\n      between(x,\n              quantile(x,.25) - 1.5 * IQR(x),\n              quantile(x,.75) + 1.5 * IQR(x)),\n          x, \n          NA)\n  }\n\ncharts &lt;- charts %&gt;% \n  mutate(across(where(is.numeric), ~remove_outlier(.))) %&gt;% \n  drop_na() %&gt;% \n  group_by(kw) %&gt;% \n  arrange(Position) %&gt;% \n  mutate(score = seq(1, 0, along.with = Position))\n\n\n\nAntwort aufdecken\n\n\n\n\n\n\nTukey, J. W. (1977). Exploratory data analysis (Vol. 2). Reading, Mass.",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "graphics.html",
    "href": "graphics.html",
    "title": "Grammar of Graphics und ggplot2",
    "section": "",
    "text": "Grammar of Graphics\nHadley Wickhams Paket ggplot2 (Wickham, 2016) versucht, die Erstellung von Grafiken in einer einheitlichen Grammatik, der “grammar of graphics”, auszudrücken. Das Ziel hier ist es, nicht mehr in “Scatterplot” und “Boxplot” als einzelne Kategorien zu denken und diese einzeln erstellen lernen zu müssen, sondern alle Abbildungen mit derselben Logik erstellen zu können.\nIn Seinem Paper (Wickham, 2010) werden die folgenden Komponenten als grundlegende Bausteine einer Grafik eingeführt:",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#grammar-of-graphics",
    "href": "graphics.html#grammar-of-graphics",
    "title": "Grammar of Graphics und ggplot2",
    "section": "",
    "text": "a default dataset and set of mappings from variables to aesthetics,\none or more layers, with each layer having one geometric object, one statistical trans- formation, one position adjustment, and optionally, one dataset and set of aesthetic mappings,\none scale for each aesthetic mapping used,\na coordinate system,\nthe facet specification. (Wickham, 2010, p. 8)\n\n\n\nKomponenten eines Plots\nWir müssen für einen Plot also überlegen:\n\nwelche Daten wir auf welche Aesthetics mappen\nwelche geometrischen Objekte wir in welcher Reihenfolge auf die Grafik layer wollen und ob diese optionale andere Daten benötigen\nwelche Skala wir für die Mappings nutzen wollen\nwelches Koordinatensystem wir nutzen wollen\nin welchen Facetten wir die Daten darstellen wollen",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#komponenten-in-ggplot2",
    "href": "graphics.html#komponenten-in-ggplot2",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Komponenten in ggplot2",
    "text": "Komponenten in ggplot2\n\nBeispieldaten\n\n\n\n\n\nPinguine im Eis\n\n\n\nIm palmerpenguins-Paket werden Pinguin-Beobachtungen der Palmer-Station in der Antarktis zur Verfügung gestellt:\n\npalmerpenguins::penguins %&gt;% \n  head()\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\n\n1. Daten und Aesthetics - ggplot() + aes()\nWir wollen den Zusammenhang zwischen Körpergewicht und Schnabellänge über die Spezies betrachten. Dafür legen wir die “Leinwand” des Plots mit den zentralen mappings an:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species))\n\n\n\n\n\n\n\n\nDabei können natürlich je nach geom(s), die aufgeschaltet werden, unterschiedliche mappings relevant sein. Welche jeweils nötig sind, lässt sich auf der Hilfeseite des entsprechenden geoms nachlesen.\nBeispiele für mögliche Werte für die meisten mappings lassen sich in der ggplot2-Vignette zum Thema (vignette(\"ggplot2-specs\")) finden.\n\n\n2. Geometrische Objekte - geom_*\nDiesem Plot fügen wir Punkte als geometrische Objekte hinzu, die uns zu einem Scatterplot führen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\n3. Skalen - scale_*\nDie Symbole und Farben haben genau wie x- und y- Koordinaten als ästhetische Mappings eigene Skalen. Wenn uns also die Farben nicht passen, können wir einfach eine andere Skala setzen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point() +\n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\n\n\n4. Koordinatensystem coord_*\nDas Koordinatensystem passt von der Auflösung erstmal, aber wir wollen eine direkte Zuordnung von 10 mm Schnabellänge zu 1000 g Körpermasse. Dazu fügen wir eine coord_*-Spezifikation an:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point() +\n  scale_color_viridis_d()+\n  coord_fixed(ratio = 10/1000)\n\n\n\n\n\n\n\n\n\n\n5. Facetten - facet_*\nAls letzte Komponente überlegen wir uns, dass die verschiedenen Beobachtungspunkte als Einteilung interessant sein könnten und wir diese getrennt betrachten wollen. Mit der facet-Familie können wir den Graphen nach Indel facettieren:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point() +\n  scale_color_viridis_d()+\n  coord_fixed(ratio = 10/1000) +\n  facet_wrap(~island)",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#sec-geoms",
    "href": "graphics.html#sec-geoms",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Einfache Grafiken",
    "text": "Einfache Grafiken\nNeben den dem Point-geom gibt es in ggplot2 natürlich auch so gut wie alle anderen geoms, die für gängige Plots nötig sind. 1\n1 Daneben gibt es einen riesigen Stamm an Paketen, die weniger gängige Plot-Typen als geoms implementieren, z.B. ggwordcloud für wordclouds, ggalluvial für Alluvial und Sankey-Diagramme, ggnet für Netzwerk-Plots und das bei meinen Studis sehr beliebte ggpubr für ‘publication ready plots’. Auf cran sind im Moment 213 Pakete gelistet, die mit “gg” anfangen und ggplot2 imoprtieren oder von ggplot2 abhängig sind.Die folgende Auswahl ist nach dem System des sehr zu empfehlenden Cheat-Sheets von posit zu ggplot2 sortiert und nur ein Bruchteil der in R angelegten geoms.\n\nEine VariableZwei VariablenDrei Variablen\n\n\n\nkontinuierlichdiskret\n\n\nFür die Darstellung einer numerischen Variable bieten Histogramme und ähnliche Darstellungen der Verteilungen einer Variable an.\nIn Abbildung Eine Auswahl der in ggplot2 angelegten geoms, die die Verteilung einer Variable abbilden. sind vier Beispiele, wie sich mit ggplot2 eine numerische Variable darstellen ließe. Alle diese Plots haben den folgenden ggplot-Call als Grundlage:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = flipper_length_mm))\n\n\n\n\n\n\n\n\n\n\n\n\n(a) + geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n(b) + geom_dotplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) + geom_area(stat= ‘bin’)\n\n\n\n\n\n\n\n\n\n\n\n(d) + geom_freqpoly()\n\n\n\n\n\n\n\nAbb 6.1: Eine Auswahl der in ggplot2 angelegten geoms, die die Verteilung einer Variable abbilden.\n\n\n\nAlle vier Beispiele berechnen dabei die bins in die die Beobachtungen einsortiert werden als Standard so, dass 30 Gruppen entstehen.\n\nWelches der auf der geom_histogram()-Hilfeseite genannten Argumente hilft mir am ehesten, die Bin-Breite auf 5mm flipper-Length zu setzen?\n\n\n\n\nbinwidth\nThe width of the bins. Can be specified as a numeric value or as a function that calculates width from unscaled x. Here, “unscaled x” refers to the original x values in the data, before application of any scale transformation. When specifying a function along with a grouping structure, the function will be called once per group. The default is to use the number of bins in bins, covering the range of the data. You should always override this value, exploring multiple widths to find the best to illustrate the stories in your data.\n\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = flipper_length_mm)) +\n  geom_histogram(binwidth=5)\n\n\n\n\n\n\n\n\nIm Hilfetext wird auch die Möglichkeit eines Funktionsaufrufs genannt. Wenn wir zum Beispiel 5% des Abstands zwischen Maximum und Minimum des Wertebereichs als Binwidth setzen wollen, können wir den folgenden Call mit Lambda-Funktion benutzen. Lambda-Funktionen sind anonyme Funktionen, für die in R 4.1.0 die Kurzschreibweise \\(x) &lt;body&gt; statt function(x) &lt;body&gt; eingeführt wurde.\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = flipper_length_mm)) +\n  geom_histogram(binwidth=\\(x) .05 * (max(x, na.rm=T) - min(x, na.rm=T)))\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\n\n\nFür eine diskrete Variable kann mit einem Barchart die Verteilung illustriert werden:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = island)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeide kontinuierlichEine diskret, eine kontinuierlich\n\n\nIn Abbildung Eine Auswahl der in ggplot2 angelegten geoms, die die Verteilung einer Variable abbilden. wird die Basis des geom_point-Blocks aus dem Anfang des ggplot-Abschnitts für alle vier Plots genutzt. Die Basis ist also in jedem Fall der folgende Code-Schnipsel:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g))\n\n\n\n\n\n\n\n\n\n\n\n\n(a) + geom_point()\n\n\n\n\n\n\n\n\n\n\n\n(b) + geom_quantile()\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) + geom_smooth(method = ‘lm’)\n\n\n\n\n\n\n\n\n\n\n\n(d) + geom_rug(sides = ‘bl’)\n\n\n\n\n\n\n\nAbb 6.2: Eine Auswahl der in ggplot2 angelegten geoms, die die Verteilung einer Variable abbilden.\n\n\n\n\n\nTypische Darstellungen, die diskrete und kontinuierliche Variablen kombinieren, sind Darstellungen von Verteilungsvergleichen. Zum Beispiel könnte der Vergleich der Verteilungen der Schnabel-Länge zwischen den Spezies mit folgendem Call angelegt werden:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = species, \n             y = bill_length_mm,\n             color = species))\n\nIn Abbildung Eine Auswahl der in ggplot2 angelegten geoms, die die Verteilung einer Variable abbilden. sind drei Möglichkeiten abgetragen, wie sich diese Basis für eine Darstellung nutzen ließe.\n\n\n\n\n\n\n\n\n\n\n\n(a) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n(b) + geom_dotplot(binaxis = ‘y’, stackdir = ‘center’)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) + geom_violin(scale = ‘area’)\n\n\n\n\n\n\n\nAbb 6.3: Eine Auswahl der in ggplot2 angelegten geoms, die die Verteilung einer Variable abbilden.\n\n\n\nNatürlich lassen sich diese beide Variablen auch mit dem Psychologen-Favourite der Mittelwert-Barcharts darstellen.\nDazu gibt es zwei Möglichkeiten. Entweder wir bauen eine Pipeline, die gruppierte Mittelwerte berechnet und darstellt wie im folgenden Beispiel:\n\npalmerpenguins::penguins %&gt;%\n  group_by(species) %&gt;% \n  summarise(bill_length_mm = mean(bill_length_mm, na.rm = T)) %&gt;% \n  ggplot(aes(x = species, \n             y = bill_length_mm,\n             fill = species)) +\n  geom_col()\n\n\n\n\n\n\n\n\nAlternativ können wir das ggplot-Feature nutzen, Berechnungen im data-Argument eines geoms anzugeben:\n\npalmerpenguins::penguins %&gt;%\n  ggplot(aes(x = species, \n             y = bill_length_mm,\n             fill = species)) +\n  geom_col(data = ~ group_by(.x, species) %&gt;% \n             summarise(bill_length_mm = mean(bill_length_mm, na.rm=T)))\n\n\n\n\n\n\n\n\n\n\n\n\n\nNatürlich sind viele der schon genannten geoms auch nutzbar, um drei Variablen darzustellen. Mit unserem Beispiel vom Anfang hatten wir z.B. ja schon drei Variablen (species, bill_length_mm und body_mass_g) auf jeweils eine “Ästhetische Dimension” gemapped.\nFür zum Beispiel Korrelationsdarstellungen könnte ergänzend aber noch geom_tile ganz interessant sein. Dazu berechnen wir einmal die Korrelation zwischen allen numerischen Variablen in unserem Datensatz:\n\npalmerpenguins::penguins %&gt;% \n  select(where(is.numeric)) %&gt;% \n  cor(., use = 'p')\n\n                  bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\nbill_length_mm        1.00000000   -0.23505287         0.6561813  0.59510982\nbill_depth_mm        -0.23505287    1.00000000        -0.5838512 -0.47191562\nflipper_length_mm     0.65618134   -0.58385122         1.0000000  0.87120177\nbody_mass_g           0.59510982   -0.47191562         0.8712018  1.00000000\nyear                  0.05454458   -0.06035364         0.1696751  0.04220939\n                         year\nbill_length_mm     0.05454458\nbill_depth_mm     -0.06035364\nflipper_length_mm  0.16967511\nbody_mass_g        0.04220939\nyear               1.00000000\n\n\nMit ein bisschen R-Magie machen wir daraus einen ggplot-kompatiblen Datensatz mit den drei Variablen x-Dimension, y-Dimension und Korrelation:\n\n\nCode\nr &lt;- palmerpenguins::penguins %&gt;%\n  select(where(is.numeric)) %&gt;%\n  cor(., use = 'p')\n\nr &lt;- tibble(x = rep(row.names(r), nrow(r)),\n       y = rep(colnames(r), each=nrow(r)),\n       r = c(r))\n\nr\n\n\n# A tibble: 25 × 3\n   x                 y                    r\n   &lt;chr&gt;             &lt;chr&gt;            &lt;dbl&gt;\n 1 bill_length_mm    bill_length_mm  1     \n 2 bill_depth_mm     bill_length_mm -0.235 \n 3 flipper_length_mm bill_length_mm  0.656 \n 4 body_mass_g       bill_length_mm  0.595 \n 5 year              bill_length_mm  0.0545\n 6 bill_length_mm    bill_depth_mm  -0.235 \n 7 bill_depth_mm     bill_depth_mm   1     \n 8 flipper_length_mm bill_depth_mm  -0.584 \n 9 body_mass_g       bill_depth_mm  -0.472 \n10 year              bill_depth_mm  -0.0604\n# ℹ 15 more rows\n\n\nDiese drei Dimensionen können wir mit geom_tile darstellen:\n\nr %&gt;% \n  ggplot(aes(x, y, fill = r)) +\n  geom_tile() \n\n\n\n\n\n\n\n\nAlternativ gibt es selbstverständlich auch ein Paket, das ggplot2-basierte Korrelationsmatrizen darstellt:\n\nr &lt;- palmerpenguins::penguins %&gt;%\n  select(where(is.numeric)) %&gt;%\n  cor(., use = 'p')\n\n\nggcorrplot::ggcorrplot(r)\n\n\n\n\n\n\n\n\n\n\n\n\nAufgaben\n\nAufgabe 1\nLesen Sie den Datensatz “worldbank_indicators.xlsx” ein. In ihm sind Daten von der worldbank zu verschiedenen Indikatoren in mehreren Ländern für die Jahre von 2000 bis 2021 vorgehalten.\nWählen Sie ein Jahr aus und filtern Sie den Datensatz, so dass nur noch dieses Jahr enthalten ist.\nErstellen Sie mit den Daten\n\neine Grafik mit einer kontinuierlichen Variable\neine Grafik mit zwei kontinuierlichen Variablen\neine Grafik mit dem Länder-Namen und einer kontinuierlichen Variable Ihrer Wahl\n\n\n\n\nlibrary(readxl)\n\nworldbank_indicators &lt;- read_excel(\"data/worldbank_indicators.xlsx\")\n\none_year &lt;- worldbank_indicators %&gt;% \n  filter(Year == 2019)\n\none_year %&gt;% \n  ggplot(aes(x = `Life expectancy at birth, total (years)`)) +\n  geom_histogram(fill = 'white',\n                 color = 'darkblue')\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\none_year %&gt;% \n  ggplot(aes(`Life expectancy at birth, total (years)`,\n             `GDP per capita (current US$)`,\n             color = `Country Name`)) +\n  geom_point()\n\n\n\n\n\n\n\none_year %&gt;% \n  ggplot(aes(`Country Name`,\n             `Total alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age)`,\n             fill = `Country Name`)) +\n  geom_col() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\n\n\nAufgabe 2\nLesen Sie die Hilfeseite für geom_line. Erstellen Sie ein Liniendiagramm mit der Zeit auf der x-Achse und einer Variable Ihrer Wahl auf der y-Achse.\nSollten Sie noch Zeit haben, fügen Sie dem Datensatz eine Variable hinzu, die den Mittelwert des Alkoholkonsums über die Jahre pro Land enthält. Nutzen Sie diese Variable um eine neue Variable zu erstellen, die einen Median-Split enthält. Sie müssen dafür wahrscheinlich einmal ungroup aufrufen.\nFacettieren Sie das Liniendiagramm nach diesem Split.\n\n\n\nworldbank_indicators %&gt;% \n  ggplot(aes(Year,\n             `Life expectancy at birth, total (years)`,\n             color = `Country Name`)) +\n  geom_line()\n\n\n\n\n\n\n\nworldbank_indicators %&gt;% \n  group_by(`Country Name`) %&gt;% \n  mutate(mean_consumption = mean(`Total alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age)`, na.rm = T)) %&gt;% \n  ungroup() %&gt;% \n  mutate(median_split = case_when(mean_consumption &gt; median(mean_consumption) ~ 'Hoher Konsum',\n                                  mean_consumption &lt;= median(mean_consumption) ~ 'Weniger hoher Konsum')) %&gt;% \n  ggplot(aes(Year,\n             `Life expectancy at birth, total (years)`,\n             color = `Country Name`)) +\n  geom_line() +\n  facet_wrap(~median_split)\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\n\n\nAufgabe 3\nErstellen Sie eine Grafik mit geom_tile auf Basis des Original-Datensatz. Auf der x-Achse sollen die Jahre zu sehen sein, auf der y-Achse die Länder. Die Flächen sollen so eingefärbt werden, dass der Quotient des GDPs und der Lebenserwartung sichtbar wird.\n\n\n\nworldbank_indicators %&gt;% \n  mutate(quotient = `GDP per capita (current US$)` / `Life expectancy at birth, total (years)`) %&gt;% \n  ggplot(aes(Year,\n             `Country Name`,\n             fill = quotient)) +\n  geom_tile()\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#kombination-mehrerer-geoms",
    "href": "graphics.html#kombination-mehrerer-geoms",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Kombination mehrerer geoms",
    "text": "Kombination mehrerer geoms\nPlots müssen nicht nur aus einem geom bestehen.\nEin möglicher Fall ist der Wunsch nach der Darstellung von Summary-Statistics in Grafiken mit Rohdaten.\nIm Pinguin-Scatter-Plot vom Anfang könnten wir uns zum Beispiel wünschen, die Mittelwerte pro Gruppe darzustellen. Dazu müssen wir zuerst diesen neuen Datensatz berechnen. :\n\npenguin_means &lt;- palmerpenguins::penguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(across(c(bill_length_mm, \n                     body_mass_g), \n                   ~mean(., na.rm=T)))\n\n…und auf den Plot in einem neuen Layer hinzufügen2:\n2 alternativ würde natürlich wieder eine (Lambda-)Funktion im data-Argument funktionieren.\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point() +\n  geom_point(data=penguin_means)+\n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\nFür den Layer können wir dann auch wieder spezifische geometrische Eigenschaften einfügen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point() +\n  geom_point(data=penguin_means, shape = 3)+\n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\nOder direkt ein neues Mapping einführen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original')) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'))+\n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\nUnd auch beide Varianten kombinieren:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3)+\n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\nDie Kombination von mehreren geoms kann außerdem interessant sein, wenn wir verschiedene kombinieren wollen, um mehrere Aspekte abzubilden. So könnte man mehrere der in Einfache Grafiken besprochenen geoms zur Darstellung gleicher Daten auf einem Plot zusammenfügen.\nIn Abbildung Abbildungen mit Kombinationen mehrerer geoms sind Beispiele dargestellt, die mit dem eingeklappten Chunk erstellt wurden, um mit Hilfe mehrerer geoms mehr Informationen abzubilden.\n\nCode\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = flipper_length_mm, \n             y = bill_length_mm,\n             color = species)) +\n  geom_point(alpha = .5) +\n  geom_smooth(method = 'lm') +\n  geom_quantile(lty = 3)\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = species, \n             y = bill_length_mm,\n             color = species)) +\n  geom_violin(scale = 'area',\n              aes(fill = species),\n              alpha = .25) +\n  geom_boxplot(width = 0.25,\n               position = position_nudge(x = -0.125)) +\n  geom_dotplot(aes(fill = species),\n               binaxis = 'y', \n               stackdir = 'up',\n               dotsize = 0.1)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Zwei kontinuierliche Variablen (+1 diskrete)\n\n\n\n\n\n\n\n\n\n\n\n(b) Je eine diskrete und eine kontinuierliche Variable\n\n\n\n\n\n\n\nAbb 6.4: Abbildungen mit Kombinationen mehrerer geoms",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#mehrere-scales",
    "href": "graphics.html#mehrere-scales",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Mehrere scales",
    "text": "Mehrere scales\nGenauso wie die Verwendung mehrerer geoms, können natürlich auch mehrere Skalen gesetzt werden. So können wir im Scatter-Plot mit den Mittwelwerten zum Beispiel noch die Symbole für die unterschiedlichen dargestellten Daten anpassen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#sec-multipleGeomTask",
    "href": "graphics.html#sec-multipleGeomTask",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Aufgabe",
    "text": "Aufgabe\nFür diese Aufgabe benötigen Sie wieder den Worldbank-Datensatz.\nErstellen Sie ein Liniendiagramm, das für drei von Ihnen ausgewählte Länder die Entwicklung der Lebenserwartung für Frauen und Männer darstellt.\nDie Länder sollen in eigenen Facetten zu sehen sein.\nPassen Sie die scale der Farbe so an, dass Ihnen die Farben gefallen.\n\n\n\nworldbank_indicators %&gt;% \n  filter(`Country Name` %in% c('Germany', 'United States', 'United Kingdom')) %&gt;% \n  ggplot(aes(x = Year)) +\n  geom_line(aes(y = `Life expectancy at birth, female (years)`,\n                color = 'female')) +\n  geom_line(aes(y = `Life expectancy at birth, male (years)`,\n                color = 'male')) +\n  facet_wrap(~`Country Name`) +\n  scale_color_manual(values = c('female' = 'royalblue1', 'male' = 'darkslategrey'))\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\nBerechnen Sie dann die mittlere Lebenserwartung im ganzen Datensatz pro Jahr und Geschlecht.\nFügen Sie diese Verläufe nach der Facettierung der Grafik hinzu.\nPassen Sie die Linientypen (linetype) so an, dass die Mittelwerte schraffiert und die tatsächlichen Werte durchgezogen sind.\n\n\n\nmean_life_expectancy &lt;- worldbank_indicators %&gt;% \n  group_by(Year) %&gt;% \n  summarise(across(matches('male'), mean))\n\nworldbank_indicators %&gt;% \n  filter(`Country Name` %in% c('Germany', 'United States', 'United Kingdom')) %&gt;% \n  ggplot(aes(x = Year)) +\n  geom_line(aes(y = `Life expectancy at birth, female (years)`,\n                color = 'female',\n                lty = 'country')) +\n  geom_line(aes(y = `Life expectancy at birth, male (years)`,\n                color = 'male',\n                lty = 'country')) +\n  facet_wrap(~`Country Name`)+\n  geom_line(data = mean_life_expectancy,\n            aes(y = `Life expectancy at birth, female (years)`,\n                color = 'female',\n                lty = 'average')) +\n  geom_line(data = mean_life_expectancy,\n            aes(y = `Life expectancy at birth, male (years)`,\n                color = 'male',\n                lty = 'average'))+\n  scale_color_manual(values = c('female' = 'royalblue1', 'male' = 'darkslategrey')) +\n  scale_linetype_manual(values = c('country' = 1, 'average' = 2))\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\nBerechnen Sie zuletzt pro Land einen Mittelwert der Lebenserwartung pro Geschlecht über den Messzeitraum. Lesen Sie sich die Hilfeseite der geom_hline-Funktion durch und fügen Sie die Mittelwerte für die drei von Ihnen ausgewählten Länder zu der Grafik hinzu.\n\n\n\nmean_per_country &lt;- worldbank_indicators  %&gt;% \n  filter(`Country Name` %in% c('Germany', 'United States', 'United Kingdom')) %&gt;% \n  group_by(`Country Name`) %&gt;% \n  summarise(across(matches('male'), mean))\n\n\nworldbank_indicators %&gt;% \n  filter(`Country Name` %in% c('Germany', 'United States', 'United Kingdom')) %&gt;% \n  ggplot(aes(x = Year)) +\n  geom_line(aes(y = `Life expectancy at birth, female (years)`,\n                color = 'female',\n                lty = 'country')) +\n  geom_line(aes(y = `Life expectancy at birth, male (years)`,\n                color = 'male',\n                lty = 'country')) +\n  geom_hline(data = mean_per_country,\n             aes(yintercept = `Life expectancy at birth, female (years)`,\n                color = 'female',\n                lty = 'average')) +\n  geom_hline(data = mean_per_country,\n             aes(yintercept = `Life expectancy at birth, male (years)`,\n                color = 'male',\n                lty = 'average')) +\n  facet_wrap(~`Country Name`)+\n  geom_line(data = mean_life_expectancy,\n            aes(y = `Life expectancy at birth, female (years)`,\n                color = 'female',\n                lty = 'average')) +\n  geom_line(data = mean_life_expectancy,\n            aes(y = `Life expectancy at birth, male (years)`,\n                color = 'male',\n                lty = 'average'))+\n  scale_color_manual(values = c('female' = 'royalblue1', 'male' = 'darkslategrey')) +\n  scale_linetype_manual(values = c('country' = 1, 'average' = 2))\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#styling",
    "href": "graphics.html#styling",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Styling",
    "text": "Styling\nggplot2 hat neben den in der Grammar of Graphics beschriebenen Komponenten außerdem noch Gruppen von Funktionen die die Usability verbessern oder die Einstellung zur optischen Erscheinung neben den scales ermöglichen.\nDie wohl wichtigste dieser Funktionen ist die labs-Funktion, mit der sich die Beschriftungen des Graphen anpassen lassen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))+\n  coord_fixed(ratio = 10/1000) +\n  facet_wrap(~island) +\n  labs(x = 'Schnabellänge (mm)',\n       y = 'Körpergewicht (g)',\n       color = 'Pinguin-Spezies',\n       shape = 'Aggregations-Niveau')\n\n\n\n\n\n\n\n\nFür eine top-Level-Anpassung der optischen Erscheinung gibt es außerdem die Familie der theme_ Funktionen. In Abbildung Alle in ggplot2 angelegten Themes ist der Pinguin-Plot von eben mit allen in ggplot2 definierten themes kombiniert.\n\n\n\n\n\n\n\n\n\n\n\n(a) theme_grey\n\n\n\n\n\n\n\n\n\n\n\n(b) theme_bw\n\n\n\n\n\n\n\n\n\n\n\n(c) theme_linedraw\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d) theme_light\n\n\n\n\n\n\n\n\n\n\n\n(e) theme_dark\n\n\n\n\n\n\n\n\n\n\n\n(f) theme_minimal\n\n\n\n\n\n\n\n\n\n\n\n\n\n(g) theme_classic\n\n\n\n\n\n\n\n\n\n\n\n(h) theme_void\n\n\n\n\n\n\n\n\n\n\n\n(i) theme_test\n\n\n\n\n\n\n\nAbb 7.1: Alle in ggplot2 angelegten Themes\n\n\n\nMir gefallen aus dieser Aufstellung “light” und “minimal” am Besten, die anderen sind aber je nach Anlass auch gute Startpunkte.\nUnserem Plot können wir das theme wie alle bisherigen layer hinzufügen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))+\n  labs(x = 'Schnabellänge (mm)',\n       y = 'Körpergewicht (g)',\n       color = 'Pinguin-Spezies',\n       shape = 'Aggregations-Niveau') +\n  theme_light()\n\n\n\n\n\n\n\n\nIn diesem Zusammenhang können wir auch gleich Base-Font und Schriftgröße setzen. theme_light setzt die kleinste Schriftgröße auf .8 mal die base_size3, wenn wir minimal 8pt große Schrift haben wollen, wie es zum Beispiel von der APA gefordert wird. Außerdem lässt sich eine APA-konforme Schriftart auswählen.\n3 Diese Info findet man nicht auf der Hilfeseite, wenn man aber in RStudio eine Funktion markiert und F2 drückt, kann man den Quellcode einsehen. theme_light ist dabei auch ein gutes Beispiel als Ausgangpunkt für ein eigenes theme\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))+\n  labs(x = 'Schnabellänge (mm)',\n       y = 'Körpergewicht (g)',\n       color = 'Pinguin-Spezies',\n       shape = 'Aggregations-Niveau') +\n  theme_light(base_family = 'Helvetica',\n              base_size = 10)\n\n\n\n\n\n\n\n\nFür genauere Kontrolle der optischen Eigenschaften kann die theme-Funktion benutzt werden. Wir kratzen nur mal an der Oberfläche der Möglichkeiten und verschieben die Legende an den unteren Rand des Graphen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))+\n  labs(x = 'Schnabellänge (mm)',\n       y = 'Körpergewicht (g)',\n       color = 'Pinguin-Spezies',\n       shape = 'Aggregations-Niveau') +\n  theme_light(base_family = 'Helvetica',\n              base_size = 10) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\nUm die zu breite Beschriftung zu reparieren nutzen wir die guides-Funktion 4\n4 ggplot2 hat eine ganze Familie an guide_-Funktionen, die unterschiedliche Legenden-Arten und Legenden-Anpassungen bieten - aus Zeitgründen sei hier aber nur auf deren Existenz verwiesen.\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))+\n  labs(x = 'Schnabellänge (mm)',\n       y = 'Körpergewicht (g)',\n       color = 'Pinguin-Spezies',\n       shape = 'Aggregations-Niveau') +\n  theme_light(base_family = 'Helvetica',\n              base_size = 10) +\n  theme(legend.position = 'bottom') +\n  guides(color = guide_legend(nrow = 3),\n         shape = guide_legend(nrow = 2))\n\n\n\n\n\n\n\n\n\nExport\nZum Abschluss wollen wir die Grafiken natürlich exportieren.\nDie Textgröße ist in pt gesetzt, deswegen sollten wir nach dem Export die Größe im besten Fall nicht mehr viel ändern.\nEine Din A4-Seite ist 8.2 x 11.6 Zoll groß. Wenn wir eine Grafik auf 80% der Seitenbreite haben wollen, brauchen wir also eine 6.56 Zoll breite Grafik.\nZum Speichern setzen wir unsere Grafik und die Maße in ggsave ein:\n\np &lt;- palmerpenguins::penguins %&gt;% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))+\n  labs(x = 'Schnabellänge (mm)',\n       y = 'Körpergewicht (g)',\n       color = 'Pinguin-Spezies',\n       shape = 'Aggregations-Niveau') +\n  theme_light(base_family = 'Helvetica',\n              base_size = 10) +\n  theme(legend.position = 'bottom') +\n  guides(color = guide_legend(nrow = 3),\n         shape = guide_legend(nrow = 2))\n\nggsave(plot = p,\n       filename = 'imgs/penguin_scatter.png',\n       width = 6.56,units = 'in')\n\nSaving 6.56 x 5 in image\n\n\nDer Export sieht so aus:\n\n\n\nExportierte Grafik\n\n\nDer Plot ist für meinen Geschmack etwas zu sehr vertikal geraten, das können wir im Export mit “hight” anpassen:\n\nggsave(plot = p,\n       filename = 'imgs/shorter_penguin_scatter.png',\n       width = 6.56, height = 6, units = 'in')\n\n\n\nConvenient Standards\nDie beiden theme-Funktionen müssten wir so an jede Grafik anfügen. Solche Wiederholungen sind schlechter Stil und stören beim Lesen des Skripts, deswegen bietet ggplot2 convenience-Funktionen um allgemeine Einstellungen zu setzen. Mit dem folgenden Snippet am Anfang des Skripts werden die Standards für alle Grafiken genutzt:\n\nmy_theme &lt;-  theme_light(base_family = 'Helvetica',\n              base_size = 10) +\n  theme(legend.position = 'bottom')\n\ntheme_set(my_theme)\n\nSo kann ich jetzt beispielsweise einfach ein eingefärbtes Histogramm für die Flossen-Länge mit den gesetzten Standards erstellen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = flipper_length_mm,\n             fill = sex)) +\n  geom_histogram(binwidth = 5)",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#summary-layer",
    "href": "graphics.html#summary-layer",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Summary-Layer",
    "text": "Summary-Layer\nUm einer Grafik deskriptive Statistiken hinzuzufügen, gibt es mehrere Möglichkeiten. Eine haben wir bereits genutzt, indem wir ein geom erstellt haben, dass einen anderen Wert für das data-Argument5 übergeben bekommt:\n5 Oder halt wieder eine Lambda-Funktion als data-Argument\npenguin_means &lt;- palmerpenguins::penguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(across(c(bill_length_mm, \n                     body_mass_g), \n                   ~mean(., na.rm=T)))\n\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(x = species, \n             y = body_mass_g,\n             color = species))+ \n  geom_boxplot(alpha = .5) +\n  geom_point(data=penguin_means,\n             size = 3)+\n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\nAuf diese Art und Weise können wir natürlich beliebig viele Statistiken hinzufügen, so zum Beispiel Mittelwerte +/- SEMs und Text, der Anzahl der in die Mittelwerte einfließenden Werte beziffert:\n\npenguin_means &lt;- palmerpenguins::penguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(across(c(bill_length_mm, \n                     body_mass_g), \n                   .fns = list(mean = ~mean(., na.rm=T),\n                               n = ~sum(!is.na(.)),\n                               sem = ~sd(., na.rm = T)/sqrt(sum(!is.na(.))))))\n\npenguin_means %&gt;% \n1  ggplot(aes(color = species,\n                 x = species,\n                 y = body_mass_g_mean)) +\n2  geom_boxplot(data = palmerpenguins::penguins,\n               aes(y = body_mass_g)) +\n  geom_point(size = 3) +\n3  geom_errorbar(aes(ymin = body_mass_g_mean - body_mass_g_sem,\n                     ymax = body_mass_g_mean + body_mass_g_sem),\n                width = 0.5, lty = 2) +\n4  geom_text(aes(label = paste('N =', bill_length_mm_n)),\n5            position = position_nudge(x = 0.175, y = 30),\n            color = 'black') +\n  scale_color_viridis_d()\n\n\n1\n\nDa nur noch der erste geom_point-Layer die Koordinaten aus dem original-Datensatz zieht ist das wirklich einheitliche Mapping auf den gerade erstellten Datensatz bezogen.\n\n2\n\nAlle Layer nach diesem nutzen den erstellten Datensatz - so rum muss nur dem ersten Layer ein extra-Datenargument übergeben werden.\n\n3\n\ngeom_linerange und geom_errorbar brauchen Start- und Endpunkte der Fehlerbalken. Um die Koordinaten zu berechnen, können wir direkt im Mapping eine Funktion, hier den +-Operator aufrufen.\n\n4\n\nMit paste fügen wir den String zusammen.\n\n5\n\nMit position_nudge können wir die labels verschieben. Die genauen Werte kann man durch ausprobieren finden. Oder man nutzt das Paket ggrepel, das genau dieses Problem löst.\n\n\n\n\n\n\n\n\n\n\n\nAb einem bestimmten Punkt werden diese Operationen aber natürlich etwas unübersichtlich. Für diesen Fall bietet ggplot2 die stat_-Layer und die Lambda-Funktionen im data-Argument.\nDerselbe Graph lässt sich damit auch wie folgt erstellen:\n\npalmerpenguins::penguins %&gt;% \n  ggplot(aes(color = species,\n                 x = species,\n                 y = body_mass_g)) + \n  geom_boxplot() +\n  stat_summary() +\n  geom_text(data = ~ group_by(., species) %&gt;%  \n              summarise(n = sum(!is.na(body_mass_g)),\n                        body_mass_g = mean(body_mass_g, na.rm = T)),\n            aes(label = paste('N =', n)),\n            position = position_nudge(x = 0.175, y = 30),\n            color = 'black') +\n  scale_color_viridis_d()\n\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n\n\nDieser Graph ist auch ein gutes Beispiel, um Faktoren zur Gruppierung von kategorialen aesthetics zu besprechen.\nNeben den bisher besprochenen atomaren Variablentypen logical, numeric und character gibt es in R noch das etwas speziellere Format der factors.\nfactoren sind kategoriale Variablen, deren levels eine Ordnung zugewiesen werden kann. ggplot2 sortiert kategoriale Variablen erstmal nach Alphabet, Faktor-levels werden aber berücksichtigt.\nWir können uns zum Beispiel wünschen, dass die Spezies in der Reihenfolge Gentoo, Chinstrap, Adelie aufgelistet werden, also genau umgekehrt.\nDazu können wir die species-Variable in einer Pipeline in einen Faktor umwandeln und die levels entsprechend unserer Vorstellung sortieren:\n\npalmerpenguins::penguins %&gt;%\n  mutate(species = factor(species, levels = c('Gentoo', 'Chinstrap', 'Adelie'))) %&gt;% \n  ggplot(aes(color = species,\n                 x = species,\n                 y = body_mass_g)) + \n  geom_boxplot() +\n  stat_summary() +\n  geom_text(data = ~ group_by(., species) %&gt;%  \n              summarise(n = sum(!is.na(body_mass_g)),\n                        body_mass_g = mean(body_mass_g, na.rm = T)),\n            aes(label = paste('N =', n)),\n            position = position_nudge(x = 0.175, y = 30),\n            color = 'black') +\n  scale_color_viridis_d()\n\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n\n\nWie (so gut wie) immer bietet das tidyverse aber auch hier natürlich eine bequemere und flexiblere Lösung.\nMit dem forcats-Paket (Wickham, 2023) lassen sich Faktoren mit einer Reihe von Ordnungsfunktionen anordnen:\n\n\n\n\n\n\n\n\n\n\n\n(a) forcats::fct_infreq(species) - nach Anzahl\n\n\n\n\n\n\n\n\n\n\n\n(b) forcats::fct_reorder(species, body_mass_g) - nach Median einer anderen Variable\n\n\n\n\n\n\n\n\n\n\n\n(c) forcats::fct_rev(species) - umgedreht\n\n\n\n\n\n\n\nAbb 7.2: Drei Möglichkeiten, Faktoren mit forcats umzusortieren.\n\n\n\n\nAufgabe\nSie benötigen wieder die Worldbank-Daten.\nErstellen Sie einen Boxplot mit den Jahren von 2015 aufwärts auf der x-Achse und der Prevalence of severe food insecurity in the population (%) auf der y-Achse. Wandeln Sie dazu die Jahreszahlen in einen Faktor um.\nWenden Sie auf diesen Graphen ein theme Ihrer Wahl an.\n\n\n\nworldbank_indicators %&gt;% \n  filter(Year &gt; 2015) %&gt;% \n  mutate(Year = factor(Year)) %&gt;% \n  ggplot(aes(x = Year,\n             y = `Prevalence of severe food insecurity in the population (%)`)) +\n  geom_boxplot() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\nFügen Sie dem Graphen Mittelwerte als Punkte und Streuungen mit geom_errorbar hinzu.\nTun sie dies entweder mit einem neuen Datensatz oder gehen Sie die etwas anspruchsvollere Route, die Funktion (fun.data) der stat_summary-Funktion anzupassen.\n\n\n\nmeans_and_sds &lt;- worldbank_indicators %&gt;% \n  filter(Year &gt; 2015) %&gt;% \n  mutate(Year = factor(Year)) %&gt;% \n  group_by(Year) %&gt;% \n  summarise(m = mean(`Prevalence of severe food insecurity in the population (%)`, na.rm = T),\n            sd = sd(`Prevalence of severe food insecurity in the population (%)`, na.rm = T))\n\nworldbank_indicators %&gt;% \n  filter(Year &gt; 2015) %&gt;% \n  mutate(Year = factor(Year)) %&gt;% \n  ggplot(aes(x = Year)) +\n  geom_boxplot(aes(y = `Prevalence of severe food insecurity in the population (%)`)) +\n  geom_point(data = means_and_sds,\n             aes(y = m,\n                 pch = 'mean')) +\n  geom_errorbar(data = means_and_sds,\n                aes(ymin = m - sd,\n                    ymax = m + sd),\n                lty = 3) +\n  theme_light()\n\n\n\n\n\n\n\n## alternativ:\n\nrange_fun &lt;- \\(x)tibble(y = mean(x, na.rm = T),\n                                     ymin = y - sd(x, na.rm = T),\n                                     ymax = y + sd(x, na.rm = T))\n\nworldbank_indicators %&gt;% \n  filter(Year &gt; 2015) %&gt;% \n  mutate(Year = factor(Year)) %&gt;% \n  ggplot(aes(x = Year,\n             y = `Prevalence of severe food insecurity in the population (%)`)) +\n  geom_boxplot() +\n  stat_summary(fun.data = range_fun,\n               geom = \"errorbar\") +\n  stat_summary(fun.data = range_fun,\n               geom = \"point\") +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\nFärben Sie die hinzugefügten Statistiken rot ein. Übersetzen Sie die Achsen-Beschriftungen auf Deutsch und setzen Sie die Überschrift der Farb-Skala auf einen leeren String (’’).\n\n\n\nrange_fun &lt;- \\(x)tibble(y = mean(x, na.rm = T),\n                                     ymin = y - sd(x, na.rm = T),\n                                     ymax = y + sd(x, na.rm = T))\n\nworldbank_indicators %&gt;% \n  filter(Year &gt; 2015) %&gt;% \n  mutate(Year = factor(Year)) %&gt;% \n  ggplot(aes(x = Year,\n             y = `Prevalence of severe food insecurity in the population (%)`)) +\n  geom_boxplot() +\n  stat_summary(fun.data = range_fun,\n               geom = \"errorbar\",\n               aes(color = 'M+/-SD')) +\n  stat_summary(fun.data = range_fun,\n               geom = \"point\",\n               aes(color = 'M+/-SD')) +\n  theme_light() +\n  scale_color_manual(values = c('M+/-SD' = 'firebrick4')) +\n  labs(color = '',\n       y = 'Prävalenz von schwerer Ernährungsunsicherheit in der Bevölkerung (%)',\n       x = 'Jahr')\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\nHier ist ein etwas angepasstes theme, das ich für mich erstellt habe:\n\nmy_theme &lt;- \\(){\n  theme_minimal(base_size = 12) +\n    theme(\n      # Beschriftung allgemein:\n      text = element_text(colour = \"#335272\", family = \"DejaVu Sans\",\n                          lineheight = 1.1),\n      \n      # spezifische Beschriftungen:\n      plot.title = element_text(colour = '#01284F', family = \"DejaVu Sans\", \n                                size = rel(1.6), margin = margin(12, 0, 8, 0)),\n      plot.subtitle = element_text(size = rel(1.1), margin = margin(4, 0, 0, 0)),\n      axis.text.y = element_text(colour = \"#667E95\", size = rel(0.8)),\n      axis.title.y = element_text(size = rel(1), margin = margin(0, 4, 0, 0)),\n      axis.text.x = element_text(colour = \"#667E95\", size = rel(0.8)),\n      axis.title.x = element_text(size = rel(1), margin = margin(0, 4, 0, 0)),\n      plot.caption = element_text(size = rel(0.8), margin = margin(8, 0, 0, 0)),\n      \n      # Formatierung der Legenden:\n      legend.position = \"top\",\n      legend.justification = 1,\n      \n      # Formatierung des Orientierungs-grids:\n      panel.grid = element_line(colour = \"#F3F4F5\"),\n      panel.grid.major.x = element_line(colour = \"#F5F6F7\", linetype = 1, linewidth = 0.2),\n      panel.grid.minor.x = element_blank(),\n      panel.grid.major.y =  element_line(colour = \"#F5F6F7\", linetype = 1, linewidth = 0.2),\n      panel.grid.minor.y = element_blank(),\n      \n      # Formatierung der Einzüge und des Umrisses:\n      plot.margin = margin(0.25, 0.25, 0.25, 0.25,\"cm\"),\n      panel.border = element_rect(colour = \"#F3F4F5\", fill = NA, linetype = 1),\n      panel.background = element_rect(fill = NA))\n}\n\nBenutzen Sie dieses Beispiel und die Hilfeseite der theme-Funktion als Orientierung, um Ihre Grafik so unansehnlich wie möglich zu gestalten.\n\n\n\nworldbank_indicators %&gt;% \n  filter(Year &gt; 2015) %&gt;% \n  mutate(Year = factor(Year)) %&gt;% \n  ggplot(aes(x = Year,\n             y = `Prevalence of severe food insecurity in the population (%)`)) +\n  geom_boxplot() +\n  stat_summary(fun.data = range_fun,\n               geom = \"errorbar\",\n               aes(color = 'M+/-SD')) +\n  stat_summary(fun.data = range_fun,\n               geom = \"point\",\n               aes(color = 'M+/-SD')) +\n  scale_color_manual(values = c('M+/-SD' = 'firebrick4')) +\n  labs(color = '',\n       y = 'Prävalenz von schwerer Ernährungsunsicherheit in der Bevölkerung (%)',\n       x = 'Jahr') +\n    theme(\n      # Beschriftung allgemein:\n      text = element_text(colour = \"plum\", family = \"Zapf Dingbats\",\n                          lineheight = 1.1),\n      \n      # spezifische Beschriftungen:\n      plot.title = element_text(colour = 'olivedrab1', family = \"Zapf Dingbats\", \n                                size = rel(1.6), margin = margin(12, 0, 8, 0)),\n      plot.subtitle = element_text(size = rel(1.1), margin = margin(4, 0, 0, 0)),\n      axis.text.y = element_text(colour = \"hotpink\", size = rel(0.8)),\n      axis.title.y = element_text(size = rel(1), margin = margin(0, 4, 0, 0)),\n      axis.text.x = element_text(colour = \"black\", size = rel(0.8)),\n      axis.title.x = element_text(size = rel(1), margin = margin(0, 4, 0, 0)),\n      plot.caption = element_text(size = rel(0.8), margin = margin(8, 0, 0, 0)),\n      \n      # Formatierung der Legenden:\n      legend.position = \"top\",\n      legend.justification = 1,\n      \n      # Formatierung des Orientierungs-grids:\n      panel.grid = element_line(colour = \"black\"),\n      panel.grid.major.x = element_line(colour = \"black\", linetype = 3, linewidth = 8),\n      panel.grid.minor.x = element_blank(),\n      panel.grid.major.y =  element_line(colour = \"orange\", linetype = 1, linewidth = 16),\n      panel.grid.minor.y = element_blank(),\n      \n      # Formatierung der Einzüge und des Umrisses:\n      plot.margin = margin(0.25, 0.25, 0.25, 0.25,\"cm\"),\n      panel.border = element_rect(colour = \"purple\", fill = NA, linetype = 1),\n      panel.background = element_rect(fill = \"greenyellow\"))\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#hilfreiche-links",
    "href": "graphics.html#hilfreiche-links",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Hilfreiche Links",
    "text": "Hilfreiche Links\n\nfür einen Überblick über alle möglichen Kompenenten empfiehlt sich das von posit herausgegebene cheatsheet\ndas Kapitel zu Datenvisualisierungen in Grolemund & Wickham (2016) ist sehr gut und geht weiter ins Detail als hier möglich ist\nIm Paket ggpubr wird ggplot2 genutzt um eine Reihe von “publication ready plots” zu erstelllen\nUnter diesem Link ist eine shiny-App zur interaktiven Erstellung von ggplot-Graphen zu finden\nUnter diesem Link findet sich eine Sammlung von Farben, Formen, usw., die mit ggplot nutzbar sind.",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "graphics.html#literatur",
    "href": "graphics.html#literatur",
    "title": "Grammar of Graphics und ggplot2",
    "section": "Literatur",
    "text": "Literatur\n\n\n\n\nGrolemund, G., & Wickham, H. (2016). R for Data Science. https://r4ds.had.co.nz/\n\n\nWickham, H. (2010). A layered grammar of graphics. Journal of Computational and Graphical Statistics, 19(1), 3–28.\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2023). Forcats: Tools for working with categorical variables (factors). https://CRAN.R-project.org/package=forcats",
    "crumbs": [
      "Tag 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>*Grammar of Graphics* und `ggplot2`</span>"
    ]
  },
  {
    "objectID": "wrangling02.html",
    "href": "wrangling02.html",
    "title": "Zusammenführen von Datensätzen",
    "section": "",
    "text": "Aufgabe\nSie benötigen hier wieder die Datensätze aus der Aufgabe zum Import. Der Code zum Import war der folgende:\nlibrary(tidyverse)\ntemp &lt;-  read_csv2('data/temp.csv')\n## ℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n## Rows: 338 Columns: 3\n## ── Column specification ──────────────────────────\n## Delimiter: \";\"\n## dbl  (2): temp, cw\n## date (1): date\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nlibrary(haven)\ncovid_cases &lt;- read_sav(\"data/covid_cases.sav\")\n\nlibrary(readxl)\ncharts &lt;- read_excel(\"data/charts.xlsx\")\nFügen Sie den Covid und den Temperatur-Datensatz anhand der Kalenderwoche zusammen. Dabei sollen alle Zeilen, die im Temperatur-Datensatz vorliegen auch im neuen Datensatz vorliegen. Ersetzen Sie anschließend alle möglicherweise vorliegenden fehlenden Werte durch Nullen.\nBenennen Sie abschließend die Kalender-Wochen-Spalte in calendar_week und die Fall-Spalte im new_covid_cases um. Lesen Sie dazu die Hilfeseite der rename-Funktion\nSpeichern Sie sich den so erstellten Datensatz für später als ‘temp_covid.csv’ ab.",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Zusammenführen von Datensätzen</span>"
    ]
  },
  {
    "objectID": "wrangling02.html#pivotieren-von-datensätzen",
    "href": "wrangling02.html#pivotieren-von-datensätzen",
    "title": "Zusammenführen von Datensätzen",
    "section": "Pivotieren von Datensätzen",
    "text": "Pivotieren von Datensätzen\nFür SPSS-Nutzer:innen sehen viele Datensätze, die wir bisher gesehen haben, wahrscheinlich etwas seltsam aus. Das liegt vielleicht zum Teil daran, dass das tidyverse grundsätzlich das long-Format dem wide-Format vorzieht.\nDas folgende Beispiel der Ergebnisse der Bundestagswahlen nach 2002 1 illustriert vielleicht den Unterschied. Im wide-Format ist das zentrale Ziel dass pro Fall eine Zeile vorliegt, im long-Format wird pro Variable eine Spalte angelegt.\n1 gekürzt von https://www.bundestag.de/parlament/wahlen/ergebnisse_seit1949-244692\n\nlong-Format\n\n\n# A tibble: 35 × 3\n    Jahr Partei                Zweitstimmen\n   &lt;int&gt; &lt;chr&gt;                        &lt;dbl&gt;\n 1  2021 CDU/CSU                       24.1\n 2  2021 SPD                           25.7\n 3  2021 FDP                           11.5\n 4  2021 Bündnis 90/Die Grünen         14.8\n 5  2021 Die Linke. PDS                 4.9\n 6  2021 AfD                           10.3\n 7  2021 Sonstige                       8.7\n 8  2017 CDU/CSU                       32.9\n 9  2017 SPD                           20.5\n10  2017 FDP                           10.7\n# ℹ 25 more rows\n\n\n\nwide-Format\n\n\n# A tibble: 5 × 8\n   Jahr `CDU/CSU`   SPD   FDP\n  &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  2021      24.1  25.7  11.5\n2  2017      32.9  20.5  10.7\n3  2013      41.5  25.7   4.8\n4  2009      33.8  23    14.6\n5  2005      35.2  34.2   9.8\n# ℹ 4 more variables:\n#   `Bündnis 90/Die Grünen` &lt;dbl&gt;,\n#   `Die Linke. PDS` &lt;dbl&gt;, AfD &lt;dbl&gt;,\n#   Sonstige &lt;dbl&gt;\n\n\n\n\nBeide Formate haben Vorteile, im tidyverse ist das Hauptargument (neben Geschmaack) für das long-Format, dass sich so vektorisierte Funktionen direkt auf eine Variable anwenden lassen.\nUm zwischen den Formaten zu konvertieren gibt es im tidyverse die pivot_wider und pivot_longer Funktionen.\nDer Original-Datensatz zu den Bundestagswahlen sieht wie folgt aus:\n\nbundestagswahl\n\n# A tibble: 20 × 8\n    Jahr `CDU/CSU`   SPD   FDP\n   &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  2021      24.1  25.7  11.5\n 2  2017      32.9  20.5  10.7\n 3  2013      41.5  25.7   4.8\n 4  2009      33.8  23    14.6\n 5  2005      35.2  34.2   9.8\n 6  2002      38.5  38.5   7.4\n 7  1998      35.2  40.9   6.2\n 8  1994      41.5  36.4   6.9\n 9  1990      43.8  33.5  11  \n10  1987      44.3  37     9.1\n11  1983      48.8  38.2   7  \n12  1980      44.5  42.9  10.6\n13  1976      48.6  42.6   7.9\n14  1972      44.9  45.8   8.4\n15  1969      46.1  42.7   5.8\n16  1965      47.6  39.3   9.5\n17  1961      45.3  36.2  12.8\n18  1957      50.2  31.8   7.7\n19  1953      45.2  28.8   9.5\n20  1949      31    29.2  11.9\n# ℹ 4 more variables:\n#   `Bündnis 90/Die Grünen` &lt;dbl&gt;,\n#   `Die Linke. PDS` &lt;dbl&gt;, AfD &lt;dbl&gt;,\n#   Sonstige &lt;dbl&gt;\n\n\nWir würden gern eine ggplot-Grafik erstellen, in der die Verläufe der Stimmen über die Zeit dargestellt sind. Da wir alle Zweitstimmen-Prozente auf einem aesthetic darstellen wollen, brauchen wir den Datensatz aber natürlich im long-Format\nDas pivotieren geht mit pivot_longer auch sehr einfach:\n\nbtw_long &lt;- bundestagswahl %&gt;% \n  pivot_longer(-Jahr,\n               names_to = 'Partei',\n               values_to = 'Zweitstimmen')\nbtw_long\n\n# A tibble: 140 × 3\n    Jahr Partei                Zweitstimmen\n   &lt;int&gt; &lt;chr&gt;                        &lt;dbl&gt;\n 1  2021 CDU/CSU                       24.1\n 2  2021 SPD                           25.7\n 3  2021 FDP                           11.5\n 4  2021 Bündnis 90/Die Grünen         14.8\n 5  2021 Die Linke. PDS                 4.9\n 6  2021 AfD                           10.3\n 7  2021 Sonstige                       8.7\n 8  2017 CDU/CSU                       32.9\n 9  2017 SPD                           20.5\n10  2017 FDP                           10.7\n# ℹ 130 more rows\n\n\n\nWie erstelle ich damit jetzt einen line-chart?\n\n\n\n\nbtw_long %&gt;% \n  ggplot(aes(x = Jahr, y = Zweitstimmen, color = Partei)) +\n  geom_line(linewidth = 0.7) +\n  scale_color_manual(values = c(AfD = '#0489DB',\n                                'Bündnis 90/Die Grünen' = '#1AA037',\n                                CDU = '#000000',\n                                'Die Linke. PDS' = '#BD3075',\n                                FDP = '#FFEF00',\n                                Sonstige = 'darkgrey',\n                                SPD = '#E3000F'\n                                ))\n\nScale for colour is already present.\nAdding another scale for colour, which will\nreplace the existing scale.\n\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\nZu dieser Grafik wollen wir noch Mittlere Werte über die Zeit +/- Streuungen als Linien hinzufügen.\n\nWie ginge das denn mit summarise und across? Und wie könnte ich die Linien hinzufügen?\n\n\n\n\nbtw_summary &lt;- btw_long %&gt;% \n  group_by(Partei) %&gt;% \n  summarise('M' = mean(Zweitstimmen, na.rm=T),\n            'SD' = sd(Zweitstimmen, na.rm=T),\n            lower = M - SD,\n            upper = M + SD)\n\nDen Datensatz können wir jetzt benutzen:\n\nbtw_long %&gt;% \n  ggplot(aes(x = Jahr, y = Zweitstimmen, color = Partei)) +\n  geom_line(linewidth = 0.7) +\n  geom_hline(data = btw_summary,\n             aes(yintercept = M, color = Partei))+\n  geom_hline(data = btw_summary,\n             aes(yintercept = lower, color = Partei),\n             lty = 2)+\n  geom_hline(data = btw_summary,\n             aes(yintercept = upper, color = Partei),\n             lty = 2)+\n  scale_color_manual(values = c(AfD = '#0489DB',\n                                'Bündnis 90/Die Grünen' = '#1AA037',\n                                'CDU/CSU' = '#000000',\n                                'Die Linke. PDS' = '#BD3075',\n                                FDP = '#FFEF00',\n                                Sonstige = 'darkgrey',\n                                SPD = '#E3000F'\n                                )) \n\nScale for colour is already present.\nAdding another scale for colour, which will\nreplace the existing scale.\n\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\nUnter der Grafik wollen wir zum Schluss noch die Mittelwerte pro Partei hintereinander als Spalten darstellen. Das heißt, wir müssen die Tabelle ins wide-Format überführen. Auch dieser Schritt ist relativ einfach:\n\nbtw_summary %&gt;% \n  select(Partei, M) %&gt;% \n  pivot_wider(values_from = M,\n              names_from = Partei,\n              names_prefix = 'M ')\n\n# A tibble: 1 × 7\n  `M AfD` `M Bündnis 90/Die Grünen` `M CDU/CSU`\n    &lt;dbl&gt;                     &lt;dbl&gt;       &lt;dbl&gt;\n1     9.2                       8.3        41.2\n# ℹ 4 more variables: `M Die Linke. PDS` &lt;dbl&gt;,\n#   `M FDP` &lt;dbl&gt;, `M SPD` &lt;dbl&gt;,\n#   `M Sonstige` &lt;dbl&gt;\n\n\nDie pivot_wider-Funktion ist aber wesentlich mächtiger, was wir zum Beispiel sehen können wenn wir die Streuungen mit hinzufügen:\n\nbtw_summary %&gt;% \n  select(Partei, M, SD) %&gt;% \n  pivot_wider(values_from = c(M, SD),\n              names_from = Partei,\n              names_glue = '{.value} {Partei}')\n\n# A tibble: 1 × 14\n  `M AfD` `M Bündnis 90/Die Grünen` `M CDU/CSU`\n    &lt;dbl&gt;                     &lt;dbl&gt;       &lt;dbl&gt;\n1     9.2                       8.3        41.2\n# ℹ 11 more variables: `M Die Linke. PDS` &lt;dbl&gt;,\n#   `M FDP` &lt;dbl&gt;, `M SPD` &lt;dbl&gt;,\n#   `M Sonstige` &lt;dbl&gt;, `SD AfD` &lt;dbl&gt;,\n#   `SD Bündnis 90/Die Grünen` &lt;dbl&gt;,\n#   `SD CDU/CSU` &lt;dbl&gt;,\n#   `SD Die Linke. PDS` &lt;dbl&gt;, `SD FDP` &lt;dbl&gt;,\n#   `SD SPD` &lt;dbl&gt;, `SD Sonstige` &lt;dbl&gt;\n\n\nDie letzte Tabelle ließe sich natürlich auch direkt aus dem Ursprünglichen Datensatz erstellen…\n\nWie ginge das direkt mit summarise und across?\n\n\n\n\nbundestagswahl %&gt;% \n  summarise(across(-Jahr, \n                   .fns = list(mean = ~mean(., na.rm=T),\n                               sd = ~sd(., na.rm=T))))\n\n# A tibble: 1 × 14\n  `CDU/CSU_mean` `CDU/CSU_sd` SPD_mean SPD_sd\n           &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1           41.2         7.00     34.6   7.22\n# ℹ 10 more variables: FDP_mean &lt;dbl&gt;,\n#   FDP_sd &lt;dbl&gt;,\n#   `Bündnis 90/Die Grünen_mean` &lt;dbl&gt;,\n#   `Bündnis 90/Die Grünen_sd` &lt;dbl&gt;,\n#   `Die Linke. PDS_mean` &lt;dbl&gt;,\n#   `Die Linke. PDS_sd` &lt;dbl&gt;, AfD_mean &lt;dbl&gt;,\n#   AfD_sd &lt;dbl&gt;, Sonstige_mean &lt;dbl&gt;, …\n\n\n\n\nAntwort aufdecken\n\n\n\nAufgabe\nImportieren Sie nochmal den Worldbank-Datensatz aus dem Abschnitt zu Grammar of Graphics und ggplot2. Der Import funktionierte wie folgt:\n\nworldbank_indicators &lt;- read_excel(\"data/worldbank_indicators.xlsx\")\n\nFiltern Sie den Datensatz so, dass nur die Daten für die USA und die drei Variablen zur Lebenserwartung im Datensatz vorhanden sind.\nPivotieren Sie den Datensatz ins long-Format, so dass die Lebenserwartung in einer Variable vorliegt.\n\n\n\npivoted_data &lt;- worldbank_indicators %&gt;% \n  filter(`Country Name` == 'United States') %&gt;% \n  select(Year, matches('Life')) %&gt;% \n  pivot_longer(matches('Life'),\n               names_to = 'group',\n               values_to = 'Life Expectancy')\n\n\n\nAntwort aufdecken\n\n\nStellen Sie die drei Verläufe in einem facettierten Liniendiagramm dar. Wenn Sie Lust haben, nutzen Sie vorher str_extract um die Gruppe aus der Namensspalte zu extrahieren.\n\n\n\npivoted_data %&gt;% \n  mutate(group = str_extract(group, '\\\\w+al\\\\w*')) %&gt;% \n  ggplot(aes(x = Year, y = `Life Expectancy`)) +\n  geom_line() +\n  facet_wrap(~group)\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\nPivotieren Sie den pivotierten Datensatz anschließend so ins wide-Format, dass die Jahreszahlen in den Spalten und die Gruppen in den Zeilen stehen.\n\n\n\npivoted_data %&gt;% \n  mutate(group = str_extract(group, '\\\\w+al\\\\w*')) %&gt;% \n  pivot_wider(values_from = `Life Expectancy`,\n              names_from = Year,\n              names_prefix = 'Year_')\n\n# A tibble: 3 × 23\n  group  Year_2000 Year_2001 Year_2002 Year_2003\n  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 female      79.3      79.5      79.6      79.7\n2 male        74.1      74.3      74.4      74.5\n3 total       76.6      76.8      76.9      77.0\n# ℹ 18 more variables: Year_2004 &lt;dbl&gt;,\n#   Year_2005 &lt;dbl&gt;, Year_2006 &lt;dbl&gt;,\n#   Year_2007 &lt;dbl&gt;, Year_2008 &lt;dbl&gt;,\n#   Year_2009 &lt;dbl&gt;, Year_2010 &lt;dbl&gt;,\n#   Year_2011 &lt;dbl&gt;, Year_2012 &lt;dbl&gt;,\n#   Year_2013 &lt;dbl&gt;, Year_2014 &lt;dbl&gt;,\n#   Year_2015 &lt;dbl&gt;, Year_2016 &lt;dbl&gt;, …\n\n\n\n\nAntwort aufdecken",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Zusammenführen von Datensätzen</span>"
    ]
  },
  {
    "objectID": "tidymodels.html",
    "href": "tidymodels.html",
    "title": "tidymodels",
    "section": "",
    "text": "Modelltypen, Modes und Engines\nDie Modelldefinition funktioniert in tidymodels über das parsnip-Paket. Die Syntax besteht auf der Modellseite dabei immer aus einem Modelltyp, im Beispiel linear_reg.\nDabei gibt es für so gut wie jeden Anwendungsfall von statistischer oder ML-Modellierung einen Modelltyp, der das Problem abzubilden versucht. 2\nEin anderes Beispiel für einen Modelltypen ist ein rand_forest. Um unser Preis-Problem zu lösen könnten wir den Aufruf wie folgt gestalten: 3\nlibrary(bonsai)\npartykit_model &lt;- rand_forest(trees = 500) %&gt;% \n  set_mode('regression') %&gt;% \n  set_engine('partykit')\n\n\npartykit_fit &lt;- partykit_model %&gt;% \n  fit(price ~ sqft + beds, data = Sacramento)\n\npartykit_fit$fit %&gt;% \n  partykit::varimp()\n\n       sqft        beds \n18570726692   663613243\nRandom Forests können sowohl Klassifikations- als auch Regressions-Probleme lösen. Mit dem Zusatz set_mode zur Pipeline können wir deshalb spezifizieren, welche Art von Problem mit dem Modell gefittet werden soll.\nNach Definition von Modelltyp und mode folgt eine engine, mit der das Problem gelöst werden soll. In den Beispielen waren die engines erst lm aus stats, dann glmnet aus dem gleichnamigen Paket und abschließend der Wrapper keras_mlp um ein Keras-Netz aus dem parsnip-Paket. Zuletzt kam jetzt noch ein cforest aus dem partykit dazu.\nparsnip macht mit den Anweisungen nichts anderes, als daraus einen dem Paket angemessenen Template-Call zu formulieren. Diesen template-Call kann man sich exemplarisch für das zweite Beispiel wie folgt angucken:\nglmnet_model %&gt;% \n  translate()\n\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 0.95\n  mixture = 0.5\n\nComputational engine: glmnet \n\nModel fit template:\nglmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(), \n    alpha = 0.5, family = \"gaussian\")\nFür x, y und weights werden Platzhalter eingefügt, die dann im fit-Aufruf aufgefüllt werden.\nIm Output sieht man auch, welche Werte für die so genannten Main-Argumente gesetzt sind. parsnip unterscheidet nämlich zwischen denjenigen Parametern, die für viele oder gar alle einem Modelltyp angehörigen Modelle nötig sind und vereinheitlicht deren Aufruf. Diese verpflichtenden Modellparameter, z.B. der Grad der Regularisierung bei der linearen Regression, oder auch die Anzahl der zu trainierenden Bäume in einem Random Forest, werden dann direkt im ersten Modell-Call angegeben.\nDann gibt es aber noch für jede engine spezifische Argumente, deren Setzen für einen Großteil der anderen engines keinen Sinn ergäbe. Diese Engine-arguments können im set_engine-Call übergeben werden. So können wir unserer glmnet-Regression zum Beispiel die (zumindest diskutable) Anweisung auf den Weg geben, die Mietpreise als poisson-verteilt anzunehmen:\nglmnet_model &lt;- linear_reg(penalty = 0.95, mixture = 0.5) %&gt;% \n  set_engine('glmnet', family = 'poisson')\n\n\nglmnet_fit &lt;- glmnet_model %&gt;% \n  fit(price ~ sqft + beds, data = Sacramento)\n\ntidy(glmnet_fit)\n\n# A tibble: 3 × 3\n  term         estimate penalty\n  &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept) 11.7         0.95\n2 sqft         0.000493    0.95\n3 beds        -0.0556      0.95\nAlle standardmäßig implementierten möglichen Kombinationen von Modelltypen, Engines und Modes können in dieser Tabelle gefunden werden.",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>tidymodels</span>"
    ]
  },
  {
    "objectID": "tidymodels.html#modelltypen-modes-und-engines",
    "href": "tidymodels.html#modelltypen-modes-und-engines",
    "title": "tidymodels",
    "section": "",
    "text": "2 Im mit parsnip gelieferten Datensatz model_db ist eine (so weit ich das richtig sehe) nicht vollständige Liste der möglichen Modelle - hier werden allein 37 verschiedene Modelle gelistet.3 Für die partykit-engine sind die Zusatzpakete partykit und bonsai nötig.\n\n\n\n\n\n\n\n\n\n\n\nAufgabe\nFür diese Aufgaben benötigen Sie wieder den Datensatz der Worldbank, der Import lief so:\n\nlibrary(readxl)\nworldbank_indicators &lt;- read_excel(\"data/worldbank_indicators.xlsx\")\n\nFiltern Sie den Datensatz so, dass nur das Jahr 2019 vorliegt.\nFitten Sie die Daten mit zwei linearen Regressionsmodellen, einmal mit lm und einmal mit glm als engine. Setzen Sie für das quasi-Modell die family auf “quasi”. Dabei soll in beiden Fällen die mittlere Lebenserwartung als Kriterium mit dem Alkoholkonsum, dem GDP und dem Zugang zu Elektrizität vorhergesagt werden.\n\n\n\nfit_data &lt;- worldbank_indicators %&gt;% \n  filter(Year == 2019) %&gt;% \n  select(Lebenserwartung = `Life expectancy at birth, total (years)`,\n        GDP = `GDP per capita (current US$)`,\n        Zugang = `Access to electricity (% of population)`,\n        Alkoholkonsum = `Total alcohol consumption per capita (liters of pure alcohol, projected estimates, 15+ years of age)`)\n\nlm_model &lt;- linear_reg()\n\nlm_fit &lt;- lm_model %&gt;% \n  fit(Lebenserwartung ~ Zugang + GDP + Alkoholkonsum, data = fit_data)\n\ntidy(lm_fit)\n\n# A tibble: 4 × 5\n  term             estimate  std.error statistic p.value\n  &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)   -90.9       75.1          -1.21   0.244 \n2 Zugang          1.66       0.758         2.19   0.0437\n3 GDP             0.0000978  0.0000366     2.67   0.0167\n4 Alkoholkonsum   0.207      0.222         0.931  0.365 \n\nglm_model &lt;- linear_reg() %&gt;% \n  set_engine('glm', family = 'quasi')\n\nglm_fit &lt;- glm_model %&gt;% \n  fit(Lebenserwartung ~ Zugang + GDP + Alkoholkonsum, data = fit_data)\n\ntidy(glm_fit)\n\n# A tibble: 4 × 5\n  term             estimate  std.error statistic p.value\n  &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)   -90.9       75.1          -1.21   0.244 \n2 Zugang          1.66       0.758         2.19   0.0437\n3 GDP             0.0000978  0.0000366     2.67   0.0167\n4 Alkoholkonsum   0.207      0.222         0.931  0.365 \n\n\n\n\nAntwort aufdecken\n\n\nFitten Sie die Daten mit einem Random Forest mit randomForest als engine und 200 gefitteten Bäumen.\n\n\n\nrf_model &lt;- rand_forest(trees = 200) %&gt;% \n  set_mode('regression') %&gt;% \n  set_engine('randomForest')\n\nrf_fit &lt;- rf_model %&gt;% \n  fit(Lebenserwartung ~ Zugang + GDP + Alkoholkonsum, data = fit_data)\n\nrf_fit\n\nparsnip model object\n\n\nCall:\n randomForest(x = maybe_data_frame(x), y = y, ntree = ~200) \n               Type of random forest: regression\n                     Number of trees: 200\nNo. of variables tried at each split: 1\n\n          Mean of squared residuals: 4.709591\n                    % Var explained: 75.31\n\n\n\n\nAntwort aufdecken\n\n\nFügen Sie mit predict(&lt;Ihr Modell-fit&gt;, new_data=&lt;Datensatz&gt;) und mutate drei Spalten an Ihren Datensatz an, in denen die jeweiligen Modellvorhersagen angegeben sind. Eventuell müssen Sie das Ergebnis der predict-Funktion mit unlist in einen Vektor überführen.\n\n\n\nfit_data &lt;- fit_data %&gt;% \n  mutate(lm = unlist(predict(lm_fit, fit_data)),\n         glm = unlist(predict(glm_fit, fit_data)),\n         rf = unlist(predict(rf_fit, fit_data)))\n\n\n\nAntwort aufdecken\n\n\nPivotieren Sie den Datensatz ins long-Format, so dass alle Prognosen in einer Spalte vorliegen.\n\n\n\nfit_data &lt;- fit_data %&gt;% \n  pivot_longer(lm:rf,\n               values_to = 'Prognose',\n               names_to = 'Model')\n\n\n\nAntwort aufdecken\n\n\nErstellen Sie einen ggplot, der auf der x-Achse die Prognosen und auf der y-Achse die tatsächlichen Werte abträgt. Färben Sie die Punkte nach dem GDP ein, skalieren Sie auc hdie Größe der Punkte nach dem GDP. Facettieren Sie den Plot nach den drei Modellen. Fügen Sie der Grafik mit geom_abline eine schwarze Linie hinzu, die mit einer Steigung von 1 und einem Intercept von 0 eine Diagonale einzeichnet.\n\n\n\nfit_data %&gt;% \n  ggplot(aes(x = Prognose, y = Lebenserwartung, color = GDP, size = GDP)) +\n  geom_abline(intercept = 0, slope = 1) +\n  geom_point() +\n  facet_wrap(~Model) \n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>tidymodels</span>"
    ]
  },
  {
    "objectID": "tidymodels.html#recipes-und-workflows",
    "href": "tidymodels.html#recipes-und-workflows",
    "title": "tidymodels",
    "section": "Recipes und Workflows",
    "text": "Recipes und Workflows\n\nRecipes\nNeben dem Erstellen der Modelle bietet tidymodels auch pipeline-Interfaces für das standardisieren von der Vor- und Nachbereitung von Analysen. Das Vorbereiten können dabei relativ aufwändige Aufgaben des feature-Engineerings wie Methoden zur Dimensionsreduktion sein, aber auch für den inferenzstatistischen Alltag relevantere Schritte wie die Logarithmierung oder Dummyfizierung von Variablen.\nDas dafür genutzte Paket heißt passenderweise recipes. Wenn wir in unserem Wohnungs-Beispiel vor der Analyse die Prädiktoren standardisieren wollen, fangen wir mit der Definition eines Rezeptes an:\n\nmy_recipe &lt;- recipe(price ~ sqft + beds,\n                    data = Sacramento)\n\nDas Rezept können wir nun schrittweise ergänzen. Wenn alle Prädiktoren und vielleicht auch das Kriterium standardisieren wollen, müssen wir zuerst die Daten zentrieren und dann skalieren.\nDiese Schritte sind in recipes mit den angemessen als step-Funktionen benannten Anweisungen implementiert. Für die Schritte muss jeweils angegeben werden, auf welche Teile der Designmatrix die Operationen angewandt werden sollen.\nDazu können wir die schon bekannten tidy-select-helper nutzen, wir können aber auch die sepzifischen, von recipes gelieferten Auswahl-Helfer genutzt werden. Auf der mit ?selections aufrufbaren Hifleseite sind alle aufgelistet.\nWir wollen wie gesagt alle numerischen Variablen z-transformieren, ergänzen unser Rezept also wie folgt:\n\nmy_recipe &lt;- recipe(price ~ sqft + beds,\n                    data = Sacramento) %&gt;% \n  step_center(all_numeric()) %&gt;% \n  step_scale(all_numeric())\n\nWenn wir das Recipe aufrufen, wird uns eine Zusammenfassung unserer Vorbereitungsschritte angezeigt:\n\nmy_recipe\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:   1\npredictor: 2\n\n\n\n\n\n── Operations \n\n\n• Centering for: all_numeric()\n\n\n• Scaling for: all_numeric()\n\n\nNeben diesen Einfachen steps gibt es natürlich auch wesentlich kompliziertere, unter diesem Link sind alle implementierten Steps aufgelistet.\nDie für das Rezept nötigen “Zutaten” können wir uns mit prep vorbereiten lassen:\n\nmy_prep &lt;- my_recipe %&gt;% \n  prep(Sacramento)\n\nmy_prep\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:   1\npredictor: 2\n\n\n\n\n\n── Training information \n\n\nTraining data contained 932 data points and no incomplete rows.\n\n\n\n\n\n── Operations \n\n\n• Centering for: sqft, beds, price | Trained\n\n\n• Scaling for: sqft, beds, price | Trained\n\n\nUnd mit bake können wir das Rezept abschließend anwenden:\n\nscaled_data &lt;- my_prep %&gt;% \n  bake(Sacramento)\n\nscaled_data\n\n# A tibble: 932 × 3\n     sqft   beds price\n    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 -1.16  -1.44  -1.43\n 2 -0.707 -0.311 -1.36\n 3 -1.22  -1.44  -1.36\n 4 -1.14  -1.44  -1.35\n 5 -1.22  -1.44  -1.26\n 6 -0.769 -0.311 -1.20\n 7 -0.794 -0.311 -1.19\n 8 -0.693 -0.311 -1.19\n 9 -1.02  -1.44  -1.16\n10 -0.736 -0.311 -1.13\n# ℹ 922 more rows\n\n\nDiesen Datensatz können wir dann wieder nutzen, um eine Regression zu fitten:\n\nlm_model &lt;- linear_reg() \n\n\nlm_fit &lt;- lm_model %&gt;% \n  fit(price ~ sqft + beds, data = scaled_data)\n\nlm_fit %&gt;% \n  tidy()\n\n# A tibble: 3 × 5\n  term         estimate std.error statistic   p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)  3.04e-16    0.0206  1.47e-14 1.00e+  0\n2 sqft         8.94e- 1    0.0296  3.02e+ 1 2.95e-140\n3 beds        -1.76e- 1    0.0296 -5.96e+ 0 3.53e-  9\n\n\n\n\nWorkflows\nRezepte, Modelldefinition und -fit lassen sich im tidymodels-framework auch zu einer pipeline zusammenfügen.\nWie bei parsnip und recipes beginnt die Definition eines sogenannten Workflows aus workflows mit einer Objektdefinition.\n\nmy_wf &lt;- workflow()\n\nDiesem Workflow können wir dann Rezept und Modell hinzufügen:\n\nmy_wf &lt;- my_wf %&gt;% \n  add_recipe(my_recipe) %&gt;% \n  add_model(lm_model)\n\nAnschließend können wir den ganzen Workflow fitten:\n\nmy_wf %&gt;% \n  fit(data = Sacramento) %&gt;% \n  tidy()\n\n# A tibble: 3 × 5\n  term         estimate std.error statistic   p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)  3.04e-16    0.0206  1.47e-14 1.00e+  0\n2 sqft         8.94e- 1    0.0296  3.02e+ 1 2.95e-140\n3 beds        -1.76e- 1    0.0296 -5.96e+ 0 3.53e-  9\n\n\n\nWozu ist das jetzt nützlich?\n\nNützlich wird das, wenn wir eine Analyse z.B. auf mehreren Datensätzen durchführen wollen.\nOder einen Workflow einmal mit und einmal ohne Logarithmierung des Kriteriums ausprobieren wollen.\nMit update_recipe können wir das ganz einfach testen:\n\nmy_wf %&gt;%\n  update_recipe(my_recipe %&gt;%  step_log(all_outcomes())) %&gt;% \n  fit(data = Sacramento) %&gt;% \n  tidy()\n\nWarning in bake.step_log(x$steps[[i]], new_data = training): NaNs produced\n\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   -1.09     0.0724    -15.1  2.51e-40\n2 sqft           0.803    0.0746     10.8  1.20e-23\n3 beds          -0.303    0.0806     -3.76 2.01e- 4\n\n\nAußerdem lässt sich natürlich das Modell austauschen, wenn ich das möchte:\n\nmy_wf %&gt;%\n  update_model(keras_model) %&gt;% \n  fit(data = Sacramento)\n\nEpoch 1/20\n30/30 - 1s - loss: 0.7295 - 818ms/epoch - 27ms/step\nEpoch 2/20\n30/30 - 0s - loss: 0.5119 - 97ms/epoch - 3ms/step\nEpoch 3/20\n30/30 - 0s - loss: 0.4602 - 58ms/epoch - 2ms/step\nEpoch 4/20\n30/30 - 0s - loss: 0.4416 - 56ms/epoch - 2ms/step\nEpoch 5/20\n30/30 - 0s - loss: 0.4305 - 50ms/epoch - 2ms/step\nEpoch 6/20\n30/30 - 0s - loss: 0.4273 - 49ms/epoch - 2ms/step\nEpoch 7/20\n30/30 - 0s - loss: 0.4260 - 54ms/epoch - 2ms/step\nEpoch 8/20\n30/30 - 0s - loss: 0.4209 - 52ms/epoch - 2ms/step\nEpoch 9/20\n30/30 - 0s - loss: 0.4213 - 52ms/epoch - 2ms/step\nEpoch 10/20\n30/30 - 0s - loss: 0.4174 - 50ms/epoch - 2ms/step\nEpoch 11/20\n30/30 - 0s - loss: 0.4158 - 46ms/epoch - 2ms/step\nEpoch 12/20\n30/30 - 0s - loss: 0.4149 - 47ms/epoch - 2ms/step\nEpoch 13/20\n30/30 - 0s - loss: 0.4154 - 46ms/epoch - 2ms/step\nEpoch 14/20\n30/30 - 0s - loss: 0.4116 - 46ms/epoch - 2ms/step\nEpoch 15/20\n30/30 - 0s - loss: 0.4115 - 53ms/epoch - 2ms/step\nEpoch 16/20\n30/30 - 0s - loss: 0.4090 - 43ms/epoch - 1ms/step\nEpoch 17/20\n30/30 - 0s - loss: 0.4082 - 41ms/epoch - 1ms/step\nEpoch 18/20\n30/30 - 0s - loss: 0.4105 - 45ms/epoch - 2ms/step\nEpoch 19/20\n30/30 - 0s - loss: 0.4083 - 46ms/epoch - 2ms/step\nEpoch 20/20\n30/30 - 0s - loss: 0.4079 - 47ms/epoch - 2ms/step\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_center()\n• step_scale()\n\n── Model ───────────────────────────────────────────────────────────────────────\nModel: \"sequential\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n dense (Dense)                      (None, 128)                     384         \n dense_1 (Dense)                    (None, 1)                       129         \n================================================================================\nTotal params: 513 (2.00 KB)\nTrainable params: 513 (2.00 KB)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n\n\n\n\nAufgabe\nSie benötigen wieder den Datensatz der Worldbank. Erstellen Sie damit zwei Datensätze, einen mit den Daten zum Jahr 2019 und einen zum Jahr 2015. Beide Datensätze sollen die Gesamt-Lebenserwartung als Spalte mit dem Namen “target” enthalten, außerdem alle Variablen mit Ausnahme der Jahreszahl und der spezifischen Lebenserwartungen.\n\n\n\nworldbank_indicators &lt;- read_excel(\"data/worldbank_indicators.xlsx\")\n\nfit_data &lt;- worldbank_indicators %&gt;% \n  select(target = `Life expectancy at birth, total (years)`,\n         everything(),\n         - matches('ale'))\n\nfit_data_2015 &lt;- fit_data %&gt;% \n  filter(Year == 2015) %&gt;% \n  select(-Year)\n\nfit_data_2019 &lt;- fit_data %&gt;% \n  filter(Year == 2019) %&gt;% \n  select(-Year)\n\n\n\nAntwort aufdecken\n\n\nErstellen Sie einen Workflow, mit dem für alle numerische Variablen alle fehlenden Werte durch die Spalten-Mittelwerte ersetzt werden. Außerdem sollen alle numerischen Werte auf einen Wertebereich von 0 bis 1 skaliert werden. Die Liste aller Steps kann Ihnen dabei helfen. Entfernen Sie außerdem mit step_zv alle Spalten, die nur einen Wert enthalten. Der Workflow soll dann alle Variablen als Kriterium nutzen um die Variable target vorherzusagen. Anfänglich soll der Workflow eine lm-engine dazu nutzen.\n\n\n\nmy_recipe &lt;- recipe(target ~ ., data = fit_data_2015) %&gt;% \n  step_impute_mean(all_numeric_predictors()) %&gt;% \n  step_range(all_numeric_predictors()) %&gt;% \n  step_zv(all_predictors())\n\nlm_model &lt;- linear_reg() \n\nmy_wf &lt;- workflow() %&gt;% \n  add_recipe(my_recipe) %&gt;% \n  add_model(lm_model)\n\n\n\nAntwort aufdecken\n\n\nFitten Sie den Workflow auf die Datensätze zu den Jahren 2015 und 2019.\n\n\n\nlm_fit_2015 &lt;- my_wf %&gt;% \n  fit(data = fit_data_2015)\n\nWarning: Column `Electric power consumption (kWh per capita)` returned NaN. Consider\nusing `step_zv()` to remove variables containing only a single value.\n\nlm_fit_2019 &lt;- my_wf %&gt;% \n  fit(data = fit_data_2019)\n\nWarning: Column `Electric power consumption (kWh per capita)` returned NaN. Consider\nusing `step_zv()` to remove variables containing only a single value.\n\n\n\n\nAntwort aufdecken\n\n\nTauschen Sie das Modell gegen einen randomForest mit Regressions-Mode aus und fitten Sie wieder beide Modelle.\n\n\n\nrf_model &lt;- rand_forest() %&gt;% \n  set_mode('regression') %&gt;% \n  set_engine('randomForest')\n\nmy_wf &lt;- my_wf %&gt;% \n  update_model(rf_model)\n\nrf_fit_2015 &lt;- my_wf %&gt;% \n  fit(data = fit_data_2015)\n\nWarning: Column `Electric power consumption (kWh per capita)` returned NaN. Consider\nusing `step_zv()` to remove variables containing only a single value.\n\nrf_fit_2019 &lt;- my_wf %&gt;% \n  fit(data = fit_data_2019)\n\nWarning: Column `Electric power consumption (kWh per capita)` returned NaN. Consider\nusing `step_zv()` to remove variables containing only a single value.\n\n\n\n\nAntwort aufdecken\n\n\nErstellen Sie einen Datensatz mit allen Prognosen und targets. Pivotieren Sie diesen So, dass die targets in einer und die Prognosen in einer zweiten Spalte stehen. Nutzen Sie dazu zuerst das names_pattern-Argument der pivot_longer-Funktion und den .value-Platzhalter des names_to-Arguments. Anschließend müssen Sie vielleicht ein zweites Mal pivotieren. Lesen Sie die Hilfeseite der mape-Funktion aus dem yardstick Paket und nutzen Sie diese um die Modelle oberflächlich zu vergleichen.\n\n\n\nresults = tibble(target_2015 = fit_data_2015$target,\n                 target_2019 = fit_data_2019$target,\n                 lm_2015 = unlist(predict(lm_fit_2015, fit_data_2015)),\n                 lm_2019 = unlist(predict(lm_fit_2019, fit_data_2019)),\n                 rf_2015 = unlist(predict(rf_fit_2015, fit_data_2015)),\n                 rf_2019 = unlist(predict(rf_fit_2019, fit_data_2019))) %&gt;% \n  pivot_longer(everything(),\n               names_pattern = '(.+)_(.+)',\n               names_to = c('.value', 'year')) %&gt;% \n  pivot_longer(c(lm, rf))\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\", : prediction from rank-deficient fit; consider predict(.,\nrankdeficient=\"NA\")\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\", : prediction from rank-deficient fit; consider predict(.,\nrankdeficient=\"NA\")\n\nresults %&gt;% \n  group_by(name) %&gt;% \n  mape(target, value)\n\n# A tibble: 2 × 4\n  name  .metric .estimator .estimate\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 lm    mape    standard    5.33e-14\n2 rf    mape    standard    1.44e+ 0\n\n\n\n\nAntwort aufdecken",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>tidymodels</span>"
    ]
  },
  {
    "objectID": "tidymodels.html#inferenzstatistik-pipelines-mit-infer",
    "href": "tidymodels.html#inferenzstatistik-pipelines-mit-infer",
    "title": "tidymodels",
    "section": "Inferenzstatistik-Pipelines mit infer",
    "text": "Inferenzstatistik-Pipelines mit infer\nNeben der Kombination von parsnip und broom bietet tidymodels mit infer ein weiteres Paket für den inferenzstatistischen Einsatz.\ninfer stellt dabei ein einfaches Interface zur Formulierung von Hypothesen und deren Testung mit Bootstrapping, Permutationstests und anderen Randomisierungsverfahren zur Verfügung.\nDer Ablauf sieht dabei immer wie in Abbildung Infer-Workflow - von https://infer.tidymodels.org/ aus. Zuerst wird/werden mit specify die Variablen spezifiziert, die von Interesse sind. Daraufhin wird mit hypothesize in Textform angegeben, welche Nullhypothese man über diese Variablen testen will. Mit generate werden anschließend Daten generiert, die dieser Nullhypothese entsprechen. Abschließend kann mit calculate aus den generierten Werten eine Verteilung berechnet werden, die mit den beobachteten Werten verglichen werden kann.\n\n\n\n\n\n\nAbb 7.1: Infer-Workflow - von https://infer.tidymodels.org/\n\n\n\nWir könnten zum Beispiel die Annahme haben, dass die Art der Mietwohnungen unterschiedlich in den verschiedenen Städten verteilt sind. Die uns interessierenden Variablen sind also type und city. Das legen wir zuallererst mit specify fest:\n\nSacramento %&gt;% \n  specify(type ~ city)\n\nResponse: type (factor)\nExplanatory: city (factor)\n# A tibble: 932 × 2\n   type        city          \n   &lt;fct&gt;       &lt;fct&gt;         \n 1 Residential SACRAMENTO    \n 2 Residential SACRAMENTO    \n 3 Residential SACRAMENTO    \n 4 Residential SACRAMENTO    \n 5 Residential SACRAMENTO    \n 6 Condo       SACRAMENTO    \n 7 Residential SACRAMENTO    \n 8 Residential SACRAMENTO    \n 9 Condo       RANCHO_CORDOVA\n10 Residential RIO_LINDA     \n# ℹ 922 more rows\n\n\nUnsere Nullhypothese ist unabhängigkeit, die können wir also direkt hinzufügen:\n\nSacramento %&gt;% \n  specify(type ~ city) %&gt;% \n  hypothesize('independence')\n\nResponse: type (factor)\nExplanatory: city (factor)\nNull Hypothesis: independence\n# A tibble: 932 × 2\n   type        city          \n   &lt;fct&gt;       &lt;fct&gt;         \n 1 Residential SACRAMENTO    \n 2 Residential SACRAMENTO    \n 3 Residential SACRAMENTO    \n 4 Residential SACRAMENTO    \n 5 Residential SACRAMENTO    \n 6 Condo       SACRAMENTO    \n 7 Residential SACRAMENTO    \n 8 Residential SACRAMENTO    \n 9 Condo       RANCHO_CORDOVA\n10 Residential RIO_LINDA     \n# ℹ 922 more rows\n\n\nUm nun Daten für den Test zu generieren, können wir 1000 Datensätze mit Permuationen der Reihenfolge einer der Variablen generieren:\n\nSacramento %&gt;% \n  specify(type ~ city) %&gt;% \n  hypothesize('independence') %&gt;% \n  generate(reps = 1000, type = 'permute')\n\nResponse: type (factor)\nExplanatory: city (factor)\nNull Hypothesis: independence\n# A tibble: 932,000 × 3\n# Groups:   replicate [1,000]\n   type        city           replicate\n   &lt;fct&gt;       &lt;fct&gt;              &lt;int&gt;\n 1 Residential SACRAMENTO             1\n 2 Residential SACRAMENTO             1\n 3 Residential SACRAMENTO             1\n 4 Residential SACRAMENTO             1\n 5 Residential SACRAMENTO             1\n 6 Residential SACRAMENTO             1\n 7 Residential SACRAMENTO             1\n 8 Residential SACRAMENTO             1\n 9 Residential RANCHO_CORDOVA         1\n10 Residential RIO_LINDA              1\n# ℹ 931,990 more rows\n\n\nZuletzt müssen wir noch eine Teststatistik berechnen, deren Verteilung wir betrachten können. Bei unserem Fall bietet sich natürlich \\(\\chi^2\\) an:\n\nSacramento %&gt;% \n  specify(type ~ city) %&gt;% \n  hypothesize('independence') %&gt;% \n  generate(reps = 1000, type = 'permute') %&gt;% \n  calculate('Chisq')\n\nResponse: type (factor)\nExplanatory: city (factor)\nNull Hypothesis: independence\n# A tibble: 1,000 × 2\n   replicate  stat\n       &lt;int&gt; &lt;dbl&gt;\n 1         1  26.8\n 2         2 121. \n 3         3  46.1\n 4         4  61.5\n 5         5  96.6\n 6         6  36.0\n 7         7  98.2\n 8         8  42.0\n 9         9  68.1\n10        10  71.8\n# ℹ 990 more rows\n\n\nDie Verteilung können wir jetzt mit mitgelieferten ggplot2-Wrappern darstellen:\n\nSacramento %&gt;% \n  specify(type ~ city) %&gt;% \n  hypothesize('independence') %&gt;% \n  generate(reps = 1000, type = 'permute') %&gt;% \n  calculate('Chisq') %&gt;% \n  visualize()\n\n\n\n\n\n\n\n\nUnd wenn wir die beobachtete Teststatistik berechnen, können wir auch eine Signifikanz-Aussage tätigen:\n\nobs_chisq &lt;- Sacramento %&gt;% \n  specify(type ~ city) %&gt;% \n  calculate('Chisq')\n  \nSacramento %&gt;% \n  specify(type ~ city) %&gt;% \n  hypothesize('independence') %&gt;% \n  generate(reps = 1000, type = 'permute') %&gt;% \n  calculate('Chisq') %&gt;% \n  visualize() +\n  shade_p_value(obs_stat = obs_chisq, direction = \"greater\")\n\n\n\n\n\n\n\n\n\nAufgabe\nFür diese Aufgabe benötigen Sie den attrition-Datensatz, der mit tidymodels geliefert und geladen wird.\nVerschaffen Sie sich einen Überblick über den Datensatz. Wir benötigen die Variable Gender und die Variable HourlyRate.\nStellen Sie eine specify -&gt; hypothesize -&gt; generate-Pipeline für einen t-Test auf den Unterschied in HourlyRate zwischen den Auspärgungen von Gender auf. Lesen Sie die Hilfeseiten von hypothesize und generate um den richtigen Begriff für die angemessene Nullhypothese und das angemessene Sampling-Vorgehen zu bestimmen.\n\n\n\nhypothesis &lt;- attrition %&gt;% \n  specify(HourlyRate ~ Gender) %&gt;% \n  hypothesize('independence') %&gt;% \n  generate(reps = 1000, type = 'bootstrap')\n\n\n\nAntwort aufdecken\n\n\nBerechnen Sie mit calculate den empirischen t-Wert und vergleichen Sie ihn mit visualize mit der simulierten Verteilung.\n\n\n\nsimulated &lt;- attrition %&gt;% \n  specify(HourlyRate ~ Gender) %&gt;% \n  hypothesize('independence') %&gt;% \n  generate(reps = 1000, type = 'permute') %&gt;% \n  calculate('t', order = c('Male', 'Female'))\n\nobserved &lt;- attrition %&gt;% \n  specify(HourlyRate ~ Gender) %&gt;% \n  calculate('t', order = c('Male', 'Female'))\n\nsimulated %&gt;% \n  visualize() +\n  shade_p_value(obs_stat = observed, direction = \"two.sided\")\n\n\n\n\n\n\n\n\n\n\nAntwort aufdecken",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>tidymodels</span>"
    ]
  },
  {
    "objectID": "quarto.html",
    "href": "quarto.html",
    "title": "quarto",
    "section": "",
    "text": "Code-chunks\nDer große Vorteil quartos ist es, dass wir Code-chunks im Dokument anlegen können, deren Output direkt in das gerenderte Ergebnis eingebunden wird.\nDazu kann mit der “Insert new code chunk”-Schaltfläche (1 in Abbildung Neuen Chunk erstellen.) oben rechts oder Strg + Alt + I ein neuer Chunk eingefügt werden, der an die Cursor-Stelle im Dokument eingefügt wird (2).\nIn der ersten Zeile des neuen Chunks steht die Sprache. In den Chunk kann dann wie in ein R-Skript Code eingefügt werden.\nDamit haben wir die Basics die wir brauchen.",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>`quarto`{#sec-quarto}</span>"
    ]
  },
  {
    "objectID": "quarto.html#code-chunks",
    "href": "quarto.html#code-chunks",
    "title": "quarto",
    "section": "",
    "text": "Abb 8.3: Neuen Chunk erstellen.\n\n\n\n\n\n\n\n\n\n\n\n\nAbb 8.4: Code Chunks mit bisherigen Analysen.\n\n\n\n\nIn Abbildung Code Chunks mit bisherigen Analysen. ist das neue file mit dem Code für die Grafik aus Grammar of Graphics und ggplot2 eingefügt.\nDer erste Chunk (1) ist dabei nur dafür da um Pakete und die Daten zu laden und ein theme zu setzen. Im zweiten Chunk (2) wird die Grafik erstellt.\nWie in (3) und (4) zu sehen ist, kann zwischen den Chunks einfach Text eingefügt werden.\nDie Chunks können dabei wie ein ganz normales R-Skript genutzt werden und der Code an der Zeile des Cursors kann mit Strg + Enter ausgeführt werden. Der Output erscheint dabei unter dem Chunk, kann mit Hilfe der Einstellungen aber auch in die Konsole verschoben werden.",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>`quarto`{#sec-quarto}</span>"
    ]
  },
  {
    "objectID": "quarto.html#yaml-header",
    "href": "quarto.html#yaml-header",
    "title": "quarto",
    "section": "YAML-Header",
    "text": "YAML-Header\nUm das Ergebnis des Renderns anzupassen können wir den YAML-Header setzen.\nFür dieses Skript konzentrieren wir uns auf Output im docx-Format, Quarto bietet aber wesentlich mehr Optionen. Die Doku für alle unterstützten Header-Optionen für docx findet sich hier.\nFür uns sind erstmal die folgenden Parameter wichtig:\nformat: docx # setzt das Format des Outputs\nfig-width: 6.56 # setzt 6.56 Zoll als Standard-Breite für alle Plot-Outputs\nfig-dpi: 300 # setzt alle plots auf 300 dpi\nNach Klick auf “Render” kann ich neben dem erstellten qmd-file das in Abbildung Erstes Render-Ergebnis. abgebildete Dokument finden.\n\n\n\n\n\n\nAbb 8.5: Erstes Render-Ergebnis.\n\n\n\nDer Output der Chunks wurde also erfolgreich in das Dokument übergeben, ich brauche aber die ganzen messages nicht.\nUm diese zu unterdrücken kann ich den YAML-Header einfach um den folgenden Teil ergänzen:\nexecute:\n  warning: false\n  message: false\nExecute im YAML-Header setzt dabei Ausführungsstandards für alle Code-Chunks im Dokument. warning: false unterdrückt alle Warnungen, message: false alle Nachrichten von Paketen, etc. im Output.\nWas zu folgendem Output führt:\n Schon viel besser, für einen Bericht stört aber noch der Code zwischen den Outputs. Um das Rausschreiben der Chunks zu unterdrücken ergänzen wir nur noch echo: false um bei folgendem vollständigen Header zu enden:\ntitle: \"Methoden\"\neditor: visual\nformat: docx\nfig-width: 6.56\nfig-dpi: 300\nexecute:\n  warning: false\n  message: false\n  echo: false\nUnd schon ist das Ergebnis nicht mehr allzu schlecht:\n\n\n\n\n\n\nAbb 8.6: Ergebnis ohne Chunks",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>`quarto`{#sec-quarto}</span>"
    ]
  },
  {
    "objectID": "quarto.html#code-chunk-optionen",
    "href": "quarto.html#code-chunk-optionen",
    "title": "quarto",
    "section": "Code-Chunk-Optionen",
    "text": "Code-Chunk-Optionen\nDie letzten drei Parameter waren Beispiele für chunk-Optionen, die das Verhalten von Chunks anpassen. Das kann entweder global im YAML-Header unter execute oder lokal pro Chunk gesetzt werden.\nAuf der quarto-Seite gibt es einen Überblick über alle Optionen, wir konzentrieren uns aber erstmal auf einen kleinen Teil zur Beschriftung von Grafiken.\nUm eine Grafik zu beschriften und im Text referenzierbar zu machen, müssen wir zwei Optionen für den Chunk setzten: label und fig-cap. In Abbildung Chunk-Optionen für Grafiken ist ein Beispiel wie das aussehen könnte. Die Chunk-Optionen werden dabei immer durch ein so genanntes “pipe-comment” eingeleitet.\n\n\n\n\n\n\nAbb 8.7: Chunk-Optionen für Grafiken\n\n\n\nIm text können wir die Grafik dann mit @fig-scatter referenzieren. Das label für Grafiken muss dabei durch “fig-” eingeleitet und referenziert werden, sonst schlägt die Formatierung fehl.\nDer Output des so angepassten Skripts ist in Abbildung Ergebnis mit Cross-Referenzen zu sehen.\n\n\n\n\n\n\nAbb 8.8: Ergebnis mit Cross-Referenzen\n\n\n\nIn dem Beispiel ist außerdem ein weiterer Vorteil von Quarto zu sehen: Inline Code-Chunks",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>`quarto`{#sec-quarto}</span>"
    ]
  },
  {
    "objectID": "quarto.html#sec-inline",
    "href": "quarto.html#sec-inline",
    "title": "quarto",
    "section": "Inline Code-Chunks",
    "text": "Inline Code-Chunks\nIm Fließtext kann mit der folgenden Syntax auf R zugegriffen und Output generiert werden:\n`r &lt;some code&gt;`\nWozu ist das nützlich? Wir können so einfach statistische Kennwerte ohne sie kopieren zu müssen in den Text einfließen lassen! Und jedes mal wenn das Ergebnis erstellt wird, werden die Werte neu berechnet. So kann keine Aktualisierung vergessen werden.\nWir könnten unserem Beispiel-File so beispielsweise eine Stichprobenbeschreibung hinzufügen, wie in Abbildung Inline Chunk zu sehen ist.\n\n\n\n\n\n\nAbb 8.9: Inline Chunk\n\n\n\nDie Ergebnisse im docx können in Abbildung Gerendertes Ergebnis der Inline-Chunks gesehen werden.\n\n\n\n\n\n\nAbb 8.10: Gerendertes Ergebnis der Inline-Chunks\n\n\n\nDas hier gezeigte Beispiel ist auch im Repo des Skripts zugänglich. Außerdem sind dort alle für die Erstellung dieses Skripts nötigen files zu finden.",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>`quarto`{#sec-quarto}</span>"
    ]
  },
  {
    "objectID": "quarto.html#aufgabe",
    "href": "quarto.html#aufgabe",
    "title": "quarto",
    "section": "Aufgabe",
    "text": "Aufgabe\n\nÜbertragen Sie Ihre Ergebnisse aus den Aufgaben zu tidymodels in ein quarto-Dokument.\nBeschriften Sie alle Grafiken.\nRendern Sie das Dokument als docx.",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>`quarto`{#sec-quarto}</span>"
    ]
  },
  {
    "objectID": "quarto.html#zusammenarbeit",
    "href": "quarto.html#zusammenarbeit",
    "title": "quarto",
    "section": "Zusammenarbeit",
    "text": "Zusammenarbeit\nDer größte Nachteil an Quarto ist der etwas umständlichere Workflow beim Kommentieren und Zusammenarbeiten als das in Word möglich ist.\nDie Dokumente können zwar immer in word gerendert und dann ausgetauscht werden, etwaige Anmerkungen können aber nicht direkt in Quarto eingepflegt werden.\nUnter diesem Link findet sich aber eine Anleitung, wie man die Zusammenarbeit über git ermöglichen kann.\nAußerdem ist dort auch eine Anleitung zu finden, wie sich im Source-Editor mit quarto zitieren lässt. Für das Zitieren im allgemeinen ist der quarto-Guide zu diesem Thema ein guter Anlaufpunkt.",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>`quarto`{#sec-quarto}</span>"
    ]
  },
  {
    "objectID": "tables.html",
    "href": "tables.html",
    "title": "Tabellen und Ergebnisdarstellungen",
    "section": "",
    "text": "Export mit apaTables\nJetzt, wo wir unsere Auswertungen automatisiert und in schöne Dokumente eingebunden haben, wollen wir natürlich unsere Tabellen und Daten möglichst wenig a) händisch übertragen und b) formatieren.\nDie erste Möglichkeit ist es, vor allem beim Verzicht auf quarto, alles, was an Zahlen und Tabellen für den Text anfällt, direkt in files die wir einfach einbinden können zu exportieren.\nFür ANOVAs, Regressionen, t-Tests und Korrelationsanalysen gibt es im apaTables-Paket(Stanley, 2021) fertige Wrapper, die einen direkten Export der Tabellen ins doc-Format umsetzen.\nUnter den folgenden Links finden sich die Dokumentation der einzelnen Funktionen aufgelistet:\nAußerdem sind im Tutorial Beispiele für alle implementierten Verfahren und Tabellen zu finden.\nEin einfaches Beispiel ist der Export der Tabelle der Parameter-Fits für das erste Sacramento-Beispiel aus tidymodels:\nlm_model &lt;- linear_reg()\n\nlm_fit &lt;- lm_model %&gt;% \n  fit(price ~ sqft + beds, data = Sacramento)\nMit apa.reg.table können gewünschte Tabellen dann exportiert werden. Laut der Doku ist dabei noch wichtig, mit options eine Anzahl an Dezimalstellen vor Umwandlung in 10-er-Potenz-Notation zu setzen, die mindestens 10 ist.\nlibrary(apaTables)\noptions(digits = 10)\n\n\napa.reg.table(lm_fit$fit,\n              table.number = 1,\n              filename = \"Table1_APA.doc\")\n\n\n\nTable 1 \n\nRegression results using price as the criterion\n \n\n   Predictor           b               b_95%_CI  beta    beta_95%_CI sr2\n (Intercept)  60850.54**   [40392.19, 81308.90]                         \n        sqft    161.34**       [150.86, 171.81]  0.89   [0.84, 0.95] .39\n        beds -26035.15** [-34604.71, -17465.58] -0.18 [-0.23, -0.12] .02\n                                                                        \n                                                                        \n                                                                        \n sr2_95%_CI     r             Fit\n                                 \n [.34, .43] .77**                \n [.01, .03] .46**                \n                      R2 = .604**\n                  95% CI[.57,.63]\n                                 \n\nNote. A significant b-weight indicates the beta-weight and semi-partial correlation are also significant.\nb represents unstandardized regression weights. beta indicates the standardized regression weights. \nsr2 represents the semi-partial correlation squared. r represents the zero-order correlation.\nSquare brackets are used to enclose the lower and upper limits of a confidence interval.\n* indicates p &lt; .05. ** indicates p &lt; .01.\nDas table_number-Argument setzt dabei nur die Zahl in der Tabellen-Überschrift.\nDas Ergebnis ist in Abbildung Output von apa.reg.table zu sehen.\nWenn wir die Tabelle in ein externes file exportieren, müssen wir sie aber natürlich am Ende wieder kopieren, um sie in unsere Berichte zu kopieren.\nAngenehmer wäre es natürlich, wenn wir die Tabellen direkt in unser quarto-Dokument einbinden könnten.\napaTables unterstützt diese Möglichkeit in der aktuellen Version 3.0.0 - auf Cran ist die neueste Version aber leider die 2.0.8, die diese Funktionalität noch nicht unterstützt. Sollte diese Lösung geünscht sein, lässt sich die neuere Version wie folgt direkt von github installieren:\ninstall.packages(\"remotes\")\n\nremotes::install_github(\"dstanley4/apaTables\")\n\nlibrary(apaTables)",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tabellen und Ergebnisdarstellungen</span>"
    ]
  },
  {
    "objectID": "tables.html#export-mit-apatables",
    "href": "tables.html#export-mit-apatables",
    "title": "Tabellen und Ergebnisdarstellungen",
    "section": "",
    "text": "Korrelationsanalyse\nANOVA mit ezANOVA\nRegressionsanalyse\nZusammenfassungstabelle für deskriptive Maße, 1 Faktor\nZusammenfassungstabelle für deskriptive Maße, 2 Faktoren\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbb 9.1: Output von apa.reg.table\n\n\n\n\n\n\n\n\nAufgaben\n\nAufgabe 1\nErstellen Sie eine Tabelle mit den deskriptiven Kennwerten der Blütenblatt-Länge pro Spezies im iris-Datensatz mit apaTables. Gucken Sie sich dafür die Dokumentation der apa.1way.table-Funktion an.\n\n\n\napa.1way.table(iv=Species, dv=Petal.Length, data = iris)\n\n\n\nDescriptive statistics for Petal.Length as a function of Species.  \n\n    Species    M   SD\n     setosa 1.46 0.17\n versicolor 4.26 0.47\n  virginica 5.55 0.55\n\nNote. M and SD represent mean and standard deviation, respectively.\n \n\n\n\n\nAntwort aufdecken\n\n\n\n\nAufgabe 2\nBenutzen Sie die apa.cor.table-Funktion um eine Korrelationsanalyse für alle numerischen Variablen im iris-Datensatz durchzuführen.\n\n\n\napa.cor.table(iris)\n\n\n\nMeans, standard deviations, and correlations with confidence intervals\n \n\n  Variable        M    SD   1           2            3         \n  1. Sepal.Length 5.84 0.83                                    \n                                                               \n  2. Sepal.Width  3.06 0.44 -.12                               \n                            [-.27, .04]                        \n                                                               \n  3. Petal.Length 3.76 1.77 .87**       -.43**                 \n                            [.83, .91]  [-.55, -.29]           \n                                                               \n  4. Petal.Width  1.20 0.76 .82**       -.37**       .96**     \n                            [.76, .86]  [-.50, -.22] [.95, .97]\n                                                               \n\nNote. M and SD are used to represent mean and standard deviation, respectively.\nValues in square brackets indicate the 95% confidence interval.\nThe confidence interval is a plausible range of population correlations \nthat could have caused the sample correlation (Cumming, 2014).\n * indicates p &lt; .05. ** indicates p &lt; .01.\n \n\n\n\n\nAntwort aufdecken",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tabellen und Ergebnisdarstellungen</span>"
    ]
  },
  {
    "objectID": "tables.html#tabellen-mit-flextable",
    "href": "tables.html#tabellen-mit-flextable",
    "title": "Tabellen und Ergebnisdarstellungen",
    "section": "Tabellen mit flextable",
    "text": "Tabellen mit flextable\nEine andere Möglichkeit um Tabellen zu erstellen, die via cran verfügbar ist, ist das Paket flextable(Gohel & Skintzos, 2023).\nIm Gegensatz zu apaTables kann in diesem Framework alles in eine Tabelle gerendert werden, die Tabellen können außerdem sehr frei gestaltet werden. Dafür gibt es aber nicht wirklich Standards wie z.B. Formatierung nach APA.\nUm die Funktionalität auszuprobieren, wird im Folgenden beispielhaft eine Tabelle grob an APA orientiert formatiert.\nAn Tabellen direkt wird in den Guidelines folgende Anforderungen gestellt:\n\nJede Spalte muss eine Überschrift haben, auch die “stub”-Spalte\ndie Überschriften müssen zentriert sein\nder Inhalt der “stub”-Spalte muss linksbündig sein\nAlle Spalten sollen zentriert sein, es sei denn der Inhalt ist linksbündig besser lesbar (z.B. bei Textspalten)\nAnforderungen an Abstand und Schriftgröße in der Tabelle\n\nAußerdem kommen noch die folgenden Anforderungen an die Formatierung statistischer Ergebnisse1 hinzu:\n1 laut https://apastyle.apa.org/style-grammar-guidelines/tables-figures/tables und https://www.scribbr.com/apa-style/numbers-and-statistics/\nNamen statistischer Kennwerte sollen kursiv sein\nZahlen sollen auf den Wert gerundet werden, bei dem die Präzision erhalten wird\nWerte die nicht größer als 1 werden können sollen keine Null vor dem Komma haben\n\nFangen wir mit der Formatierung der Nummern an. Als Beispiel haben wir die folgende Tabelle, in der die mittlere Schnabellänge und Standardabweichung pro Pinguin-Spezies und Beobachtungsort aus dem palmerpenguins-Datensatz abgetragen sind:\n\nsummary_table &lt;- palmerpenguins::penguins %&gt;%\n  group_by(species, island) %&gt;%\n  summarise(across(matches(\"bill_length_mm\"),\n                   .fns = list(\n                     M = \\(x) mean(x, na.rm = T),\n                     SD = \\(x) sd(x, na.rm = T)\n                   ),\n                   .names = \"{.col}_{.fn}\")) %&gt;% # Damit Funktion hinten steht\n  pivot_wider(names_from = 'island',\n              values_from = 3:4,\n              names_glue = \"{island}_{.value}\") # Damit Insel vorne steht\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\nsummary_table\n\n# A tibble: 3 × 7\n# Groups:   species [3]\n  species   Biscoe_bill_length_m…¹ Dream_bill_length_mm_M Torgersen_bill_lengt…²\n  &lt;fct&gt;                      &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n1 Adelie                      39.0                   38.5                   39.0\n2 Chinstrap                   NA                     48.8                   NA  \n3 Gentoo                      47.5                   NA                     NA  \n# ℹ abbreviated names: ¹​Biscoe_bill_length_mm_M, ²​Torgersen_bill_length_mm_M\n# ℹ 3 more variables: Biscoe_bill_length_mm_SD &lt;dbl&gt;,\n#   Dream_bill_length_mm_SD &lt;dbl&gt;, Torgersen_bill_length_mm_SD &lt;dbl&gt;\n\n\nZuerstmal sortieren wir die Spalten so, dass Pro Ort erst Mittelwert, dann SD steht:\n\nsummary_table %&gt;% \n  select(species, matches('Bis'), matches('Dre'), matches('Tor'))\n\n# A tibble: 3 × 7\n# Groups:   species [3]\n  species   Biscoe_bill_length_m…¹ Biscoe_bill_length_m…² Dream_bill_length_mm_M\n  &lt;fct&gt;                      &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n1 Adelie                      39.0                   2.48                   38.5\n2 Chinstrap                   NA                    NA                      48.8\n3 Gentoo                      47.5                   3.08                   NA  \n# ℹ abbreviated names: ¹​Biscoe_bill_length_mm_M, ²​Biscoe_bill_length_mm_SD\n# ℹ 3 more variables: Dream_bill_length_mm_SD &lt;dbl&gt;,\n#   Torgersen_bill_length_mm_M &lt;dbl&gt;, Torgersen_bill_length_mm_SD &lt;dbl&gt;\n\n\nDann legen wir die Dezimalstellen auf eine Nachkommastelle fest:\n\nsummary_table %&gt;% \n  select(species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1)))\n\n# A tibble: 3 × 7\n# Groups:   species [3]\n  species   Biscoe_bill_length_m…¹ Biscoe_bill_length_m…² Dream_bill_length_mm_M\n  &lt;fct&gt;                      &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n1 Adelie                      39                      2.5                   38.5\n2 Chinstrap                   NA                     NA                     48.8\n3 Gentoo                      47.5                    3.1                   NA  \n# ℹ abbreviated names: ¹​Biscoe_bill_length_mm_M, ²​Biscoe_bill_length_mm_SD\n# ℹ 3 more variables: Dream_bill_length_mm_SD &lt;dbl&gt;,\n#   Torgersen_bill_length_mm_M &lt;dbl&gt;, Torgersen_bill_length_mm_SD &lt;dbl&gt;\n\n\nUnd schon können wir an die eigentliche Formatierung in einer Tabelle gehen. Dazu nutzen wir, wie schon angekündigt, das Paket flextable.\nWir können unsere Tabelle direkt in flextable pipen:\n\nlibrary(flextable)\n\n\nAttaching package: 'flextable'\n\n\nThe following object is masked from 'package:purrr':\n\n    compose\n\nsummary_table %&gt;% \n  select(species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  flextable()\n\nspeciesBiscoe_bill_length_mm_MBiscoe_bill_length_mm_SDDream_bill_length_mm_MDream_bill_length_mm_SDTorgersen_bill_length_mm_MTorgersen_bill_length_mm_SDAdelie39.02.538.52.5393Chinstrap48.83.3Gentoo47.53.1\n\n\nAls erstes können wir den Header trennen:\n\nsummary_table %&gt;% \n  select(species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  flextable() %&gt;% \n  separate_header()\n\nspeciesBiscoeDreamTorgersenbilllengthmmMSDMSDMSDAdelie39.02.538.52.5393Chinstrap48.83.3Gentoo47.53.1\n\n\nDie bill-length kann weg, am besten entfernen wir die schon vor der Umwandlung in eine flextable:\n\nsummary_table %&gt;% \n  select(species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  rename_with(.fn = ~str_remove(.,'bill_length_mm')) %&gt;% \n  flextable() %&gt;% \n  separate_header()\n\nspeciesBiscoeDreamTorgersenMSDMSDMSDAdelie39.02.538.52.5393Chinstrap48.83.3Gentoo47.53.1\n\n\n“Spezies” können wir auch in deutsch übertiteln:\n\nsummary_table %&gt;% \n  select(Spezies = species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  rename_with(.fn = ~str_remove(.,'_bill_length_mm')) %&gt;% \n  flextable() %&gt;% \n  separate_header()\n\nSpeziesBiscoeDreamTorgersenMSDMSDMSDAdelie39.02.538.52.5393Chinstrap48.83.3Gentoo47.53.1\n\n\nUnd die statistischen Kennwerte kursiv setzen:\n\nsummary_table %&gt;% \n  select(Spezies = species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  rename_with(.fn = ~str_remove(.,'_bill_length_mm')) %&gt;% \n  flextable() %&gt;% \n  separate_header() %&gt;% \n  style(i = 2,part = 'header',\n        pr_t = fp_text_default(italic = T))\n\nSpeziesBiscoeDreamTorgersenMSDMSDMSDAdelie39.02.538.52.5393Chinstrap48.83.3Gentoo47.53.1\n\n\nIm flextable-Paket gibt es außerdem die theme_apa-Funktion, die den Text und die Abstände nach APA formatiert:\n\nsummary_table %&gt;% \n  select(Spezies = species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  rename_with(.fn = ~str_remove(.,'_bill_length_mm')) %&gt;% \n  flextable() %&gt;% \n  separate_header() %&gt;%\n  italic(part =\"header\", i= 2) %&gt;% \n  theme_apa()\n\nSpeziesBiscoeDreamTorgersenMSDMSDMSDAdelie39.002.5038.502.5039.003.00Chinstrap48.803.30Gentoo47.503.10\n\n\nAußerdem können wir Linien unter den Inseln einfügen:\n\nsummary_table %&gt;% \n  select(Spezies = species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  rename_with(.fn = ~str_remove(.,'_bill_length_mm')) %&gt;% \n  flextable() %&gt;% \n  separate_header() %&gt;%\n  italic(part =\"header\", i= 2) %&gt;% \n  theme_apa() %&gt;% \n  hline(i = 1, j = -1,part = 'header', \n        border= list(width = 0.1, color = \"black\", style = \"solid\"))\n\nSpeziesBiscoeDreamTorgersenMSDMSDMSDAdelie39.002.5038.502.5039.003.00Chinstrap48.803.30Gentoo47.503.10\n\n\nZuletzt mpssen wir noch die “stub”-Spalte linksbündig formatieren:\n\nsummary_table %&gt;% \n  select(Spezies = species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  rename_with(.fn = ~str_remove(.,'_bill_length_mm')) %&gt;% \n  flextable() %&gt;% \n  separate_header() %&gt;%\n  italic(part =\"header\", i= 2) %&gt;% \n  theme_apa() %&gt;% \n  hline(i = 1, j = -1,part = 'header', \n        border= list(width = 0.1, color = \"black\", style = \"solid\")) %&gt;% \n  align_text_col()\n\nSpeziesBiscoeDreamTorgersenMSDMSDMSDAdelie39.002.5038.502.5039.003.00Chinstrap48.803.30Gentoo47.503.10\n\n\nDamit ist das Format der Tabelle erstmal fertig.\nWir können, wenn wir die Tabelle nicht in quarto einbinden wollen, auch einen Export in eine Word-Datei aus einem R-Skript durchführen:\n\nsummary_table %&gt;% \n  select(Spezies = species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  rename_with(.fn = ~str_remove(.,'_bill_length_mm')) %&gt;% \n  flextable() %&gt;% \n  separate_header() %&gt;%\n  italic(part =\"header\", i= 2) %&gt;% \n  theme_apa() %&gt;% \n  hline(i = 1, j = -1,part = 'header', \n        border= list(width = 0.1, color = \"black\", style = \"solid\")) %&gt;% \n  align_text_col() %&gt;% \n  save_as_docx(path = 'flextable_out.docx')\n\nDer Export ist in Abbildung Export des flextable-calls. zu sehen.\n\n\n\n\n\n\nAbb 9.2: Export des flextable-calls.\n\n\n\n\nEinbettung in quarto\nIm Abschnitt zu quarto haben wir ja schon die chunk-Optionen zur Einbindung von Grafiken im Text besprochen. Ähnliche Optionen gibt es auch für Tabellen in quarto-Dokumenten.\nAuch bei Tabellen muss, damit die Tabelle referenziert werden kann und numeriert wird, eine label-Option gesetzt werden. Statt dem Präfix “fig” müssen wir bei Tabellen aber den Präfix “tbl” vorstellen.\nDamit sähe ein Chunk mit der Tabelle von gerade wie folgt aus:\n#| label: tbl-penguinSummary\n\nsummary_table %&gt;% \n  select(Spezies = species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  rename_with(.fn = ~str_remove(.,'_bill_length_mm')) %&gt;% \n  flextable() %&gt;% \n  separate_header() %&gt;%\n  italic(part =\"header\", i= 2) %&gt;% \n  theme_apa() %&gt;% \n  hline(i = 1, j = -1,part = 'header', \n        border= list(width = 0.1, color = \"black\", style = \"solid\")) %&gt;% \n  align_text_col()\nDaneben können wir auch wieder Beschriftungen einfügen, diesmal mit der Chunk-Option tbl-cap:\n#| label: tbl-penguinSummary\n#| tbl-cap: Mittelwerte und Streuungen der Schnabellängen der beobachteten Pinguin-Populationen aufgeteilt nach Spezies und Insel.\n\nsummary_table %&gt;% \n  select(Spezies = species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  rename_with(.fn = ~str_remove(.,'_bill_length_mm')) %&gt;% \n  flextable() %&gt;% \n  separate_header() %&gt;%\n  italic(part =\"header\", i= 2) %&gt;% \n  theme_apa() %&gt;% \n  hline(i = 1, j = -1,part = 'header', \n        border= list(width = 0.1, color = \"black\", style = \"solid\")) %&gt;% \n  align_text_col()\nDas Ergebnis ist in diesem quarto-Dokument in Tabelle Mittelwerte und Streuungen der Schnabellängen der beobachteten Pinguin-Populationen aufgeteilt nach Spezies und Insel. zu sehen.\n\nsummary_table %&gt;% \n  select(Spezies = species, matches('Bis'), matches('Dre'), matches('Tor')) %&gt;% \n  mutate(across(where(is.numeric), ~round(., 1))) %&gt;% \n  rename_with(.fn = ~str_remove(.,'_bill_length_mm')) %&gt;% \n  flextable() %&gt;% \n  separate_header() %&gt;%\n  italic(part =\"header\", i= 2) %&gt;% \n  theme_apa() %&gt;% \n  hline(i = 1, j = -1,part = 'header', \n        border= list(width = 0.1, color = \"black\", style = \"solid\")) %&gt;% \n  align_text_col() \n\n\n\nTab 9.1: Mittelwerte und Streuungen der Schnabellängen der beobachteten Pinguin-Populationen aufgeteilt nach Spezies und Insel.\n\n\n\nSpeziesBiscoeDreamTorgersenMSDMSDMSDAdelie39.002.5038.502.5039.003.00Chinstrap48.803.30Gentoo47.503.10\n\n\n\n\n\n\n\nAufgaben\n\nAufgabe 1:\nBauen Sie die mit apaTables in Aufgabe 1 im Abschnitt zu apaTables gebaute Tabelle mit flextable nach und fügen diese zu dem bereits erstellten quarto-Dokument hinzu. Sie können gern auf die Note am unteren Rand verzichten. Oder sie lesen die Dokumentation von add_footer_lines und fügen die Notiz hinzu.\n\n\nDer Code-Chunk könnte so oder so ähnlich aussehen:\n#| label: tbl-irisSummary\n#| tbl-cap: Descriptive statistics for Petal.Length as a function of Species.\n\niris %&gt;% \n  group_by(Species) %&gt;% \n  summarise(M = mean(Petal.Length), SD = sd(Petal.Length)) %&gt;% \n  flextable() %&gt;% \n  italic(part =\"header\", i= 1, j = 2:3) %&gt;% \n  theme_apa() %&gt;% \n  hline(i = 1, j = -1,part = 'header', \n        border= list(width = 0.1, color = \"black\", style = \"solid\")) %&gt;% \n  align_text_col() %&gt;% \n  add_footer_lines('Note. M and SD represent mean and standard deviation, respectively.')\nDas Ergebnis sieht dann so aus:\n\niris %&gt;% \n  group_by(Species) %&gt;% \n  summarise(M = mean(Petal.Length), SD = sd(Petal.Length)) %&gt;% \n  flextable() %&gt;% \n  italic(part =\"header\", i= 1, j = 2:3) %&gt;% \n  theme_apa() %&gt;% \n  hline(i = 1, j = -1,part = 'header', \n        border= list(width = 0.1, color = \"black\", style = \"solid\")) %&gt;% \n  align_text_col() %&gt;% \n  add_footer_lines('Note. M and SD represent mean and standard deviation, respectively.')\n\n\n\nTab 9.2: Descriptive statistics for Petal.Length as a function of Species.\n\n\n\nSpeciesMSDsetosa1.460.17versicolor4.260.47virginica5.550.55Note. M and SD represent mean and standard deviation, respectively.\n\n\n\n\n\n\n\nAntwort aufdecken\n\n\n\n\nAufgabe 2:\nÜberfliegen Sie das Kapitel zu visuellen Eigenschaften im flextable-Buch und machen Sie die Tabelle so bunt, wie Ihre Augen es aushalten. Ändern Sie sonst noch gern alles, was die Erfahrung weniger angenehm macht.\n\n\n\ntab = iris %&gt;% \n  group_by(Species) %&gt;% \n  summarise(M = mean(Petal.Length), SD = sd(Petal.Length)) %&gt;% \n  flextable() %&gt;% \n  italic(part =\"header\", i= 1, j = 2:3) %&gt;% \n  theme_apa() %&gt;% \n  hline(i = 1, j = -1,part = 'header', \n        border= list(width = 0.1, color = \"black\", style = \"solid\")) %&gt;% \n  align_text_col() %&gt;% \n  add_footer_lines('Note. M and SD represent mean and standard deviation, respectively.') %&gt;% \n  bg(bg = \"hotpink\", part = \"all\") %&gt;% \n  bg(bg = \"darksalmon\", part = \"header\")%&gt;% \n  bg(bg = \"violetred\", part = \"footer\")\n  \n\n\n\nrows = rep(1:3, times = 3)\ncols = rep(1:3, each = 3)\ncolors = c('cyan', 'lawngreen', 'firebrick1', 'mediumorchid')\n\nfor(i in 1:9){\n  color &lt;- colors[round(sqrt(rows[i]**2 + cols[i]**2))]\n  tab &lt;- tab %&gt;% \n    style(rows[i], cols[i], fp_text_default(shading.color = color))\n}\ntab\n\n\n\nTab 9.3: Descriptive statistics for Petal.Length as a function of Species.\n\n\n\nSpeciesMSDsetosa1.460.17versicolor4.260.47virginica5.550.55Note. M and SD represent mean and standard deviation, respectively.\n\n\n\n\n\n\n\nAntwort aufdecken",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tabellen und Ergebnisdarstellungen</span>"
    ]
  },
  {
    "objectID": "tables.html#ergebnisse-mit-papaja",
    "href": "tables.html#ergebnisse-mit-papaja",
    "title": "Tabellen und Ergebnisdarstellungen",
    "section": "Ergebnisse mit papaja",
    "text": "Ergebnisse mit papaja\nIm Gegensatz zu den beiden bisher vorgestellten Paketen ist papaja (Aust & Barth, 2023) nicht nur ein Paket für Tabellen, sondern ein framework zur Erstellung ganzer Berichte. Mit papaja erstellte RMarkdown-Dokumente werden direkt vollständig in APA-Format gerendert2. Außerdem gibt es noch einen ganzen Haufen an Plots, die von papaja angeboten werden.\n2 Rmarkdown ist der Vorgänger von quarto. Da quarto in Zukunft wesentlich mehr Support und Features verspricht, werden in diesem Workshop die papaja-Rmarkdown-Dokumente ausgelassen.Für diesen Workshop sind aber zwei Features besonders interessant:\napa_print und apa_table. In beide Funktionen lassen sich Ergebnisse von einer Reihe von statistischen Ergebnissen übergeben und Inline-Ergebnis-Prints und Tabellen erstellen.\nAm Beispiel der linearen Regression vom Anfang des Abschnitts zu tidymodels, könnte das Vorgehen wie folgt aussehen. Zuerst erstellen wir unseren Modell-Fit:\n\nlm_model &lt;- linear_reg()\n\nlm_fit &lt;- lm_model %&gt;% \n  fit(price ~ sqft + beds, data = Sacramento)\n\nDann lassen wir uns den fit als als apa_print ausgeben:\n\nlibrary(papaja)\n\nLoading required package: tinylabels\n\n\n\nAttaching package: 'papaja'\n\n\nThe following object is masked from 'package:flextable':\n\n    theme_apa\n\n\nThe following object is masked from 'package:infer':\n\n    conf_int\n\nlm_fit$fit %&gt;% \n  apa_print()  \n\n$estimate\n$estimate$Intercept\n[1] \"$b = 60,850.54$, 95\\\\% CI $[40,392.19, 81,308.90]$\"\n\n$estimate$sqft\n[1] \"$b = 161.34$, 95\\\\% CI $[150.86, 171.81]$\"\n\n$estimate$beds\n[1] \"$b = -26,035.15$, 95\\\\% CI $[-34,604.71, -17,465.58]$\"\n\n$estimate$modelfit\n$estimate$modelfit$r2\n[1] \"$R^2 = .60$, 90\\\\% CI $[0.57, 0.64]$\"\n\n$estimate$modelfit$r2_adj\n[1] \"$R^2_{adj} = .60$\"\n\n$estimate$modelfit$aic\n[1] \"$\\\\mathrm{AIC} = 23,753.79$\"\n\n$estimate$modelfit$bic\n[1] \"$\\\\mathrm{BIC} = 23,773.14$\"\n\n\n\n$statistic\n$statistic$Intercept\n[1] \"$t(929) = 5.84$, $p &lt; .001$\"\n\n$statistic$sqft\n[1] \"$t(929) = 30.22$, $p &lt; .001$\"\n\n$statistic$beds\n[1] \"$t(929) = -5.96$, $p &lt; .001$\"\n\n$statistic$modelfit\n$statistic$modelfit$r2\n[1] \"$F(2, 929) = 708.47$, $p &lt; .001$\"\n\n\n\n$full_result\n$full_result$Intercept\n[1] \"$b = 60,850.54$, 95\\\\% CI $[40,392.19, 81,308.90]$, $t(929) = 5.84$, $p &lt; .001$\"\n\n$full_result$sqft\n[1] \"$b = 161.34$, 95\\\\% CI $[150.86, 171.81]$, $t(929) = 30.22$, $p &lt; .001$\"\n\n$full_result$beds\n[1] \"$b = -26,035.15$, 95\\\\% CI $[-34,604.71, -17,465.58]$, $t(929) = -5.96$, $p &lt; .001$\"\n\n$full_result$modelfit\n$full_result$modelfit$r2\n[1] \"$R^2 = .60$, 90\\\\% CI $[0.57, 0.64]$, $F(2, 929) = 708.47$, $p &lt; .001$\"\n\n\n\n$table\nA data.frame with 6 labelled columns:\n\n       term   estimate                 conf.int statistic  df p.value\n1 Intercept  60,850.54   [40,392.19, 81,308.90]      5.84 929  &lt; .001\n2      Sqft     161.34         [150.86, 171.81]     30.22 929  &lt; .001\n3      Beds -26,035.15 [-34,604.71, -17,465.58]     -5.96 929  &lt; .001\n\nterm     : Predictor \nestimate : $b$ \nconf.int : 95\\\\% CI \nstatistic: $t$ \ndf       : $\\\\mathit{df}$ \np.value  : $p$ \nattr(,\"class\")\n[1] \"apa_results\" \"list\"       \n\n\nIm Print sehen wir schon als Inline-Code formatierte Strings, die wir zum Beispiel so in den Text einfügen können:\nDer Beitrag der Wohnungsgröße zum Modell zur Aufklärung des Wohnungspreises war signifikant von 0 unterschiedlich ($b = 161.34$, 95\\% CI $[150.86, 171.81]$, $t(929) = 30.22$, $p &lt; .001$).\nIm Text sähe der Satz dann wie folgt aus:\n\nDer Beitrag der Wohnungsgröße zum Modell zur Aufklärung des Wohnungspreises war signifikant von 0 unterschiedlich (\\(b = 161.34\\), 95% CI \\([150.86, 171.81]\\), \\(t(929) = 30.22\\), \\(p &lt; .001\\)).\n\nDen Output von apa_print können wir mit apa_table dann auch direkt als Tabelle rendern:\n\nlm_fit$fit %&gt;% \n  apa_print()  %&gt;% \n  apa_table()\n\n\n(#tab:unnamed-chunk-26)\n\n\nPredictor\n\\(b\\)\n95% CI\n\\(t\\)\n\\(\\mathit{df}\\)\n\\(p\\)\n\n\n\n\nIntercept\n60,850.54\n[40,392.19, 81,308.90]\n5.84\n929\n&lt; .001\n\n\nSqft\n161.34\n[150.86, 171.81]\n30.22\n929\n&lt; .001\n\n\nBeds\n-26,035.15\n[-34,604.71, -17,465.58]\n-5.96\n929\n&lt; .001\n\n\n\n\n\nDer Output ist dabei eine markdown-Tabelle. Das heißt das unsere Formatierungsmöglichkeiten aus dem Abschnitt zu flextable auch hier funktionieren. Der folgende Chunk:\n#| label: tbl-papajaModelfit\n#| tbl-cap: Tabelle mit den Ergebnissen der Beispielregression\n\nlm_fit$fit %&gt;% \n  apa_print()  %&gt;% \n  apa_table()\nwird zu:\n\n\n\n\nTab 9.4: Tabelle mit den Ergebnissen der Beispielregression\n\n\n\n\n(#tab:tbl-papajaModelfit)\n\n\nPredictor\n\\(b\\)\n95% CI\n\\(t\\)\n\\(\\mathit{df}\\)\n\\(p\\)\n\n\n\n\nIntercept\n60,850.54\n[40,392.19, 81,308.90]\n5.84\n929\n&lt; .001\n\n\nSqft\n161.34\n[150.86, 171.81]\n30.22\n929\n&lt; .001\n\n\nBeds\n-26,035.15\n[-34,604.71, -17,465.58]\n-5.96\n929\n&lt; .001\n\n\n\n\n\n\n\n\n\nAufgaben\n\nAufgabe 1:\nRechnen Sie einen t-Test (t.test) mit der Breite der Blütenblätter als AV und den Spezies setosa und versicolor als Gruppen.\n\n\n\ntest_data &lt;- iris %&gt;% \n  filter(Species %in% c('setosa', 'versicolor')) %&gt;% \n  select(Species, Petal.Width)\n\ntest = t.test(Petal.Width ~ Species, data = test_data)\n\n\n\nAntwort aufdecken\n\n\n\n\nAufgabe 2:\nFügen Sie die Ergebnisse des t-Tests als inline-Code und als Tabelle in ein quarto-Dokument ein.\n\n\n#| label: tbl-ttest\n#| tbl-cap: Ergebnisse des t-Tests\n\ntest_print &lt;- apa_print(test)\n\napa_table(test_print)\n\n\n\n\nTab 9.5: Ergebnisse des t-Tests\n\n\n\n\n(#tab:tbl-ttest)\n\n\n\\(\\Delta M\\)\n95% CI\n\\(t\\)\n\\(\\mathit{df}\\)\n\\(p\\)\n\n\n\n\n-1.08\n[-1.14, -1.02]\n-34.08\n74.75\n&lt; .001\n\n\n\n\n\n\n\n\nDer Test war signifikant \\(\\Delta M = -1.08\\), 95% CI \\([-1.14, -1.02]\\), \\(t(74.75) = -34.08\\), \\(p &lt; .001\\).\n\n\nAntwort aufdecken",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tabellen und Ergebnisdarstellungen</span>"
    ]
  },
  {
    "objectID": "tables.html#literatur",
    "href": "tables.html#literatur",
    "title": "Tabellen und Ergebnisdarstellungen",
    "section": "Literatur",
    "text": "Literatur\n\n\n\n\nAust, F., & Barth, M. (2023). papaja: Prepare reproducible APA journal articles with R Markdown. https://github.com/crsh/papaja\n\n\nGohel, D., & Skintzos, P. (2023). Flextable: Functions for tabular reporting. https://CRAN.R-project.org/package=flextable\n\n\nStanley, D. (2021). apaTables: Create american psychological association (APA) style tables. https://CRAN.R-project.org/package=apaTables",
    "crumbs": [
      "Tag 2",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tabellen und Ergebnisdarstellungen</span>"
    ]
  }
]